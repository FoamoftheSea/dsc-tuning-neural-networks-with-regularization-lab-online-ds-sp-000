{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recall from the last lab that you had a training accuracy close to 90% and a test set accuracy close to 76%.\n",
    "\n",
    "As with your previous machine learning work, you should be asking a couple of questions:\n",
    "- Is there high bias? yes/no\n",
    "- Is there high variance? yes/no \n",
    "\n",
    "In this lab, you'll use the a train-validate-test partition as well as a validation set to get better insights of how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. However, this time, when you are presented with the `history` dictionary of the model, you will have additional data entries for not only the train and test set but also the validation set.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Construct and run a basic model in Keras\n",
    "* Construct a validation set and explain potential benefits\n",
    "* Apply L1 and L2 regularization\n",
    "* Apply dropout regularization\n",
    "* Observe and comment on the effect of using more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "As usual, start by importing some of the packages and modules that you intend to use. The first thing you'll be doing is importing the data and taking a random sample, so that should clue you in to what tools to import. If you need more tools down the line, you can always import additional packages later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; import some packages/modules you plan to use\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "As with the previous lab, the data is stored in a file **Bank_complaints.csv**. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here; load and preview the dataset\n",
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools regarding regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Train - test split\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your models performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "Generate the random sample using seed 123 for consistency of results. Make your new sample have 10,000 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "sample = df.sample(10000, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split\n",
    "\n",
    "Below, perform an appropriate train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample['Consumer complaint narrative']\n",
    "y = sample['Product']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model using a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, you saw that in deep learning, you generally set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test can then be used to define the final model perforance. \n",
    "\n",
    "In this example, take the first 1000 cases out of the training set to create a validation set. You should do this for both `train` and `label_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just run this block of code \n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding of the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing and data manipulationg before building the neural network. \n",
    "\n",
    "Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; use one-hot encoding to reformat the complaints into a matrix of vectors.\n",
    "#Only keep the 2000 most common words.\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "\n",
    "X_train_tok = tokenizer.texts_to_matrix(X_train_final, mode='binary')\n",
    "X_val = tokenizer.texts_to_matrix(X_val, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; transform the product labels to numerical values\n",
    "#Then transform these integer values into a matrix of binary flags\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "y_train_lb = to_categorical(lb.transform(y_train_final))[:, :, 1]\n",
    "y_val = to_categorical(lb.transform(y_val))[:, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild a fully connected (Dense) layer network with relu activations in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that you used 2 hidden with 50 units in the first layer and 25 in the second, both with a `relu` activation function. Because you are dealing with a multiclass problem (classifying the complaints into 7 classes), use a softmax classifyer in order to output 7 class probabilities per case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; build a neural network using Keras as described above.\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model\n",
    "In the compiler, you'll be passing the optimizer, loss function, and metrics. Train the model for 120 epochs in mini-batches of 256 samples. This time, include the argument `validation_data` and assign it `(val, label_val)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Ok, now for the resource intensive part: time to train your model! Note that this is where you also introduce the validation data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.9601 - accuracy: 0.1389 - val_loss: 1.9428 - val_accuracy: 0.1650\n",
      "Epoch 2/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9292 - accuracy: 0.1737 - val_loss: 1.9204 - val_accuracy: 0.1840\n",
      "Epoch 3/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9074 - accuracy: 0.1999 - val_loss: 1.9014 - val_accuracy: 0.2070\n",
      "Epoch 4/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8874 - accuracy: 0.2276 - val_loss: 1.8822 - val_accuracy: 0.2300\n",
      "Epoch 5/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8659 - accuracy: 0.2503 - val_loss: 1.8604 - val_accuracy: 0.2520\n",
      "Epoch 6/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8416 - accuracy: 0.2731 - val_loss: 1.8352 - val_accuracy: 0.2860\n",
      "Epoch 7/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8137 - accuracy: 0.2986 - val_loss: 1.8056 - val_accuracy: 0.3140\n",
      "Epoch 8/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7812 - accuracy: 0.3300 - val_loss: 1.7711 - val_accuracy: 0.3450\n",
      "Epoch 9/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7442 - accuracy: 0.3707 - val_loss: 1.7326 - val_accuracy: 0.3720\n",
      "Epoch 10/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7026 - accuracy: 0.4074 - val_loss: 1.6893 - val_accuracy: 0.4140\n",
      "Epoch 11/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6571 - accuracy: 0.4410 - val_loss: 1.6433 - val_accuracy: 0.4470\n",
      "Epoch 12/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6088 - accuracy: 0.4733 - val_loss: 1.5943 - val_accuracy: 0.4770\n",
      "Epoch 13/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5581 - accuracy: 0.4986 - val_loss: 1.5443 - val_accuracy: 0.4960\n",
      "Epoch 14/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5061 - accuracy: 0.5201 - val_loss: 1.4926 - val_accuracy: 0.5190\n",
      "Epoch 15/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4535 - accuracy: 0.5453 - val_loss: 1.4426 - val_accuracy: 0.5310\n",
      "Epoch 16/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4018 - accuracy: 0.5616 - val_loss: 1.3933 - val_accuracy: 0.5630\n",
      "Epoch 17/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3514 - accuracy: 0.5846 - val_loss: 1.3458 - val_accuracy: 0.5690\n",
      "Epoch 18/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3030 - accuracy: 0.5954 - val_loss: 1.2998 - val_accuracy: 0.5820\n",
      "Epoch 19/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2565 - accuracy: 0.6123 - val_loss: 1.2580 - val_accuracy: 0.5980\n",
      "Epoch 20/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2127 - accuracy: 0.6304 - val_loss: 1.2168 - val_accuracy: 0.6050\n",
      "Epoch 21/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1712 - accuracy: 0.6437 - val_loss: 1.1807 - val_accuracy: 0.6170\n",
      "Epoch 22/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1324 - accuracy: 0.6530 - val_loss: 1.1458 - val_accuracy: 0.6280\n",
      "Epoch 23/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0960 - accuracy: 0.6680 - val_loss: 1.1126 - val_accuracy: 0.6390\n",
      "Epoch 24/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0619 - accuracy: 0.6733 - val_loss: 1.0844 - val_accuracy: 0.6400\n",
      "Epoch 25/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.0303 - accuracy: 0.6809 - val_loss: 1.0568 - val_accuracy: 0.6560\n",
      "Epoch 26/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0003 - accuracy: 0.6916 - val_loss: 1.0313 - val_accuracy: 0.6580\n",
      "Epoch 27/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9729 - accuracy: 0.6987 - val_loss: 1.0068 - val_accuracy: 0.6640\n",
      "Epoch 28/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9467 - accuracy: 0.7037 - val_loss: 0.9836 - val_accuracy: 0.6770\n",
      "Epoch 29/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9225 - accuracy: 0.7126 - val_loss: 0.9651 - val_accuracy: 0.6750\n",
      "Epoch 30/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8996 - accuracy: 0.7150 - val_loss: 0.9454 - val_accuracy: 0.6820\n",
      "Epoch 31/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8788 - accuracy: 0.7209 - val_loss: 0.9284 - val_accuracy: 0.6870\n",
      "Epoch 32/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8588 - accuracy: 0.7266 - val_loss: 0.9132 - val_accuracy: 0.6910\n",
      "Epoch 33/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8406 - accuracy: 0.7300 - val_loss: 0.8974 - val_accuracy: 0.6920\n",
      "Epoch 34/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8238 - accuracy: 0.7321 - val_loss: 0.8850 - val_accuracy: 0.6930\n",
      "Epoch 35/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8074 - accuracy: 0.7390 - val_loss: 0.8697 - val_accuracy: 0.6970\n",
      "Epoch 36/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7921 - accuracy: 0.7410 - val_loss: 0.8585 - val_accuracy: 0.6970\n",
      "Epoch 37/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7775 - accuracy: 0.7436 - val_loss: 0.8472 - val_accuracy: 0.7030\n",
      "Epoch 38/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7641 - accuracy: 0.7476 - val_loss: 0.8365 - val_accuracy: 0.7050\n",
      "Epoch 39/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7516 - accuracy: 0.7517 - val_loss: 0.8282 - val_accuracy: 0.7060\n",
      "Epoch 40/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7395 - accuracy: 0.7546 - val_loss: 0.8175 - val_accuracy: 0.7110\n",
      "Epoch 41/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7278 - accuracy: 0.7563 - val_loss: 0.8082 - val_accuracy: 0.7130\n",
      "Epoch 42/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7167 - accuracy: 0.7584 - val_loss: 0.8005 - val_accuracy: 0.7140\n",
      "Epoch 43/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7064 - accuracy: 0.7629 - val_loss: 0.7959 - val_accuracy: 0.7110\n",
      "Epoch 44/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6966 - accuracy: 0.7644 - val_loss: 0.7867 - val_accuracy: 0.7170\n",
      "Epoch 45/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.7696 - val_loss: 0.7806 - val_accuracy: 0.7170\n",
      "Epoch 46/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6774 - accuracy: 0.7726 - val_loss: 0.7729 - val_accuracy: 0.7170\n",
      "Epoch 47/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.6688 - accuracy: 0.7730 - val_loss: 0.7695 - val_accuracy: 0.7210\n",
      "Epoch 48/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.7741 - val_loss: 0.7629 - val_accuracy: 0.7240\n",
      "Epoch 49/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.7794 - val_loss: 0.7570 - val_accuracy: 0.7240\n",
      "Epoch 50/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.6450 - accuracy: 0.7809 - val_loss: 0.7501 - val_accuracy: 0.7270\n",
      "Epoch 51/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.7843 - val_loss: 0.7475 - val_accuracy: 0.7240\n",
      "Epoch 52/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.7851 - val_loss: 0.7406 - val_accuracy: 0.7330\n",
      "Epoch 53/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.7884 - val_loss: 0.7388 - val_accuracy: 0.7350\n",
      "Epoch 54/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.7909 - val_loss: 0.7353 - val_accuracy: 0.7340\n",
      "Epoch 55/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.7914 - val_loss: 0.7309 - val_accuracy: 0.7410\n",
      "Epoch 56/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.6036 - accuracy: 0.7954 - val_loss: 0.7303 - val_accuracy: 0.7330\n",
      "Epoch 57/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7963 - val_loss: 0.7223 - val_accuracy: 0.7380\n",
      "Epoch 58/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7977 - val_loss: 0.7220 - val_accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.8019 - val_loss: 0.7181 - val_accuracy: 0.7380\n",
      "Epoch 60/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.8033 - val_loss: 0.7130 - val_accuracy: 0.7430\n",
      "Epoch 61/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5740 - accuracy: 0.8021 - val_loss: 0.7123 - val_accuracy: 0.7420\n",
      "Epoch 62/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.8067 - val_loss: 0.7067 - val_accuracy: 0.7450\n",
      "Epoch 63/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.8074 - val_loss: 0.7061 - val_accuracy: 0.7450\n",
      "Epoch 64/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.8110 - val_loss: 0.7044 - val_accuracy: 0.7420\n",
      "Epoch 65/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.8109 - val_loss: 0.7016 - val_accuracy: 0.7460\n",
      "Epoch 66/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.8144 - val_loss: 0.7064 - val_accuracy: 0.7440\n",
      "Epoch 67/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.8161 - val_loss: 0.6963 - val_accuracy: 0.7490\n",
      "Epoch 68/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.8160 - val_loss: 0.6955 - val_accuracy: 0.7500\n",
      "Epoch 69/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.8177 - val_loss: 0.6944 - val_accuracy: 0.7520\n",
      "Epoch 70/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.8236 - val_loss: 0.6917 - val_accuracy: 0.7500\n",
      "Epoch 71/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.8223 - val_loss: 0.6908 - val_accuracy: 0.7470\n",
      "Epoch 72/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.8267 - val_loss: 0.6879 - val_accuracy: 0.7550\n",
      "Epoch 73/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.8250 - val_loss: 0.6886 - val_accuracy: 0.7520\n",
      "Epoch 74/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.8277 - val_loss: 0.6860 - val_accuracy: 0.7530\n",
      "Epoch 75/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.8283 - val_loss: 0.6862 - val_accuracy: 0.7500\n",
      "Epoch 76/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.8320 - val_loss: 0.6832 - val_accuracy: 0.7470\n",
      "Epoch 77/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.8347 - val_loss: 0.6814 - val_accuracy: 0.7540\n",
      "Epoch 78/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.8340 - val_loss: 0.6821 - val_accuracy: 0.7480\n",
      "Epoch 79/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.8340 - val_loss: 0.6803 - val_accuracy: 0.7460\n",
      "Epoch 80/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.8341 - val_loss: 0.6792 - val_accuracy: 0.7490\n",
      "Epoch 81/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.8363 - val_loss: 0.6776 - val_accuracy: 0.7570\n",
      "Epoch 82/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.8371 - val_loss: 0.6781 - val_accuracy: 0.7500\n",
      "Epoch 83/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.8397 - val_loss: 0.6782 - val_accuracy: 0.7520\n",
      "Epoch 84/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.8423 - val_loss: 0.6762 - val_accuracy: 0.7510\n",
      "Epoch 85/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.8420 - val_loss: 0.6734 - val_accuracy: 0.7550\n",
      "Epoch 86/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.8437 - val_loss: 0.6753 - val_accuracy: 0.7570\n",
      "Epoch 87/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.8431 - val_loss: 0.6746 - val_accuracy: 0.7550\n",
      "Epoch 88/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.8459 - val_loss: 0.6740 - val_accuracy: 0.7530\n",
      "Epoch 89/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8473 - val_loss: 0.6717 - val_accuracy: 0.7550\n",
      "Epoch 90/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8490 - val_loss: 0.6709 - val_accuracy: 0.7580\n",
      "Epoch 91/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.8507 - val_loss: 0.6704 - val_accuracy: 0.7610\n",
      "Epoch 92/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.8494 - val_loss: 0.6707 - val_accuracy: 0.7590\n",
      "Epoch 93/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.8547 - val_loss: 0.6726 - val_accuracy: 0.7530\n",
      "Epoch 94/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8526 - val_loss: 0.6692 - val_accuracy: 0.7560\n",
      "Epoch 95/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8543 - val_loss: 0.6712 - val_accuracy: 0.7610\n",
      "Epoch 96/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8560 - val_loss: 0.6714 - val_accuracy: 0.7560\n",
      "Epoch 97/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8576 - val_loss: 0.6720 - val_accuracy: 0.7560\n",
      "Epoch 98/120\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8597 - val_loss: 0.6717 - val_accuracy: 0.7550\n",
      "Epoch 99/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8624 - val_loss: 0.6683 - val_accuracy: 0.7560\n",
      "Epoch 100/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8610 - val_loss: 0.6718 - val_accuracy: 0.7580\n",
      "Epoch 101/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8633 - val_loss: 0.6689 - val_accuracy: 0.7620\n",
      "Epoch 102/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8654 - val_loss: 0.6707 - val_accuracy: 0.7610\n",
      "Epoch 103/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8650 - val_loss: 0.6724 - val_accuracy: 0.7580\n",
      "Epoch 104/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8667 - val_loss: 0.6709 - val_accuracy: 0.7610\n",
      "Epoch 105/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8693 - val_loss: 0.6715 - val_accuracy: 0.7570\n",
      "Epoch 106/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8716 - val_loss: 0.6691 - val_accuracy: 0.7610\n",
      "Epoch 107/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8724 - val_loss: 0.6691 - val_accuracy: 0.7620\n",
      "Epoch 108/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8719 - val_loss: 0.6698 - val_accuracy: 0.7550\n",
      "Epoch 109/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8730 - val_loss: 0.6698 - val_accuracy: 0.7610\n",
      "Epoch 110/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8774 - val_loss: 0.6737 - val_accuracy: 0.7540\n",
      "Epoch 111/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8784 - val_loss: 0.6734 - val_accuracy: 0.7570\n",
      "Epoch 112/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8784 - val_loss: 0.6725 - val_accuracy: 0.7600\n",
      "Epoch 113/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8804 - val_loss: 0.6730 - val_accuracy: 0.7560\n",
      "Epoch 114/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8830 - val_loss: 0.6704 - val_accuracy: 0.7590\n",
      "Epoch 115/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8837 - val_loss: 0.6723 - val_accuracy: 0.7610\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8856 - val_loss: 0.6697 - val_accuracy: 0.7600\n",
      "Epoch 117/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8854 - val_loss: 0.6724 - val_accuracy: 0.7580\n",
      "Epoch 118/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8860 - val_loss: 0.6709 - val_accuracy: 0.7630\n",
      "Epoch 119/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8879 - val_loss: 0.6744 - val_accuracy: 0.7580\n",
      "Epoch 120/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8887 - val_loss: 0.6751 - val_accuracy: 0.7540\n"
     ]
    }
   ],
   "source": [
    "#Code provided; note the extra validation parameter passed.\n",
    "model_val = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Performance Results: the `history` dictionary\n",
    "\n",
    "The dictionary `history` contains four entries this time: one per metric that was being monitored during training and during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val_dict = model_val.history\n",
    "model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 889us/step - loss: 0.3565 - accuracy: 0.8910\n",
      "Training Loss: 0.356 Training Accuracy: 0.891\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess then evaluate our models performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 984us/step - loss: 0.6347 - accuracy: 0.7680\n",
      "Testing Loss: 0.635 Testing Accuracy: 0.768\n"
     ]
    }
   ],
   "source": [
    "X_test_tok = tokenizer.texts_to_matrix(X_test, mode='binary')\n",
    "y_test_cat = to_categorical(lb.transform(y_test))[:, :, 1]\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element of the list returned by `model.evaluate` is the loss, and the second is the accuracy score. \n",
    "\n",
    "Note that the result you obtained here isn't exactly the same as before. This is because the training set is slightly different! You removed 1000 instances for validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function versus the number of epochs. Be sure to include the training and the validation loss in the same plot. Then, create a second plot comparing training and validation accuracy to the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and val set\n",
    "visualize_training_results(model_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice an interesting pattern here: although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss seem to be reaching a limit around the 60th epoch. This means that you're probably **overfitting** the model to the training data when you train for many epochs past this dropoff point of around 40 epochs. Luckily, you learned how to tackle overfitting in the previous lecture! Since it seems clear that you are training too long, include early stopping at the 60th epoch first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Below, observe how to update the model to include an earlier cutoff point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.9613 - accuracy: 0.1479 - val_loss: 1.9608 - val_accuracy: 0.1490\n",
      "Epoch 2/60\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.9458 - accuracy: 0.1607 - val_loss: 1.9494 - val_accuracy: 0.1550\n",
      "Epoch 3/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9343 - accuracy: 0.1799 - val_loss: 1.9400 - val_accuracy: 0.1620\n",
      "Epoch 4/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9234 - accuracy: 0.1959 - val_loss: 1.9297 - val_accuracy: 0.1840\n",
      "Epoch 5/60\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.9114 - accuracy: 0.2141 - val_loss: 1.9181 - val_accuracy: 0.2070\n",
      "Epoch 6/60\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8972 - accuracy: 0.2399 - val_loss: 1.9046 - val_accuracy: 0.2300\n",
      "Epoch 7/60\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8803 - accuracy: 0.2639 - val_loss: 1.8892 - val_accuracy: 0.2460\n",
      "Epoch 8/60\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8606 - accuracy: 0.2824 - val_loss: 1.8706 - val_accuracy: 0.2640\n",
      "Epoch 9/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8378 - accuracy: 0.3017 - val_loss: 1.8484 - val_accuracy: 0.2800\n",
      "Epoch 10/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8117 - accuracy: 0.3229 - val_loss: 1.8226 - val_accuracy: 0.2980\n",
      "Epoch 11/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7817 - accuracy: 0.3369 - val_loss: 1.7940 - val_accuracy: 0.3090\n",
      "Epoch 12/60\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.7477 - accuracy: 0.3574 - val_loss: 1.7592 - val_accuracy: 0.3390\n",
      "Epoch 13/60\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.7090 - accuracy: 0.3744 - val_loss: 1.7207 - val_accuracy: 0.3510\n",
      "Epoch 14/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6668 - accuracy: 0.3913 - val_loss: 1.6809 - val_accuracy: 0.3710\n",
      "Epoch 15/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6228 - accuracy: 0.4151 - val_loss: 1.6393 - val_accuracy: 0.3870\n",
      "Epoch 16/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5783 - accuracy: 0.4361 - val_loss: 1.5955 - val_accuracy: 0.4120\n",
      "Epoch 17/60\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.5330 - accuracy: 0.4619 - val_loss: 1.5526 - val_accuracy: 0.4380\n",
      "Epoch 18/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4879 - accuracy: 0.4876 - val_loss: 1.5097 - val_accuracy: 0.4660\n",
      "Epoch 19/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4433 - accuracy: 0.5131 - val_loss: 1.4682 - val_accuracy: 0.4900\n",
      "Epoch 20/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3998 - accuracy: 0.5374 - val_loss: 1.4266 - val_accuracy: 0.5120\n",
      "Epoch 21/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3574 - accuracy: 0.5599 - val_loss: 1.3890 - val_accuracy: 0.5300\n",
      "Epoch 22/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3163 - accuracy: 0.5784 - val_loss: 1.3482 - val_accuracy: 0.5440\n",
      "Epoch 23/60\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.2763 - accuracy: 0.5990 - val_loss: 1.3099 - val_accuracy: 0.5650\n",
      "Epoch 24/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2379 - accuracy: 0.6129 - val_loss: 1.2748 - val_accuracy: 0.5790\n",
      "Epoch 25/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2009 - accuracy: 0.6306 - val_loss: 1.2403 - val_accuracy: 0.5900\n",
      "Epoch 26/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1653 - accuracy: 0.6431 - val_loss: 1.2079 - val_accuracy: 0.5980\n",
      "Epoch 27/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1311 - accuracy: 0.6534 - val_loss: 1.1752 - val_accuracy: 0.6180\n",
      "Epoch 28/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0982 - accuracy: 0.6644 - val_loss: 1.1470 - val_accuracy: 0.6280\n",
      "Epoch 29/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0675 - accuracy: 0.6724 - val_loss: 1.1167 - val_accuracy: 0.6390\n",
      "Epoch 30/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0375 - accuracy: 0.6800 - val_loss: 1.0878 - val_accuracy: 0.6440\n",
      "Epoch 31/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0093 - accuracy: 0.6900 - val_loss: 1.0643 - val_accuracy: 0.6430\n",
      "Epoch 32/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9829 - accuracy: 0.6951 - val_loss: 1.0388 - val_accuracy: 0.6430\n",
      "Epoch 33/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9579 - accuracy: 0.6980 - val_loss: 1.0211 - val_accuracy: 0.6530\n",
      "Epoch 34/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9347 - accuracy: 0.7049 - val_loss: 0.9952 - val_accuracy: 0.6600\n",
      "Epoch 35/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9123 - accuracy: 0.7104 - val_loss: 0.9783 - val_accuracy: 0.6570\n",
      "Epoch 36/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8915 - accuracy: 0.7169 - val_loss: 0.9574 - val_accuracy: 0.6710\n",
      "Epoch 37/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8726 - accuracy: 0.7194 - val_loss: 0.9412 - val_accuracy: 0.6700\n",
      "Epoch 38/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8541 - accuracy: 0.7249 - val_loss: 0.9270 - val_accuracy: 0.6760\n",
      "Epoch 39/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8371 - accuracy: 0.7294 - val_loss: 0.9104 - val_accuracy: 0.6830\n",
      "Epoch 40/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8210 - accuracy: 0.7300 - val_loss: 0.8979 - val_accuracy: 0.6820\n",
      "Epoch 41/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8057 - accuracy: 0.7363 - val_loss: 0.8854 - val_accuracy: 0.6860\n",
      "Epoch 42/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7919 - accuracy: 0.7380 - val_loss: 0.8739 - val_accuracy: 0.6900\n",
      "Epoch 43/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7788 - accuracy: 0.7397 - val_loss: 0.8654 - val_accuracy: 0.6880\n",
      "Epoch 44/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7660 - accuracy: 0.7430 - val_loss: 0.8558 - val_accuracy: 0.6960\n",
      "Epoch 45/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7539 - accuracy: 0.7459 - val_loss: 0.8487 - val_accuracy: 0.6910\n",
      "Epoch 46/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7428 - accuracy: 0.7523 - val_loss: 0.8344 - val_accuracy: 0.6960\n",
      "Epoch 47/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7318 - accuracy: 0.7527 - val_loss: 0.8296 - val_accuracy: 0.7050\n",
      "Epoch 48/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7221 - accuracy: 0.7549 - val_loss: 0.8203 - val_accuracy: 0.6980\n",
      "Epoch 49/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7121 - accuracy: 0.7564 - val_loss: 0.8161 - val_accuracy: 0.6980\n",
      "Epoch 50/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.7624 - val_loss: 0.8047 - val_accuracy: 0.7110\n",
      "Epoch 51/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.7614 - val_loss: 0.8002 - val_accuracy: 0.7070\n",
      "Epoch 52/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.7659 - val_loss: 0.7929 - val_accuracy: 0.7070\n",
      "Epoch 53/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.7680 - val_loss: 0.7888 - val_accuracy: 0.7070\n",
      "Epoch 54/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.7686 - val_loss: 0.7828 - val_accuracy: 0.7140\n",
      "Epoch 55/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.7706 - val_loss: 0.7781 - val_accuracy: 0.7080\n",
      "Epoch 56/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.7737 - val_loss: 0.7724 - val_accuracy: 0.7180\n",
      "Epoch 57/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.7760 - val_loss: 0.7707 - val_accuracy: 0.7180\n",
      "Epoch 58/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.7790 - val_loss: 0.7634 - val_accuracy: 0.7200\n",
      "Epoch 59/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.7790 - val_loss: 0.7592 - val_accuracy: 0.7180\n",
      "Epoch 60/60\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.7811 - val_loss: 0.7577 - val_accuracy: 0.7220\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "final_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=60,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use the test set to make label predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 956us/step - loss: 0.6230 - accuracy: 0.7861\n",
      "Training Loss: 0.623 Training Accuracy: 0.786\n",
      "63/63 [==============================] - 0s 979us/step - loss: 0.6889 - accuracy: 0.7480\n",
      "Testing Loss: 0.689 Testing Accuracy: 0.748\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've significantly reduced the variance, so this is already pretty good! your test set accuracy is slightly worse, but this model will definitely be more robust than the 120 epochs model you originally fit.\n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 2.6097 - accuracy: 0.1199 - val_loss: 2.5968 - val_accuracy: 0.1400\n",
      "Epoch 2/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.5861 - accuracy: 0.1636 - val_loss: 2.5797 - val_accuracy: 0.1700\n",
      "Epoch 3/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.5701 - accuracy: 0.1990 - val_loss: 2.5655 - val_accuracy: 0.2010\n",
      "Epoch 4/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.5557 - accuracy: 0.2286 - val_loss: 2.5520 - val_accuracy: 0.2150\n",
      "Epoch 5/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.5408 - accuracy: 0.2464 - val_loss: 2.5373 - val_accuracy: 0.2300\n",
      "Epoch 6/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.5243 - accuracy: 0.2646 - val_loss: 2.5207 - val_accuracy: 0.2490\n",
      "Epoch 7/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.5048 - accuracy: 0.2767 - val_loss: 2.5007 - val_accuracy: 0.2630\n",
      "Epoch 8/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.4821 - accuracy: 0.2924 - val_loss: 2.4779 - val_accuracy: 0.2820\n",
      "Epoch 9/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.4566 - accuracy: 0.3124 - val_loss: 2.4518 - val_accuracy: 0.2930\n",
      "Epoch 10/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.4284 - accuracy: 0.3253 - val_loss: 2.4235 - val_accuracy: 0.3180\n",
      "Epoch 11/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.3976 - accuracy: 0.3486 - val_loss: 2.3920 - val_accuracy: 0.3390\n",
      "Epoch 12/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.3638 - accuracy: 0.3656 - val_loss: 2.3579 - val_accuracy: 0.3710\n",
      "Epoch 13/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.3272 - accuracy: 0.3899 - val_loss: 2.3206 - val_accuracy: 0.3960\n",
      "Epoch 14/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.2877 - accuracy: 0.4151 - val_loss: 2.2799 - val_accuracy: 0.4190\n",
      "Epoch 15/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.2452 - accuracy: 0.4353 - val_loss: 2.2374 - val_accuracy: 0.4550\n",
      "Epoch 16/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.2012 - accuracy: 0.4620 - val_loss: 2.1932 - val_accuracy: 0.4810\n",
      "Epoch 17/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.1558 - accuracy: 0.4850 - val_loss: 2.1487 - val_accuracy: 0.4980\n",
      "Epoch 18/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.1098 - accuracy: 0.5097 - val_loss: 2.1049 - val_accuracy: 0.5050\n",
      "Epoch 19/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.0639 - accuracy: 0.5344 - val_loss: 2.0607 - val_accuracy: 0.5360\n",
      "Epoch 20/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.0185 - accuracy: 0.5559 - val_loss: 2.0181 - val_accuracy: 0.5550\n",
      "Epoch 21/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9743 - accuracy: 0.5771 - val_loss: 1.9767 - val_accuracy: 0.5630\n",
      "Epoch 22/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.9311 - accuracy: 0.5959 - val_loss: 1.9348 - val_accuracy: 0.5800\n",
      "Epoch 23/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8897 - accuracy: 0.6103 - val_loss: 1.8954 - val_accuracy: 0.5880\n",
      "Epoch 24/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8496 - accuracy: 0.6231 - val_loss: 1.8561 - val_accuracy: 0.6010\n",
      "Epoch 25/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8110 - accuracy: 0.6363 - val_loss: 1.8192 - val_accuracy: 0.6110\n",
      "Epoch 26/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7736 - accuracy: 0.6501 - val_loss: 1.7835 - val_accuracy: 0.6250\n",
      "Epoch 27/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7381 - accuracy: 0.6587 - val_loss: 1.7498 - val_accuracy: 0.6290\n",
      "Epoch 28/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7039 - accuracy: 0.6694 - val_loss: 1.7188 - val_accuracy: 0.6300\n",
      "Epoch 29/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6717 - accuracy: 0.6786 - val_loss: 1.6887 - val_accuracy: 0.6400\n",
      "Epoch 30/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6415 - accuracy: 0.6869 - val_loss: 1.6601 - val_accuracy: 0.6440\n",
      "Epoch 31/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6124 - accuracy: 0.6927 - val_loss: 1.6334 - val_accuracy: 0.6510\n",
      "Epoch 32/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5854 - accuracy: 0.7016 - val_loss: 1.6085 - val_accuracy: 0.6560\n",
      "Epoch 33/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5597 - accuracy: 0.7080 - val_loss: 1.5857 - val_accuracy: 0.6680\n",
      "Epoch 34/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.5355 - accuracy: 0.7113 - val_loss: 1.5641 - val_accuracy: 0.6700\n",
      "Epoch 35/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.5128 - accuracy: 0.7164 - val_loss: 1.5429 - val_accuracy: 0.6760\n",
      "Epoch 36/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4914 - accuracy: 0.7224 - val_loss: 1.5252 - val_accuracy: 0.6820\n",
      "Epoch 37/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4707 - accuracy: 0.7279 - val_loss: 1.5051 - val_accuracy: 0.6810\n",
      "Epoch 38/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4510 - accuracy: 0.7296 - val_loss: 1.4882 - val_accuracy: 0.6840\n",
      "Epoch 39/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4327 - accuracy: 0.7351 - val_loss: 1.4727 - val_accuracy: 0.6920\n",
      "Epoch 40/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4153 - accuracy: 0.7399 - val_loss: 1.4585 - val_accuracy: 0.6880\n",
      "Epoch 41/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3988 - accuracy: 0.7447 - val_loss: 1.4430 - val_accuracy: 0.6920\n",
      "Epoch 42/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3832 - accuracy: 0.7451 - val_loss: 1.4337 - val_accuracy: 0.6910\n",
      "Epoch 43/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3687 - accuracy: 0.7491 - val_loss: 1.4171 - val_accuracy: 0.7080\n",
      "Epoch 44/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3538 - accuracy: 0.7526 - val_loss: 1.4067 - val_accuracy: 0.7020\n",
      "Epoch 45/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3406 - accuracy: 0.7591 - val_loss: 1.3955 - val_accuracy: 0.7000\n",
      "Epoch 46/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3274 - accuracy: 0.7569 - val_loss: 1.3846 - val_accuracy: 0.7040\n",
      "Epoch 47/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3149 - accuracy: 0.7589 - val_loss: 1.3723 - val_accuracy: 0.7110\n",
      "Epoch 48/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3033 - accuracy: 0.7634 - val_loss: 1.3666 - val_accuracy: 0.7030\n",
      "Epoch 49/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2918 - accuracy: 0.7649 - val_loss: 1.3574 - val_accuracy: 0.7090\n",
      "Epoch 50/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2808 - accuracy: 0.7657 - val_loss: 1.3465 - val_accuracy: 0.7140\n",
      "Epoch 51/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2703 - accuracy: 0.7676 - val_loss: 1.3422 - val_accuracy: 0.7090\n",
      "Epoch 52/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2601 - accuracy: 0.7711 - val_loss: 1.3310 - val_accuracy: 0.7180\n",
      "Epoch 53/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2501 - accuracy: 0.7719 - val_loss: 1.3250 - val_accuracy: 0.7140\n",
      "Epoch 54/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2404 - accuracy: 0.7779 - val_loss: 1.3161 - val_accuracy: 0.7200\n",
      "Epoch 55/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2311 - accuracy: 0.7777 - val_loss: 1.3079 - val_accuracy: 0.7200\n",
      "Epoch 56/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2219 - accuracy: 0.7780 - val_loss: 1.3017 - val_accuracy: 0.7230\n",
      "Epoch 57/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2136 - accuracy: 0.7817 - val_loss: 1.2981 - val_accuracy: 0.7220\n",
      "Epoch 58/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2051 - accuracy: 0.7837 - val_loss: 1.2898 - val_accuracy: 0.7220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1966 - accuracy: 0.7876 - val_loss: 1.2843 - val_accuracy: 0.7210\n",
      "Epoch 60/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1886 - accuracy: 0.7867 - val_loss: 1.2777 - val_accuracy: 0.7270\n",
      "Epoch 61/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1802 - accuracy: 0.7910 - val_loss: 1.2742 - val_accuracy: 0.7200\n",
      "Epoch 62/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1732 - accuracy: 0.7909 - val_loss: 1.2666 - val_accuracy: 0.7250\n",
      "Epoch 63/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1656 - accuracy: 0.7933 - val_loss: 1.2620 - val_accuracy: 0.7280\n",
      "Epoch 64/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1581 - accuracy: 0.7944 - val_loss: 1.2565 - val_accuracy: 0.7240\n",
      "Epoch 65/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1509 - accuracy: 0.7959 - val_loss: 1.2504 - val_accuracy: 0.7310\n",
      "Epoch 66/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1437 - accuracy: 0.7974 - val_loss: 1.2464 - val_accuracy: 0.7330\n",
      "Epoch 67/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1371 - accuracy: 0.8017 - val_loss: 1.2425 - val_accuracy: 0.7360\n",
      "Epoch 68/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1303 - accuracy: 0.8014 - val_loss: 1.2377 - val_accuracy: 0.7290\n",
      "Epoch 69/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1236 - accuracy: 0.8039 - val_loss: 1.2350 - val_accuracy: 0.7400\n",
      "Epoch 70/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1172 - accuracy: 0.8043 - val_loss: 1.2308 - val_accuracy: 0.7310\n",
      "Epoch 71/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1105 - accuracy: 0.8067 - val_loss: 1.2256 - val_accuracy: 0.7300\n",
      "Epoch 72/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1046 - accuracy: 0.8069 - val_loss: 1.2239 - val_accuracy: 0.7330\n",
      "Epoch 73/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0984 - accuracy: 0.8099 - val_loss: 1.2193 - val_accuracy: 0.7310\n",
      "Epoch 74/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0924 - accuracy: 0.8109 - val_loss: 1.2138 - val_accuracy: 0.7340\n",
      "Epoch 75/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0864 - accuracy: 0.8129 - val_loss: 1.2098 - val_accuracy: 0.7290\n",
      "Epoch 76/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0801 - accuracy: 0.8143 - val_loss: 1.2085 - val_accuracy: 0.7430\n",
      "Epoch 77/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0746 - accuracy: 0.8181 - val_loss: 1.2036 - val_accuracy: 0.7370\n",
      "Epoch 78/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0687 - accuracy: 0.8170 - val_loss: 1.1990 - val_accuracy: 0.7450\n",
      "Epoch 79/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0630 - accuracy: 0.8193 - val_loss: 1.1971 - val_accuracy: 0.7310\n",
      "Epoch 80/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0575 - accuracy: 0.8201 - val_loss: 1.1924 - val_accuracy: 0.7390\n",
      "Epoch 81/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0520 - accuracy: 0.8233 - val_loss: 1.1892 - val_accuracy: 0.7400\n",
      "Epoch 82/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0467 - accuracy: 0.8227 - val_loss: 1.1891 - val_accuracy: 0.7430\n",
      "Epoch 83/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0412 - accuracy: 0.8271 - val_loss: 1.1822 - val_accuracy: 0.7410\n",
      "Epoch 84/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0361 - accuracy: 0.8267 - val_loss: 1.1823 - val_accuracy: 0.7400\n",
      "Epoch 85/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0312 - accuracy: 0.8274 - val_loss: 1.1777 - val_accuracy: 0.7430\n",
      "Epoch 86/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0257 - accuracy: 0.8307 - val_loss: 1.1750 - val_accuracy: 0.7430\n",
      "Epoch 87/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0209 - accuracy: 0.8297 - val_loss: 1.1715 - val_accuracy: 0.7500\n",
      "Epoch 88/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0158 - accuracy: 0.8321 - val_loss: 1.1680 - val_accuracy: 0.7470\n",
      "Epoch 89/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0106 - accuracy: 0.8341 - val_loss: 1.1699 - val_accuracy: 0.7420\n",
      "Epoch 90/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0057 - accuracy: 0.8380 - val_loss: 1.1627 - val_accuracy: 0.7480\n",
      "Epoch 91/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0008 - accuracy: 0.8359 - val_loss: 1.1622 - val_accuracy: 0.7470\n",
      "Epoch 92/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9963 - accuracy: 0.8374 - val_loss: 1.1587 - val_accuracy: 0.7500\n",
      "Epoch 93/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9913 - accuracy: 0.8374 - val_loss: 1.1567 - val_accuracy: 0.7540\n",
      "Epoch 94/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9870 - accuracy: 0.8399 - val_loss: 1.1545 - val_accuracy: 0.7480\n",
      "Epoch 95/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9821 - accuracy: 0.8416 - val_loss: 1.1500 - val_accuracy: 0.7550\n",
      "Epoch 96/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9774 - accuracy: 0.8427 - val_loss: 1.1494 - val_accuracy: 0.7560\n",
      "Epoch 97/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9732 - accuracy: 0.8427 - val_loss: 1.1473 - val_accuracy: 0.7490\n",
      "Epoch 98/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9682 - accuracy: 0.8459 - val_loss: 1.1445 - val_accuracy: 0.7480\n",
      "Epoch 99/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9639 - accuracy: 0.8453 - val_loss: 1.1404 - val_accuracy: 0.7520\n",
      "Epoch 100/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9595 - accuracy: 0.8469 - val_loss: 1.1386 - val_accuracy: 0.7590\n",
      "Epoch 101/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9551 - accuracy: 0.8496 - val_loss: 1.1386 - val_accuracy: 0.7520\n",
      "Epoch 102/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9507 - accuracy: 0.8501 - val_loss: 1.1374 - val_accuracy: 0.7540\n",
      "Epoch 103/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9466 - accuracy: 0.8524 - val_loss: 1.1332 - val_accuracy: 0.7600\n",
      "Epoch 104/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9423 - accuracy: 0.8531 - val_loss: 1.1326 - val_accuracy: 0.7600\n",
      "Epoch 105/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9384 - accuracy: 0.8550 - val_loss: 1.1284 - val_accuracy: 0.7630\n",
      "Epoch 106/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9338 - accuracy: 0.8531 - val_loss: 1.1287 - val_accuracy: 0.7590\n",
      "Epoch 107/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9300 - accuracy: 0.8571 - val_loss: 1.1258 - val_accuracy: 0.7580\n",
      "Epoch 108/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9254 - accuracy: 0.8581 - val_loss: 1.1256 - val_accuracy: 0.7640\n",
      "Epoch 109/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9216 - accuracy: 0.8591 - val_loss: 1.1218 - val_accuracy: 0.7560\n",
      "Epoch 110/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9172 - accuracy: 0.8594 - val_loss: 1.1207 - val_accuracy: 0.7660\n",
      "Epoch 111/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9135 - accuracy: 0.8600 - val_loss: 1.1175 - val_accuracy: 0.7660\n",
      "Epoch 112/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9096 - accuracy: 0.8629 - val_loss: 1.1169 - val_accuracy: 0.7610\n",
      "Epoch 113/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9056 - accuracy: 0.8614 - val_loss: 1.1176 - val_accuracy: 0.7660\n",
      "Epoch 114/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9022 - accuracy: 0.8647 - val_loss: 1.1126 - val_accuracy: 0.7710\n",
      "Epoch 115/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8983 - accuracy: 0.8670 - val_loss: 1.1117 - val_accuracy: 0.7620\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8947 - accuracy: 0.8663 - val_loss: 1.1103 - val_accuracy: 0.7640\n",
      "Epoch 117/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8907 - accuracy: 0.8704 - val_loss: 1.1071 - val_accuracy: 0.7690\n",
      "Epoch 118/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8866 - accuracy: 0.8716 - val_loss: 1.1067 - val_accuracy: 0.7730\n",
      "Epoch 119/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8830 - accuracy: 0.8736 - val_loss: 1.1032 - val_accuracy: 0.7670\n",
      "Epoch 120/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8796 - accuracy: 0.8726 - val_loss: 1.1023 - val_accuracy: 0.7690\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L2_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_model_dict = L2_model.history\n",
    "L2_model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training accuracy as well as the validation accuracy for both the L2 and the model without regularization (for 120 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "acc_values = L2_model_dict['accuracy'] \n",
    "val_acc_values = L2_model_dict['val_accuracy']\n",
    "model_acc = model_val_dict['accuracy']\n",
    "model_val_acc = model_val_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, model_acc, label='Training acc')\n",
    "ax.plot(epochs, model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at L1 regularization. Will this work better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 16.0503 - accuracy: 0.1519 - val_loss: 15.6761 - val_accuracy: 0.1390\n",
      "Epoch 2/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 15.3395 - accuracy: 0.1586 - val_loss: 14.9793 - val_accuracy: 0.1440\n",
      "Epoch 3/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 14.6555 - accuracy: 0.1646 - val_loss: 14.3065 - val_accuracy: 0.1530\n",
      "Epoch 4/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 13.9927 - accuracy: 0.1723 - val_loss: 13.6540 - val_accuracy: 0.1600\n",
      "Epoch 5/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 13.3484 - accuracy: 0.1799 - val_loss: 13.0193 - val_accuracy: 0.1700\n",
      "Epoch 6/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 12.7216 - accuracy: 0.1919 - val_loss: 12.4021 - val_accuracy: 0.1800\n",
      "Epoch 7/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 12.1126 - accuracy: 0.2051 - val_loss: 11.8022 - val_accuracy: 0.1980\n",
      "Epoch 8/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 11.5206 - accuracy: 0.2256 - val_loss: 11.2189 - val_accuracy: 0.2170\n",
      "Epoch 9/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 10.9454 - accuracy: 0.2449 - val_loss: 10.6527 - val_accuracy: 0.2330\n",
      "Epoch 10/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 10.3876 - accuracy: 0.2677 - val_loss: 10.1039 - val_accuracy: 0.2490\n",
      "Epoch 11/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 9.8468 - accuracy: 0.2934 - val_loss: 9.5728 - val_accuracy: 0.2760\n",
      "Epoch 12/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.3241 - accuracy: 0.3211 - val_loss: 9.0595 - val_accuracy: 0.3140\n",
      "Epoch 13/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.8192 - accuracy: 0.3550 - val_loss: 8.5653 - val_accuracy: 0.3210\n",
      "Epoch 14/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 8.3331 - accuracy: 0.3759 - val_loss: 8.0894 - val_accuracy: 0.3620\n",
      "Epoch 15/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.8654 - accuracy: 0.4080 - val_loss: 7.6313 - val_accuracy: 0.3880\n",
      "Epoch 16/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 7.4163 - accuracy: 0.4389 - val_loss: 7.1927 - val_accuracy: 0.4170\n",
      "Epoch 17/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 6.9859 - accuracy: 0.4601 - val_loss: 6.7724 - val_accuracy: 0.4310\n",
      "Epoch 18/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.5738 - accuracy: 0.4737 - val_loss: 6.3700 - val_accuracy: 0.4530\n",
      "Epoch 19/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.1800 - accuracy: 0.4849 - val_loss: 5.9868 - val_accuracy: 0.4700\n",
      "Epoch 20/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.8056 - accuracy: 0.4983 - val_loss: 5.6224 - val_accuracy: 0.4870\n",
      "Epoch 21/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 5.4495 - accuracy: 0.5063 - val_loss: 5.2767 - val_accuracy: 0.5020\n",
      "Epoch 22/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.1115 - accuracy: 0.5121 - val_loss: 4.9484 - val_accuracy: 0.5120\n",
      "Epoch 23/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.7926 - accuracy: 0.5184 - val_loss: 4.6392 - val_accuracy: 0.5150\n",
      "Epoch 24/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.4926 - accuracy: 0.5216 - val_loss: 4.3498 - val_accuracy: 0.5180\n",
      "Epoch 25/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.2116 - accuracy: 0.5221 - val_loss: 4.0783 - val_accuracy: 0.5220\n",
      "Epoch 26/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 3.9501 - accuracy: 0.5239 - val_loss: 3.8270 - val_accuracy: 0.5210\n",
      "Epoch 27/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3.7076 - accuracy: 0.5241 - val_loss: 3.5951 - val_accuracy: 0.5050\n",
      "Epoch 28/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3.4842 - accuracy: 0.5180 - val_loss: 3.3809 - val_accuracy: 0.5090\n",
      "Epoch 29/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3.2799 - accuracy: 0.5199 - val_loss: 3.1872 - val_accuracy: 0.5360\n",
      "Epoch 30/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3.0946 - accuracy: 0.5223 - val_loss: 3.0103 - val_accuracy: 0.5330\n",
      "Epoch 31/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.9275 - accuracy: 0.5253 - val_loss: 2.8533 - val_accuracy: 0.5420\n",
      "Epoch 32/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.7786 - accuracy: 0.5297 - val_loss: 2.7126 - val_accuracy: 0.5260\n",
      "Epoch 33/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.6475 - accuracy: 0.5296 - val_loss: 2.5902 - val_accuracy: 0.5440\n",
      "Epoch 34/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.5332 - accuracy: 0.5337 - val_loss: 2.4853 - val_accuracy: 0.5500\n",
      "Epoch 35/120\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.4574 - accuracy: 0.53 - 0s 4ms/step - loss: 2.4367 - accuracy: 0.5377 - val_loss: 2.3991 - val_accuracy: 0.5470\n",
      "Epoch 36/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.3569 - accuracy: 0.5377 - val_loss: 2.3273 - val_accuracy: 0.5560\n",
      "Epoch 37/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.2929 - accuracy: 0.5497 - val_loss: 2.2704 - val_accuracy: 0.5550\n",
      "Epoch 38/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.2431 - accuracy: 0.5521 - val_loss: 2.2254 - val_accuracy: 0.5630\n",
      "Epoch 39/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.2057 - accuracy: 0.5613 - val_loss: 2.1919 - val_accuracy: 0.5680\n",
      "Epoch 40/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.1761 - accuracy: 0.5667 - val_loss: 2.1651 - val_accuracy: 0.5770\n",
      "Epoch 41/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.1507 - accuracy: 0.5746 - val_loss: 2.1418 - val_accuracy: 0.5820\n",
      "Epoch 42/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.1278 - accuracy: 0.5789 - val_loss: 2.1197 - val_accuracy: 0.5790\n",
      "Epoch 43/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.1065 - accuracy: 0.5876 - val_loss: 2.0987 - val_accuracy: 0.5850\n",
      "Epoch 44/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.0863 - accuracy: 0.5954 - val_loss: 2.0791 - val_accuracy: 0.5970\n",
      "Epoch 45/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.0668 - accuracy: 0.5999 - val_loss: 2.0620 - val_accuracy: 0.5980\n",
      "Epoch 46/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.0487 - accuracy: 0.6044 - val_loss: 2.0441 - val_accuracy: 0.6010\n",
      "Epoch 47/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.0311 - accuracy: 0.6131 - val_loss: 2.0264 - val_accuracy: 0.6060\n",
      "Epoch 48/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.0143 - accuracy: 0.6189 - val_loss: 2.0104 - val_accuracy: 0.6040\n",
      "Epoch 49/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.9982 - accuracy: 0.6190 - val_loss: 1.9930 - val_accuracy: 0.6180\n",
      "Epoch 50/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.9817 - accuracy: 0.6279 - val_loss: 1.9785 - val_accuracy: 0.6190\n",
      "Epoch 51/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9663 - accuracy: 0.6299 - val_loss: 1.9632 - val_accuracy: 0.6250\n",
      "Epoch 52/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9517 - accuracy: 0.6343 - val_loss: 1.9490 - val_accuracy: 0.6230\n",
      "Epoch 53/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9370 - accuracy: 0.6404 - val_loss: 1.9380 - val_accuracy: 0.6330\n",
      "Epoch 54/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9223 - accuracy: 0.6421 - val_loss: 1.9210 - val_accuracy: 0.6360\n",
      "Epoch 55/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9090 - accuracy: 0.6430 - val_loss: 1.9124 - val_accuracy: 0.6310\n",
      "Epoch 56/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8955 - accuracy: 0.6441 - val_loss: 1.8941 - val_accuracy: 0.6390\n",
      "Epoch 57/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8822 - accuracy: 0.6489 - val_loss: 1.8813 - val_accuracy: 0.6410\n",
      "Epoch 58/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8693 - accuracy: 0.6500 - val_loss: 1.8734 - val_accuracy: 0.6400\n",
      "Epoch 59/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8568 - accuracy: 0.6537 - val_loss: 1.8599 - val_accuracy: 0.6370\n",
      "Epoch 60/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8447 - accuracy: 0.6551 - val_loss: 1.8463 - val_accuracy: 0.6420\n",
      "Epoch 61/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8320 - accuracy: 0.6584 - val_loss: 1.8336 - val_accuracy: 0.6420\n",
      "Epoch 62/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8207 - accuracy: 0.6571 - val_loss: 1.8232 - val_accuracy: 0.6470\n",
      "Epoch 63/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8086 - accuracy: 0.6601 - val_loss: 1.8114 - val_accuracy: 0.6420\n",
      "Epoch 64/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7973 - accuracy: 0.6627 - val_loss: 1.8008 - val_accuracy: 0.6410\n",
      "Epoch 65/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7861 - accuracy: 0.6639 - val_loss: 1.7909 - val_accuracy: 0.6480\n",
      "Epoch 66/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7754 - accuracy: 0.6674 - val_loss: 1.7794 - val_accuracy: 0.6480\n",
      "Epoch 67/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7642 - accuracy: 0.6684 - val_loss: 1.7692 - val_accuracy: 0.6470\n",
      "Epoch 68/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.7536 - accuracy: 0.6693 - val_loss: 1.7575 - val_accuracy: 0.6490\n",
      "Epoch 69/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.7436 - accuracy: 0.6711 - val_loss: 1.7489 - val_accuracy: 0.6560\n",
      "Epoch 70/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.7331 - accuracy: 0.6733 - val_loss: 1.7431 - val_accuracy: 0.6550\n",
      "Epoch 71/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7232 - accuracy: 0.6747 - val_loss: 1.7336 - val_accuracy: 0.6550\n",
      "Epoch 72/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7137 - accuracy: 0.6747 - val_loss: 1.7222 - val_accuracy: 0.6570\n",
      "Epoch 73/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7039 - accuracy: 0.6764 - val_loss: 1.7098 - val_accuracy: 0.6520\n",
      "Epoch 74/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6942 - accuracy: 0.6770 - val_loss: 1.7019 - val_accuracy: 0.6510\n",
      "Epoch 75/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6850 - accuracy: 0.6781 - val_loss: 1.6928 - val_accuracy: 0.6580\n",
      "Epoch 76/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6755 - accuracy: 0.6791 - val_loss: 1.6867 - val_accuracy: 0.6560\n",
      "Epoch 77/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6667 - accuracy: 0.6804 - val_loss: 1.6765 - val_accuracy: 0.6520\n",
      "Epoch 78/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6579 - accuracy: 0.6813 - val_loss: 1.6676 - val_accuracy: 0.6560\n",
      "Epoch 79/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6494 - accuracy: 0.6813 - val_loss: 1.6620 - val_accuracy: 0.6620\n",
      "Epoch 80/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6407 - accuracy: 0.6821 - val_loss: 1.6509 - val_accuracy: 0.6570\n",
      "Epoch 81/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6322 - accuracy: 0.6827 - val_loss: 1.6451 - val_accuracy: 0.6640\n",
      "Epoch 82/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6242 - accuracy: 0.6823 - val_loss: 1.6408 - val_accuracy: 0.6650\n",
      "Epoch 83/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6160 - accuracy: 0.6849 - val_loss: 1.6273 - val_accuracy: 0.6600\n",
      "Epoch 84/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6082 - accuracy: 0.6844 - val_loss: 1.6218 - val_accuracy: 0.6630\n",
      "Epoch 85/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5999 - accuracy: 0.6846 - val_loss: 1.6115 - val_accuracy: 0.6640\n",
      "Epoch 86/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5920 - accuracy: 0.6864 - val_loss: 1.6054 - val_accuracy: 0.6680\n",
      "Epoch 87/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5839 - accuracy: 0.6860 - val_loss: 1.5981 - val_accuracy: 0.6660\n",
      "Epoch 88/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5765 - accuracy: 0.6880 - val_loss: 1.5902 - val_accuracy: 0.6700\n",
      "Epoch 89/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5694 - accuracy: 0.6877 - val_loss: 1.5809 - val_accuracy: 0.6690\n",
      "Epoch 90/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5619 - accuracy: 0.6901 - val_loss: 1.5772 - val_accuracy: 0.6680\n",
      "Epoch 91/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.5550 - accuracy: 0.6896 - val_loss: 1.5697 - val_accuracy: 0.6680\n",
      "Epoch 92/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.5473 - accuracy: 0.6904 - val_loss: 1.5702 - val_accuracy: 0.6700\n",
      "Epoch 93/120\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.5408 - accuracy: 0.6907 - val_loss: 1.5577 - val_accuracy: 0.6730\n",
      "Epoch 94/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5338 - accuracy: 0.6924 - val_loss: 1.5509 - val_accuracy: 0.6770\n",
      "Epoch 95/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5270 - accuracy: 0.6933 - val_loss: 1.5442 - val_accuracy: 0.6660\n",
      "Epoch 96/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5196 - accuracy: 0.6931 - val_loss: 1.5379 - val_accuracy: 0.6700\n",
      "Epoch 97/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5134 - accuracy: 0.6949 - val_loss: 1.5310 - val_accuracy: 0.6720\n",
      "Epoch 98/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5066 - accuracy: 0.6946 - val_loss: 1.5244 - val_accuracy: 0.6720\n",
      "Epoch 99/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4996 - accuracy: 0.6934 - val_loss: 1.5188 - val_accuracy: 0.6730\n",
      "Epoch 100/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4940 - accuracy: 0.6967 - val_loss: 1.5119 - val_accuracy: 0.6730\n",
      "Epoch 101/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4873 - accuracy: 0.6953 - val_loss: 1.5069 - val_accuracy: 0.6760\n",
      "Epoch 102/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4814 - accuracy: 0.6966 - val_loss: 1.5012 - val_accuracy: 0.6790\n",
      "Epoch 103/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4750 - accuracy: 0.6966 - val_loss: 1.4972 - val_accuracy: 0.6770\n",
      "Epoch 104/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4693 - accuracy: 0.6986 - val_loss: 1.4886 - val_accuracy: 0.6730\n",
      "Epoch 105/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4629 - accuracy: 0.6983 - val_loss: 1.4843 - val_accuracy: 0.6720\n",
      "Epoch 106/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4570 - accuracy: 0.6986 - val_loss: 1.4769 - val_accuracy: 0.6710\n",
      "Epoch 107/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4509 - accuracy: 0.6984 - val_loss: 1.4733 - val_accuracy: 0.6730\n",
      "Epoch 108/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4454 - accuracy: 0.6990 - val_loss: 1.4706 - val_accuracy: 0.6790\n",
      "Epoch 109/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4395 - accuracy: 0.6996 - val_loss: 1.4610 - val_accuracy: 0.6740\n",
      "Epoch 110/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4344 - accuracy: 0.6999 - val_loss: 1.4559 - val_accuracy: 0.6730\n",
      "Epoch 111/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4284 - accuracy: 0.7011 - val_loss: 1.4506 - val_accuracy: 0.6720\n",
      "Epoch 112/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4226 - accuracy: 0.7007 - val_loss: 1.4481 - val_accuracy: 0.6770\n",
      "Epoch 113/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4171 - accuracy: 0.7014 - val_loss: 1.4405 - val_accuracy: 0.6750\n",
      "Epoch 114/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4118 - accuracy: 0.7020 - val_loss: 1.4356 - val_accuracy: 0.6750\n",
      "Epoch 115/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4062 - accuracy: 0.7021 - val_loss: 1.4346 - val_accuracy: 0.6730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4012 - accuracy: 0.7033 - val_loss: 1.4282 - val_accuracy: 0.6720\n",
      "Epoch 117/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3962 - accuracy: 0.7021 - val_loss: 1.4204 - val_accuracy: 0.6770\n",
      "Epoch 118/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3911 - accuracy: 0.7043 - val_loss: 1.4175 - val_accuracy: 0.6720\n",
      "Epoch 119/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3856 - accuracy: 0.7044 - val_loss: 1.4157 - val_accuracy: 0.6770\n",
      "Epoch 120/120\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3807 - accuracy: 0.7063 - val_loss: 1.4080 - val_accuracy: 0.6760\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy doesn't reach rates much higher than 70%. It does seem like you can still improve the model by training much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 16.0344 - accuracy: 0.1733 - val_loss: 15.6523 - val_accuracy: 0.1900\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 15.3170 - accuracy: 0.2073 - val_loss: 14.9512 - val_accuracy: 0.2130\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 14.6250 - accuracy: 0.2289 - val_loss: 14.2702 - val_accuracy: 0.2320\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 13.9510 - accuracy: 0.2410 - val_loss: 13.6052 - val_accuracy: 0.2440\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 13.2924 - accuracy: 0.2547 - val_loss: 12.9550 - val_accuracy: 0.2670\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 12.6488 - accuracy: 0.2856 - val_loss: 12.3214 - val_accuracy: 0.2820\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 12.0227 - accuracy: 0.3121 - val_loss: 11.7065 - val_accuracy: 0.3190\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 11.4151 - accuracy: 0.3437 - val_loss: 11.1100 - val_accuracy: 0.3500\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 10.8264 - accuracy: 0.3743 - val_loss: 10.5318 - val_accuracy: 0.3700\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 10.2565 - accuracy: 0.4029 - val_loss: 9.9730 - val_accuracy: 0.3940\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 9.7058 - accuracy: 0.4304 - val_loss: 9.4334 - val_accuracy: 0.4310\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 9.1738 - accuracy: 0.4570 - val_loss: 8.9119 - val_accuracy: 0.4650\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.6602 - accuracy: 0.4880 - val_loss: 8.4094 - val_accuracy: 0.4810\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.1662 - accuracy: 0.5091 - val_loss: 7.9267 - val_accuracy: 0.5140\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.6920 - accuracy: 0.5334 - val_loss: 7.4629 - val_accuracy: 0.5250\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 7.2379 - accuracy: 0.5524 - val_loss: 7.0191 - val_accuracy: 0.5550\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.8035 - accuracy: 0.5721 - val_loss: 6.5952 - val_accuracy: 0.5700\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 6.3887 - accuracy: 0.5884 - val_loss: 6.1914 - val_accuracy: 0.5890\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.9938 - accuracy: 0.6029 - val_loss: 5.8072 - val_accuracy: 0.6040\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.6192 - accuracy: 0.6193 - val_loss: 5.4444 - val_accuracy: 0.6110\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.2644 - accuracy: 0.6284 - val_loss: 5.0974 - val_accuracy: 0.6140\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.9285 - accuracy: 0.6407 - val_loss: 4.7726 - val_accuracy: 0.6240\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.6117 - accuracy: 0.6489 - val_loss: 4.4663 - val_accuracy: 0.6350\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.3148 - accuracy: 0.6563 - val_loss: 4.1787 - val_accuracy: 0.6380\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.0374 - accuracy: 0.6611 - val_loss: 3.9112 - val_accuracy: 0.6490\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3.7794 - accuracy: 0.6657 - val_loss: 3.6627 - val_accuracy: 0.6620\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3.5407 - accuracy: 0.6681 - val_loss: 3.4348 - val_accuracy: 0.6600\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3.3213 - accuracy: 0.6767 - val_loss: 3.2250 - val_accuracy: 0.6630\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 3.1208 - accuracy: 0.6780 - val_loss: 3.0353 - val_accuracy: 0.6630\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.9397 - accuracy: 0.6824 - val_loss: 2.8627 - val_accuracy: 0.6650\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.7770 - accuracy: 0.6817 - val_loss: 2.7103 - val_accuracy: 0.6650\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.6328 - accuracy: 0.6871 - val_loss: 2.5757 - val_accuracy: 0.6660\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.5065 - accuracy: 0.6874 - val_loss: 2.4577 - val_accuracy: 0.6690\n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.3978 - accuracy: 0.6890 - val_loss: 2.3571 - val_accuracy: 0.6660\n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.3053 - accuracy: 0.6867 - val_loss: 2.2731 - val_accuracy: 0.6670\n",
      "Epoch 36/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.2291 - accuracy: 0.6887 - val_loss: 2.2044 - val_accuracy: 0.6650\n",
      "Epoch 37/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.1679 - accuracy: 0.6884 - val_loss: 2.1511 - val_accuracy: 0.6670\n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.1200 - accuracy: 0.6894 - val_loss: 2.1099 - val_accuracy: 0.6760\n",
      "Epoch 39/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.0841 - accuracy: 0.6894 - val_loss: 2.0777 - val_accuracy: 0.6660\n",
      "Epoch 40/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.0561 - accuracy: 0.6894 - val_loss: 2.0558 - val_accuracy: 0.6670\n",
      "Epoch 41/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.0324 - accuracy: 0.6867 - val_loss: 2.0297 - val_accuracy: 0.6660\n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.0110 - accuracy: 0.6884 - val_loss: 2.0104 - val_accuracy: 0.6670\n",
      "Epoch 43/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9917 - accuracy: 0.6887 - val_loss: 1.9907 - val_accuracy: 0.6670\n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9737 - accuracy: 0.6874 - val_loss: 1.9731 - val_accuracy: 0.6660\n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9562 - accuracy: 0.6870 - val_loss: 1.9566 - val_accuracy: 0.6680\n",
      "Epoch 46/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9399 - accuracy: 0.6874 - val_loss: 1.9419 - val_accuracy: 0.6660\n",
      "Epoch 47/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9242 - accuracy: 0.6883 - val_loss: 1.9242 - val_accuracy: 0.6630\n",
      "Epoch 48/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9096 - accuracy: 0.6893 - val_loss: 1.9103 - val_accuracy: 0.6680\n",
      "Epoch 49/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8955 - accuracy: 0.6893 - val_loss: 1.8972 - val_accuracy: 0.6690\n",
      "Epoch 50/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8811 - accuracy: 0.6909 - val_loss: 1.8827 - val_accuracy: 0.6670\n",
      "Epoch 51/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8675 - accuracy: 0.6913 - val_loss: 1.8686 - val_accuracy: 0.6660\n",
      "Epoch 52/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8544 - accuracy: 0.6931 - val_loss: 1.8574 - val_accuracy: 0.6750\n",
      "Epoch 53/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8421 - accuracy: 0.6930 - val_loss: 1.8465 - val_accuracy: 0.6730\n",
      "Epoch 54/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.8293 - accuracy: 0.6940 - val_loss: 1.8342 - val_accuracy: 0.6690\n",
      "Epoch 55/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8175 - accuracy: 0.6939 - val_loss: 1.8243 - val_accuracy: 0.6630\n",
      "Epoch 56/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8059 - accuracy: 0.6946 - val_loss: 1.8080 - val_accuracy: 0.6660\n",
      "Epoch 57/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7946 - accuracy: 0.6954 - val_loss: 1.8018 - val_accuracy: 0.6720\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7835 - accuracy: 0.6944 - val_loss: 1.7870 - val_accuracy: 0.6690\n",
      "Epoch 59/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7724 - accuracy: 0.6959 - val_loss: 1.7766 - val_accuracy: 0.6770\n",
      "Epoch 60/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7617 - accuracy: 0.6967 - val_loss: 1.7689 - val_accuracy: 0.6640\n",
      "Epoch 61/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7516 - accuracy: 0.6983 - val_loss: 1.7597 - val_accuracy: 0.6660\n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7418 - accuracy: 0.6964 - val_loss: 1.7495 - val_accuracy: 0.6690\n",
      "Epoch 63/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7317 - accuracy: 0.6979 - val_loss: 1.7370 - val_accuracy: 0.6760\n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7223 - accuracy: 0.6973 - val_loss: 1.7271 - val_accuracy: 0.6710\n",
      "Epoch 65/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7124 - accuracy: 0.6990 - val_loss: 1.7179 - val_accuracy: 0.6730\n",
      "Epoch 66/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7026 - accuracy: 0.6993 - val_loss: 1.7109 - val_accuracy: 0.6740\n",
      "Epoch 67/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6935 - accuracy: 0.6984 - val_loss: 1.7009 - val_accuracy: 0.6770\n",
      "Epoch 68/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6849 - accuracy: 0.6991 - val_loss: 1.6951 - val_accuracy: 0.6680\n",
      "Epoch 69/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6756 - accuracy: 0.7000 - val_loss: 1.6821 - val_accuracy: 0.6710\n",
      "Epoch 70/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6675 - accuracy: 0.6989 - val_loss: 1.6744 - val_accuracy: 0.6690\n",
      "Epoch 71/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6585 - accuracy: 0.7029 - val_loss: 1.6670 - val_accuracy: 0.6750\n",
      "Epoch 72/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6502 - accuracy: 0.7013 - val_loss: 1.6631 - val_accuracy: 0.6680\n",
      "Epoch 73/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6425 - accuracy: 0.7013 - val_loss: 1.6507 - val_accuracy: 0.6720\n",
      "Epoch 74/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6340 - accuracy: 0.7017 - val_loss: 1.6437 - val_accuracy: 0.6740\n",
      "Epoch 75/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6260 - accuracy: 0.7029 - val_loss: 1.6365 - val_accuracy: 0.6730\n",
      "Epoch 76/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6183 - accuracy: 0.7016 - val_loss: 1.6331 - val_accuracy: 0.6750\n",
      "Epoch 77/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6110 - accuracy: 0.7037 - val_loss: 1.6223 - val_accuracy: 0.6750\n",
      "Epoch 78/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6033 - accuracy: 0.7034 - val_loss: 1.6162 - val_accuracy: 0.6760\n",
      "Epoch 79/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5954 - accuracy: 0.7041 - val_loss: 1.6085 - val_accuracy: 0.6730\n",
      "Epoch 80/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5883 - accuracy: 0.7027 - val_loss: 1.5996 - val_accuracy: 0.6770\n",
      "Epoch 81/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5812 - accuracy: 0.7043 - val_loss: 1.5917 - val_accuracy: 0.6760\n",
      "Epoch 82/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5744 - accuracy: 0.7046 - val_loss: 1.5860 - val_accuracy: 0.6760\n",
      "Epoch 83/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5670 - accuracy: 0.7050 - val_loss: 1.5826 - val_accuracy: 0.6750\n",
      "Epoch 84/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5598 - accuracy: 0.7054 - val_loss: 1.5749 - val_accuracy: 0.6770\n",
      "Epoch 85/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5529 - accuracy: 0.7064 - val_loss: 1.5655 - val_accuracy: 0.6790\n",
      "Epoch 86/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5460 - accuracy: 0.7051 - val_loss: 1.5610 - val_accuracy: 0.6760\n",
      "Epoch 87/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5394 - accuracy: 0.7073 - val_loss: 1.5519 - val_accuracy: 0.6750\n",
      "Epoch 88/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5319 - accuracy: 0.7080 - val_loss: 1.5466 - val_accuracy: 0.6800\n",
      "Epoch 89/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5251 - accuracy: 0.7070 - val_loss: 1.5416 - val_accuracy: 0.6770\n",
      "Epoch 90/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5181 - accuracy: 0.7083 - val_loss: 1.5362 - val_accuracy: 0.6800\n",
      "Epoch 91/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5115 - accuracy: 0.7089 - val_loss: 1.5288 - val_accuracy: 0.6780\n",
      "Epoch 92/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5053 - accuracy: 0.7073 - val_loss: 1.5221 - val_accuracy: 0.6790\n",
      "Epoch 93/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4985 - accuracy: 0.7077 - val_loss: 1.5157 - val_accuracy: 0.6750\n",
      "Epoch 94/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4920 - accuracy: 0.7104 - val_loss: 1.5092 - val_accuracy: 0.6800\n",
      "Epoch 95/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4858 - accuracy: 0.7100 - val_loss: 1.5020 - val_accuracy: 0.6800\n",
      "Epoch 96/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4789 - accuracy: 0.7099 - val_loss: 1.4980 - val_accuracy: 0.6780\n",
      "Epoch 97/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4731 - accuracy: 0.7110 - val_loss: 1.4936 - val_accuracy: 0.6830\n",
      "Epoch 98/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4673 - accuracy: 0.7119 - val_loss: 1.4852 - val_accuracy: 0.6850\n",
      "Epoch 99/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4609 - accuracy: 0.7120 - val_loss: 1.4802 - val_accuracy: 0.6810\n",
      "Epoch 100/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4546 - accuracy: 0.7133 - val_loss: 1.4778 - val_accuracy: 0.6840\n",
      "Epoch 101/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4497 - accuracy: 0.7120 - val_loss: 1.4709 - val_accuracy: 0.6830\n",
      "Epoch 102/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4432 - accuracy: 0.7136 - val_loss: 1.4728 - val_accuracy: 0.6780\n",
      "Epoch 103/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4373 - accuracy: 0.7136 - val_loss: 1.4579 - val_accuracy: 0.6870\n",
      "Epoch 104/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4314 - accuracy: 0.7124 - val_loss: 1.4536 - val_accuracy: 0.6870\n",
      "Epoch 105/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4260 - accuracy: 0.7123 - val_loss: 1.4460 - val_accuracy: 0.6870\n",
      "Epoch 106/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4199 - accuracy: 0.7143 - val_loss: 1.4415 - val_accuracy: 0.6870\n",
      "Epoch 107/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4145 - accuracy: 0.7157 - val_loss: 1.4398 - val_accuracy: 0.6880\n",
      "Epoch 108/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4094 - accuracy: 0.7141 - val_loss: 1.4335 - val_accuracy: 0.6850\n",
      "Epoch 109/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4038 - accuracy: 0.7144 - val_loss: 1.4292 - val_accuracy: 0.6900\n",
      "Epoch 110/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3988 - accuracy: 0.7151 - val_loss: 1.4219 - val_accuracy: 0.6880\n",
      "Epoch 111/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.7163 - val_loss: 1.4160 - val_accuracy: 0.6910\n",
      "Epoch 112/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3876 - accuracy: 0.7159 - val_loss: 1.4171 - val_accuracy: 0.6870\n",
      "Epoch 113/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3826 - accuracy: 0.7157 - val_loss: 1.4101 - val_accuracy: 0.6870\n",
      "Epoch 114/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3775 - accuracy: 0.7156 - val_loss: 1.4014 - val_accuracy: 0.6890\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3724 - accuracy: 0.7181 - val_loss: 1.4016 - val_accuracy: 0.6900\n",
      "Epoch 116/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3676 - accuracy: 0.7190 - val_loss: 1.3942 - val_accuracy: 0.6930\n",
      "Epoch 117/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3623 - accuracy: 0.7183 - val_loss: 1.3922 - val_accuracy: 0.6910\n",
      "Epoch 118/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3576 - accuracy: 0.7189 - val_loss: 1.3824 - val_accuracy: 0.6950\n",
      "Epoch 119/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3527 - accuracy: 0.7186 - val_loss: 1.3795 - val_accuracy: 0.6920\n",
      "Epoch 120/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3480 - accuracy: 0.7199 - val_loss: 1.3745 - val_accuracy: 0.6890\n",
      "Epoch 121/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3428 - accuracy: 0.7204 - val_loss: 1.3730 - val_accuracy: 0.6910\n",
      "Epoch 122/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3382 - accuracy: 0.7200 - val_loss: 1.3651 - val_accuracy: 0.6910\n",
      "Epoch 123/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3332 - accuracy: 0.7211 - val_loss: 1.3605 - val_accuracy: 0.6910\n",
      "Epoch 124/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3289 - accuracy: 0.7211 - val_loss: 1.3557 - val_accuracy: 0.6930\n",
      "Epoch 125/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3245 - accuracy: 0.7199 - val_loss: 1.3539 - val_accuracy: 0.6920\n",
      "Epoch 126/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3198 - accuracy: 0.7206 - val_loss: 1.3538 - val_accuracy: 0.6890\n",
      "Epoch 127/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3151 - accuracy: 0.7226 - val_loss: 1.3419 - val_accuracy: 0.6920\n",
      "Epoch 128/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3106 - accuracy: 0.7221 - val_loss: 1.3417 - val_accuracy: 0.6920\n",
      "Epoch 129/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3063 - accuracy: 0.7236 - val_loss: 1.3355 - val_accuracy: 0.6900\n",
      "Epoch 130/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.3016 - accuracy: 0.7237 - val_loss: 1.3348 - val_accuracy: 0.6940\n",
      "Epoch 131/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2979 - accuracy: 0.7239 - val_loss: 1.3286 - val_accuracy: 0.6890\n",
      "Epoch 132/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2933 - accuracy: 0.7246 - val_loss: 1.3290 - val_accuracy: 0.7000\n",
      "Epoch 133/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2896 - accuracy: 0.7254 - val_loss: 1.3223 - val_accuracy: 0.6880\n",
      "Epoch 134/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2849 - accuracy: 0.7239 - val_loss: 1.3175 - val_accuracy: 0.6980\n",
      "Epoch 135/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2811 - accuracy: 0.7251 - val_loss: 1.3148 - val_accuracy: 0.6950\n",
      "Epoch 136/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2768 - accuracy: 0.7257 - val_loss: 1.3076 - val_accuracy: 0.6970\n",
      "Epoch 137/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2724 - accuracy: 0.7261 - val_loss: 1.3058 - val_accuracy: 0.6950\n",
      "Epoch 138/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2688 - accuracy: 0.7253 - val_loss: 1.3017 - val_accuracy: 0.6940\n",
      "Epoch 139/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2648 - accuracy: 0.7244 - val_loss: 1.2967 - val_accuracy: 0.6940\n",
      "Epoch 140/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2611 - accuracy: 0.7250 - val_loss: 1.2932 - val_accuracy: 0.6940\n",
      "Epoch 141/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2560 - accuracy: 0.7279 - val_loss: 1.2941 - val_accuracy: 0.6920\n",
      "Epoch 142/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2532 - accuracy: 0.7263 - val_loss: 1.2909 - val_accuracy: 0.6870\n",
      "Epoch 143/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2490 - accuracy: 0.7263 - val_loss: 1.2823 - val_accuracy: 0.6930\n",
      "Epoch 144/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2452 - accuracy: 0.7284 - val_loss: 1.2792 - val_accuracy: 0.6990\n",
      "Epoch 145/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2419 - accuracy: 0.7299 - val_loss: 1.2774 - val_accuracy: 0.6960\n",
      "Epoch 146/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2383 - accuracy: 0.7277 - val_loss: 1.2726 - val_accuracy: 0.6980\n",
      "Epoch 147/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2342 - accuracy: 0.7290 - val_loss: 1.2708 - val_accuracy: 0.7020\n",
      "Epoch 148/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2309 - accuracy: 0.7300 - val_loss: 1.2659 - val_accuracy: 0.6980\n",
      "Epoch 149/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2272 - accuracy: 0.7309 - val_loss: 1.2612 - val_accuracy: 0.6960\n",
      "Epoch 150/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2236 - accuracy: 0.7309 - val_loss: 1.2626 - val_accuracy: 0.6890\n",
      "Epoch 151/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2197 - accuracy: 0.7330 - val_loss: 1.2560 - val_accuracy: 0.7010\n",
      "Epoch 152/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2170 - accuracy: 0.7304 - val_loss: 1.2532 - val_accuracy: 0.7000\n",
      "Epoch 153/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2127 - accuracy: 0.7320 - val_loss: 1.2552 - val_accuracy: 0.6880\n",
      "Epoch 154/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2100 - accuracy: 0.7327 - val_loss: 1.2495 - val_accuracy: 0.7010\n",
      "Epoch 155/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2071 - accuracy: 0.7311 - val_loss: 1.2442 - val_accuracy: 0.6950\n",
      "Epoch 156/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2031 - accuracy: 0.7313 - val_loss: 1.2471 - val_accuracy: 0.6890\n",
      "Epoch 157/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.2006 - accuracy: 0.7299 - val_loss: 1.2434 - val_accuracy: 0.6920\n",
      "Epoch 158/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1972 - accuracy: 0.7327 - val_loss: 1.2403 - val_accuracy: 0.6890\n",
      "Epoch 159/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1936 - accuracy: 0.7314 - val_loss: 1.2330 - val_accuracy: 0.7030\n",
      "Epoch 160/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1912 - accuracy: 0.7333 - val_loss: 1.2299 - val_accuracy: 0.7030\n",
      "Epoch 161/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1884 - accuracy: 0.7320 - val_loss: 1.2295 - val_accuracy: 0.6970\n",
      "Epoch 162/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1855 - accuracy: 0.7344 - val_loss: 1.2290 - val_accuracy: 0.6930\n",
      "Epoch 163/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1823 - accuracy: 0.7341 - val_loss: 1.2212 - val_accuracy: 0.7030\n",
      "Epoch 164/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1787 - accuracy: 0.7337 - val_loss: 1.2232 - val_accuracy: 0.7060\n",
      "Epoch 165/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1774 - accuracy: 0.7329 - val_loss: 1.2196 - val_accuracy: 0.6980\n",
      "Epoch 166/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1730 - accuracy: 0.7349 - val_loss: 1.2158 - val_accuracy: 0.6970\n",
      "Epoch 167/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1707 - accuracy: 0.7364 - val_loss: 1.2128 - val_accuracy: 0.6980\n",
      "Epoch 168/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1685 - accuracy: 0.7369 - val_loss: 1.2163 - val_accuracy: 0.6910\n",
      "Epoch 169/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1649 - accuracy: 0.7367 - val_loss: 1.2110 - val_accuracy: 0.7020\n",
      "Epoch 170/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1626 - accuracy: 0.7353 - val_loss: 1.2081 - val_accuracy: 0.7020\n",
      "Epoch 171/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1602 - accuracy: 0.7350 - val_loss: 1.2033 - val_accuracy: 0.6960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1570 - accuracy: 0.7379 - val_loss: 1.1982 - val_accuracy: 0.7020\n",
      "Epoch 173/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1543 - accuracy: 0.7377 - val_loss: 1.2077 - val_accuracy: 0.6940\n",
      "Epoch 174/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1521 - accuracy: 0.7361 - val_loss: 1.2022 - val_accuracy: 0.6940\n",
      "Epoch 175/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1496 - accuracy: 0.7374 - val_loss: 1.1964 - val_accuracy: 0.6990\n",
      "Epoch 176/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1469 - accuracy: 0.7386 - val_loss: 1.1941 - val_accuracy: 0.7060\n",
      "Epoch 177/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1444 - accuracy: 0.7377 - val_loss: 1.1901 - val_accuracy: 0.7050\n",
      "Epoch 178/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1415 - accuracy: 0.7386 - val_loss: 1.1931 - val_accuracy: 0.6940\n",
      "Epoch 179/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1394 - accuracy: 0.7389 - val_loss: 1.1878 - val_accuracy: 0.7010\n",
      "Epoch 180/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1371 - accuracy: 0.7379 - val_loss: 1.1845 - val_accuracy: 0.7010\n",
      "Epoch 181/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1349 - accuracy: 0.7400 - val_loss: 1.1872 - val_accuracy: 0.7020\n",
      "Epoch 182/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1325 - accuracy: 0.7400 - val_loss: 1.1856 - val_accuracy: 0.6920\n",
      "Epoch 183/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1303 - accuracy: 0.7407 - val_loss: 1.1773 - val_accuracy: 0.7080\n",
      "Epoch 184/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1282 - accuracy: 0.7384 - val_loss: 1.1754 - val_accuracy: 0.7000\n",
      "Epoch 185/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1263 - accuracy: 0.7396 - val_loss: 1.1768 - val_accuracy: 0.7020\n",
      "Epoch 186/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1239 - accuracy: 0.7411 - val_loss: 1.1789 - val_accuracy: 0.6970\n",
      "Epoch 187/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1223 - accuracy: 0.7409 - val_loss: 1.1753 - val_accuracy: 0.6950\n",
      "Epoch 188/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1201 - accuracy: 0.7413 - val_loss: 1.1754 - val_accuracy: 0.6970\n",
      "Epoch 189/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1178 - accuracy: 0.7411 - val_loss: 1.1679 - val_accuracy: 0.7050\n",
      "Epoch 190/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1159 - accuracy: 0.7400 - val_loss: 1.1698 - val_accuracy: 0.6990\n",
      "Epoch 191/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1138 - accuracy: 0.7430 - val_loss: 1.1644 - val_accuracy: 0.7040\n",
      "Epoch 192/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1121 - accuracy: 0.7419 - val_loss: 1.1645 - val_accuracy: 0.7040\n",
      "Epoch 193/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1103 - accuracy: 0.7416 - val_loss: 1.1612 - val_accuracy: 0.7060\n",
      "Epoch 194/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1083 - accuracy: 0.7430 - val_loss: 1.1602 - val_accuracy: 0.7030\n",
      "Epoch 195/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1067 - accuracy: 0.7426 - val_loss: 1.1640 - val_accuracy: 0.6990\n",
      "Epoch 196/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1049 - accuracy: 0.7436 - val_loss: 1.1575 - val_accuracy: 0.7050\n",
      "Epoch 197/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1033 - accuracy: 0.7431 - val_loss: 1.1575 - val_accuracy: 0.7020\n",
      "Epoch 198/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1008 - accuracy: 0.7430 - val_loss: 1.1539 - val_accuracy: 0.7080\n",
      "Epoch 199/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.7436 - val_loss: 1.1501 - val_accuracy: 0.7060\n",
      "Epoch 200/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0982 - accuracy: 0.7430 - val_loss: 1.1498 - val_accuracy: 0.7080\n",
      "Epoch 201/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0960 - accuracy: 0.7429 - val_loss: 1.1523 - val_accuracy: 0.7020\n",
      "Epoch 202/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0947 - accuracy: 0.7429 - val_loss: 1.1474 - val_accuracy: 0.7040\n",
      "Epoch 203/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0929 - accuracy: 0.7456 - val_loss: 1.1484 - val_accuracy: 0.7060\n",
      "Epoch 204/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0911 - accuracy: 0.7450 - val_loss: 1.1480 - val_accuracy: 0.7070\n",
      "Epoch 205/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0898 - accuracy: 0.7441 - val_loss: 1.1450 - val_accuracy: 0.7070\n",
      "Epoch 206/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0886 - accuracy: 0.7456 - val_loss: 1.1435 - val_accuracy: 0.7080\n",
      "Epoch 207/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0869 - accuracy: 0.7451 - val_loss: 1.1424 - val_accuracy: 0.7030\n",
      "Epoch 208/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0849 - accuracy: 0.7449 - val_loss: 1.1420 - val_accuracy: 0.7060\n",
      "Epoch 209/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0838 - accuracy: 0.7449 - val_loss: 1.1375 - val_accuracy: 0.7120\n",
      "Epoch 210/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0825 - accuracy: 0.7467 - val_loss: 1.1537 - val_accuracy: 0.6940\n",
      "Epoch 211/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0808 - accuracy: 0.7474 - val_loss: 1.1410 - val_accuracy: 0.7000\n",
      "Epoch 212/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0788 - accuracy: 0.7477 - val_loss: 1.1369 - val_accuracy: 0.7130\n",
      "Epoch 213/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0787 - accuracy: 0.7451 - val_loss: 1.1383 - val_accuracy: 0.6980\n",
      "Epoch 214/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0765 - accuracy: 0.7474 - val_loss: 1.1383 - val_accuracy: 0.7000\n",
      "Epoch 215/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0754 - accuracy: 0.7493 - val_loss: 1.1324 - val_accuracy: 0.7030\n",
      "Epoch 216/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.0736 - accuracy: 0.7486 - val_loss: 1.1336 - val_accuracy: 0.7050\n",
      "Epoch 217/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.0729 - accuracy: 0.7480 - val_loss: 1.1330 - val_accuracy: 0.7040\n",
      "Epoch 218/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0714 - accuracy: 0.7484 - val_loss: 1.1306 - val_accuracy: 0.7030\n",
      "Epoch 219/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0703 - accuracy: 0.7497 - val_loss: 1.1314 - val_accuracy: 0.7100\n",
      "Epoch 220/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0685 - accuracy: 0.7487 - val_loss: 1.1293 - val_accuracy: 0.7070\n",
      "Epoch 221/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0670 - accuracy: 0.7477 - val_loss: 1.1322 - val_accuracy: 0.7050\n",
      "Epoch 222/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0658 - accuracy: 0.7463 - val_loss: 1.1243 - val_accuracy: 0.7090\n",
      "Epoch 223/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0641 - accuracy: 0.7484 - val_loss: 1.1229 - val_accuracy: 0.7100\n",
      "Epoch 224/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0629 - accuracy: 0.7506 - val_loss: 1.1221 - val_accuracy: 0.7080\n",
      "Epoch 225/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0628 - accuracy: 0.7473 - val_loss: 1.1234 - val_accuracy: 0.7000\n",
      "Epoch 226/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0611 - accuracy: 0.7493 - val_loss: 1.1393 - val_accuracy: 0.6980\n",
      "Epoch 227/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0605 - accuracy: 0.7474 - val_loss: 1.1275 - val_accuracy: 0.7000\n",
      "Epoch 228/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0581 - accuracy: 0.7511 - val_loss: 1.1180 - val_accuracy: 0.7080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0578 - accuracy: 0.7483 - val_loss: 1.1219 - val_accuracy: 0.7060\n",
      "Epoch 230/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0644 - accuracy: 0.74 - 0s 4ms/step - loss: 1.0557 - accuracy: 0.7506 - val_loss: 1.1162 - val_accuracy: 0.7120\n",
      "Epoch 231/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0544 - accuracy: 0.7516 - val_loss: 1.1145 - val_accuracy: 0.7140\n",
      "Epoch 232/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0538 - accuracy: 0.7517 - val_loss: 1.1193 - val_accuracy: 0.7030\n",
      "Epoch 233/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0522 - accuracy: 0.7504 - val_loss: 1.1183 - val_accuracy: 0.7000\n",
      "Epoch 234/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0514 - accuracy: 0.7507 - val_loss: 1.1204 - val_accuracy: 0.7040\n",
      "Epoch 235/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0495 - accuracy: 0.7504 - val_loss: 1.1198 - val_accuracy: 0.7030\n",
      "Epoch 236/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0487 - accuracy: 0.7519 - val_loss: 1.1163 - val_accuracy: 0.7040\n",
      "Epoch 237/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0476 - accuracy: 0.7514 - val_loss: 1.1097 - val_accuracy: 0.7050\n",
      "Epoch 238/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0465 - accuracy: 0.7510 - val_loss: 1.1202 - val_accuracy: 0.7030\n",
      "Epoch 239/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0459 - accuracy: 0.7514 - val_loss: 1.1130 - val_accuracy: 0.7110\n",
      "Epoch 240/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0435 - accuracy: 0.7520 - val_loss: 1.1108 - val_accuracy: 0.7080\n",
      "Epoch 241/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0438 - accuracy: 0.7516 - val_loss: 1.1051 - val_accuracy: 0.7090\n",
      "Epoch 242/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0414 - accuracy: 0.7510 - val_loss: 1.1150 - val_accuracy: 0.7030\n",
      "Epoch 243/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0414 - accuracy: 0.7529 - val_loss: 1.1091 - val_accuracy: 0.7090\n",
      "Epoch 244/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0398 - accuracy: 0.7537 - val_loss: 1.1088 - val_accuracy: 0.7050\n",
      "Epoch 245/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0390 - accuracy: 0.7521 - val_loss: 1.1031 - val_accuracy: 0.7080\n",
      "Epoch 246/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0377 - accuracy: 0.7524 - val_loss: 1.1009 - val_accuracy: 0.7160\n",
      "Epoch 247/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0369 - accuracy: 0.7536 - val_loss: 1.1055 - val_accuracy: 0.7090\n",
      "Epoch 248/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0351 - accuracy: 0.7541 - val_loss: 1.1054 - val_accuracy: 0.7080\n",
      "Epoch 249/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0336 - accuracy: 0.7539 - val_loss: 1.1000 - val_accuracy: 0.7100\n",
      "Epoch 250/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0334 - accuracy: 0.7521 - val_loss: 1.1070 - val_accuracy: 0.7080\n",
      "Epoch 251/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0322 - accuracy: 0.7539 - val_loss: 1.1052 - val_accuracy: 0.7070\n",
      "Epoch 252/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0313 - accuracy: 0.7546 - val_loss: 1.1004 - val_accuracy: 0.7050\n",
      "Epoch 253/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0301 - accuracy: 0.7544 - val_loss: 1.0979 - val_accuracy: 0.7130\n",
      "Epoch 254/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0296 - accuracy: 0.7544 - val_loss: 1.0959 - val_accuracy: 0.7140\n",
      "Epoch 255/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0282 - accuracy: 0.7551 - val_loss: 1.0958 - val_accuracy: 0.7110\n",
      "Epoch 256/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0278 - accuracy: 0.7549 - val_loss: 1.0952 - val_accuracy: 0.7160\n",
      "Epoch 257/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0261 - accuracy: 0.7539 - val_loss: 1.0937 - val_accuracy: 0.7070\n",
      "Epoch 258/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0260 - accuracy: 0.7540 - val_loss: 1.0923 - val_accuracy: 0.7140\n",
      "Epoch 259/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0250 - accuracy: 0.7551 - val_loss: 1.0939 - val_accuracy: 0.7130\n",
      "Epoch 260/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0233 - accuracy: 0.7554 - val_loss: 1.0928 - val_accuracy: 0.7100\n",
      "Epoch 261/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0232 - accuracy: 0.7539 - val_loss: 1.0929 - val_accuracy: 0.7110\n",
      "Epoch 262/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0223 - accuracy: 0.7563 - val_loss: 1.0925 - val_accuracy: 0.7090\n",
      "Epoch 263/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0214 - accuracy: 0.7564 - val_loss: 1.0986 - val_accuracy: 0.7040\n",
      "Epoch 264/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0200 - accuracy: 0.7544 - val_loss: 1.0866 - val_accuracy: 0.7170\n",
      "Epoch 265/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0190 - accuracy: 0.7576 - val_loss: 1.0920 - val_accuracy: 0.7070\n",
      "Epoch 266/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0181 - accuracy: 0.7559 - val_loss: 1.0887 - val_accuracy: 0.7130\n",
      "Epoch 267/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0172 - accuracy: 0.7556 - val_loss: 1.0849 - val_accuracy: 0.7180\n",
      "Epoch 268/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0168 - accuracy: 0.7571 - val_loss: 1.0950 - val_accuracy: 0.7020\n",
      "Epoch 269/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0154 - accuracy: 0.7590 - val_loss: 1.0880 - val_accuracy: 0.7180\n",
      "Epoch 270/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0147 - accuracy: 0.7569 - val_loss: 1.0851 - val_accuracy: 0.7190\n",
      "Epoch 271/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0139 - accuracy: 0.7563 - val_loss: 1.0898 - val_accuracy: 0.7080\n",
      "Epoch 272/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0128 - accuracy: 0.7576 - val_loss: 1.0863 - val_accuracy: 0.7110\n",
      "Epoch 273/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0112 - accuracy: 0.7560 - val_loss: 1.0885 - val_accuracy: 0.7170\n",
      "Epoch 274/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0116 - accuracy: 0.7554 - val_loss: 1.0910 - val_accuracy: 0.7100\n",
      "Epoch 275/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0105 - accuracy: 0.7570 - val_loss: 1.0812 - val_accuracy: 0.7190\n",
      "Epoch 276/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0102 - accuracy: 0.7590 - val_loss: 1.0830 - val_accuracy: 0.7080\n",
      "Epoch 277/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.7581 - val_loss: 1.0811 - val_accuracy: 0.7170\n",
      "Epoch 278/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0085 - accuracy: 0.7563 - val_loss: 1.0861 - val_accuracy: 0.7090\n",
      "Epoch 279/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0069 - accuracy: 0.7577 - val_loss: 1.0804 - val_accuracy: 0.7190\n",
      "Epoch 280/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0059 - accuracy: 0.7597 - val_loss: 1.0779 - val_accuracy: 0.7190\n",
      "Epoch 281/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0054 - accuracy: 0.7587 - val_loss: 1.0815 - val_accuracy: 0.7070\n",
      "Epoch 282/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0049 - accuracy: 0.7590 - val_loss: 1.0788 - val_accuracy: 0.7200\n",
      "Epoch 283/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0039 - accuracy: 0.7579 - val_loss: 1.0885 - val_accuracy: 0.7060\n",
      "Epoch 284/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0033 - accuracy: 0.7580 - val_loss: 1.0766 - val_accuracy: 0.7210\n",
      "Epoch 285/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0031 - accuracy: 0.7569 - val_loss: 1.0734 - val_accuracy: 0.7200\n",
      "Epoch 286/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0017 - accuracy: 0.7599 - val_loss: 1.0779 - val_accuracy: 0.7100\n",
      "Epoch 287/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0006 - accuracy: 0.7597 - val_loss: 1.0788 - val_accuracy: 0.7120\n",
      "Epoch 288/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.0002 - accuracy: 0.7579 - val_loss: 1.0792 - val_accuracy: 0.7110\n",
      "Epoch 289/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9997 - accuracy: 0.7591 - val_loss: 1.0727 - val_accuracy: 0.7190\n",
      "Epoch 290/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9987 - accuracy: 0.7601 - val_loss: 1.0707 - val_accuracy: 0.7210\n",
      "Epoch 291/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9979 - accuracy: 0.7589 - val_loss: 1.0790 - val_accuracy: 0.7140\n",
      "Epoch 292/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9963 - accuracy: 0.7607 - val_loss: 1.0735 - val_accuracy: 0.7100\n",
      "Epoch 293/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9964 - accuracy: 0.7609 - val_loss: 1.0725 - val_accuracy: 0.7210\n",
      "Epoch 294/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9956 - accuracy: 0.7586 - val_loss: 1.0719 - val_accuracy: 0.7160\n",
      "Epoch 295/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9944 - accuracy: 0.7611 - val_loss: 1.0806 - val_accuracy: 0.7090\n",
      "Epoch 296/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9940 - accuracy: 0.7606 - val_loss: 1.0787 - val_accuracy: 0.7090\n",
      "Epoch 297/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9928 - accuracy: 0.7609 - val_loss: 1.0713 - val_accuracy: 0.7120\n",
      "Epoch 298/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9927 - accuracy: 0.7624 - val_loss: 1.0807 - val_accuracy: 0.7100\n",
      "Epoch 299/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9913 - accuracy: 0.7619 - val_loss: 1.0712 - val_accuracy: 0.7130\n",
      "Epoch 300/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9912 - accuracy: 0.7620 - val_loss: 1.0765 - val_accuracy: 0.7040\n",
      "Epoch 301/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9896 - accuracy: 0.7621 - val_loss: 1.0668 - val_accuracy: 0.7130\n",
      "Epoch 302/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9895 - accuracy: 0.7627 - val_loss: 1.0667 - val_accuracy: 0.7180\n",
      "Epoch 303/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9880 - accuracy: 0.7614 - val_loss: 1.0662 - val_accuracy: 0.7230\n",
      "Epoch 304/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9888 - accuracy: 0.7601 - val_loss: 1.0679 - val_accuracy: 0.7150\n",
      "Epoch 305/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9871 - accuracy: 0.7614 - val_loss: 1.0646 - val_accuracy: 0.7210\n",
      "Epoch 306/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9858 - accuracy: 0.7629 - val_loss: 1.0673 - val_accuracy: 0.7190\n",
      "Epoch 307/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9857 - accuracy: 0.7620 - val_loss: 1.0701 - val_accuracy: 0.7090\n",
      "Epoch 308/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9848 - accuracy: 0.7629 - val_loss: 1.0635 - val_accuracy: 0.7160\n",
      "Epoch 309/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9840 - accuracy: 0.7601 - val_loss: 1.0656 - val_accuracy: 0.7120\n",
      "Epoch 310/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9831 - accuracy: 0.7620 - val_loss: 1.0621 - val_accuracy: 0.7160\n",
      "Epoch 311/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9827 - accuracy: 0.7636 - val_loss: 1.0642 - val_accuracy: 0.7150\n",
      "Epoch 312/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9826 - accuracy: 0.7627 - val_loss: 1.0649 - val_accuracy: 0.7170\n",
      "Epoch 313/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9810 - accuracy: 0.7633 - val_loss: 1.0633 - val_accuracy: 0.7230\n",
      "Epoch 314/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9810 - accuracy: 0.7623 - val_loss: 1.0619 - val_accuracy: 0.7200\n",
      "Epoch 315/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9801 - accuracy: 0.7636 - val_loss: 1.0652 - val_accuracy: 0.7140\n",
      "Epoch 316/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9796 - accuracy: 0.7620 - val_loss: 1.0620 - val_accuracy: 0.7160\n",
      "Epoch 317/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9785 - accuracy: 0.7629 - val_loss: 1.0584 - val_accuracy: 0.7110\n",
      "Epoch 318/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9780 - accuracy: 0.7624 - val_loss: 1.0610 - val_accuracy: 0.7140\n",
      "Epoch 319/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9778 - accuracy: 0.7644 - val_loss: 1.0607 - val_accuracy: 0.7170\n",
      "Epoch 320/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9767 - accuracy: 0.7650 - val_loss: 1.0617 - val_accuracy: 0.7190\n",
      "Epoch 321/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9755 - accuracy: 0.7640 - val_loss: 1.0587 - val_accuracy: 0.7210\n",
      "Epoch 322/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9753 - accuracy: 0.7640 - val_loss: 1.0581 - val_accuracy: 0.7150\n",
      "Epoch 323/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9754 - accuracy: 0.7637 - val_loss: 1.0563 - val_accuracy: 0.7160\n",
      "Epoch 324/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9751 - accuracy: 0.7637 - val_loss: 1.0558 - val_accuracy: 0.7170\n",
      "Epoch 325/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9730 - accuracy: 0.7651 - val_loss: 1.0542 - val_accuracy: 0.7230\n",
      "Epoch 326/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9729 - accuracy: 0.7651 - val_loss: 1.0578 - val_accuracy: 0.7130\n",
      "Epoch 327/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9713 - accuracy: 0.7646 - val_loss: 1.0605 - val_accuracy: 0.7160\n",
      "Epoch 328/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9717 - accuracy: 0.7649 - val_loss: 1.0689 - val_accuracy: 0.7140\n",
      "Epoch 329/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9720 - accuracy: 0.7629 - val_loss: 1.0563 - val_accuracy: 0.7140\n",
      "Epoch 330/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9697 - accuracy: 0.7654 - val_loss: 1.0538 - val_accuracy: 0.7220\n",
      "Epoch 331/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9698 - accuracy: 0.7647 - val_loss: 1.0534 - val_accuracy: 0.7190\n",
      "Epoch 332/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9686 - accuracy: 0.7661 - val_loss: 1.0535 - val_accuracy: 0.7190\n",
      "Epoch 333/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9682 - accuracy: 0.7654 - val_loss: 1.0581 - val_accuracy: 0.7070\n",
      "Epoch 334/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9678 - accuracy: 0.7651 - val_loss: 1.0599 - val_accuracy: 0.7130\n",
      "Epoch 335/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9673 - accuracy: 0.7660 - val_loss: 1.0608 - val_accuracy: 0.7090\n",
      "Epoch 336/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9662 - accuracy: 0.7636 - val_loss: 1.0481 - val_accuracy: 0.7200\n",
      "Epoch 337/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9657 - accuracy: 0.7661 - val_loss: 1.0498 - val_accuracy: 0.7230\n",
      "Epoch 338/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9657 - accuracy: 0.7647 - val_loss: 1.0475 - val_accuracy: 0.7190\n",
      "Epoch 339/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9638 - accuracy: 0.7660 - val_loss: 1.0497 - val_accuracy: 0.7250\n",
      "Epoch 340/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9640 - accuracy: 0.7660 - val_loss: 1.0495 - val_accuracy: 0.7240\n",
      "Epoch 341/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9642 - accuracy: 0.7673 - val_loss: 1.0501 - val_accuracy: 0.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9629 - accuracy: 0.7661 - val_loss: 1.0525 - val_accuracy: 0.7210\n",
      "Epoch 343/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9616 - accuracy: 0.7653 - val_loss: 1.0505 - val_accuracy: 0.7120\n",
      "Epoch 344/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9617 - accuracy: 0.7676 - val_loss: 1.0466 - val_accuracy: 0.7190\n",
      "Epoch 345/1000\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9609 - accuracy: 0.7666 - val_loss: 1.0642 - val_accuracy: 0.7140\n",
      "Epoch 346/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9604 - accuracy: 0.7679 - val_loss: 1.0433 - val_accuracy: 0.7240\n",
      "Epoch 347/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9598 - accuracy: 0.7677 - val_loss: 1.0475 - val_accuracy: 0.7210\n",
      "Epoch 348/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.9599 - accuracy: 0.7647 - val_loss: 1.0456 - val_accuracy: 0.7150\n",
      "Epoch 349/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9592 - accuracy: 0.7683 - val_loss: 1.0488 - val_accuracy: 0.7120\n",
      "Epoch 350/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9587 - accuracy: 0.7683 - val_loss: 1.0463 - val_accuracy: 0.7210\n",
      "Epoch 351/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9592 - accuracy: 0.7644 - val_loss: 1.0460 - val_accuracy: 0.7190\n",
      "Epoch 352/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9573 - accuracy: 0.7666 - val_loss: 1.0419 - val_accuracy: 0.7250\n",
      "Epoch 353/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9562 - accuracy: 0.7667 - val_loss: 1.0450 - val_accuracy: 0.7200\n",
      "Epoch 354/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9559 - accuracy: 0.7667 - val_loss: 1.0392 - val_accuracy: 0.7240\n",
      "Epoch 355/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9551 - accuracy: 0.7690 - val_loss: 1.0440 - val_accuracy: 0.7220\n",
      "Epoch 356/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9549 - accuracy: 0.7686 - val_loss: 1.0419 - val_accuracy: 0.7220\n",
      "Epoch 357/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9546 - accuracy: 0.7674 - val_loss: 1.0527 - val_accuracy: 0.7080\n",
      "Epoch 358/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9544 - accuracy: 0.7684 - val_loss: 1.0517 - val_accuracy: 0.7140\n",
      "Epoch 359/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9533 - accuracy: 0.7684 - val_loss: 1.0380 - val_accuracy: 0.7290\n",
      "Epoch 360/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9524 - accuracy: 0.7667 - val_loss: 1.0535 - val_accuracy: 0.7110\n",
      "Epoch 361/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9530 - accuracy: 0.7673 - val_loss: 1.0410 - val_accuracy: 0.7190\n",
      "Epoch 362/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9526 - accuracy: 0.7681 - val_loss: 1.0393 - val_accuracy: 0.7210\n",
      "Epoch 363/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9529 - accuracy: 0.7683 - val_loss: 1.0383 - val_accuracy: 0.7260\n",
      "Epoch 364/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9509 - accuracy: 0.7687 - val_loss: 1.0398 - val_accuracy: 0.7150\n",
      "Epoch 365/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9502 - accuracy: 0.7684 - val_loss: 1.0388 - val_accuracy: 0.7220\n",
      "Epoch 366/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9499 - accuracy: 0.7691 - val_loss: 1.0395 - val_accuracy: 0.7180\n",
      "Epoch 367/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9499 - accuracy: 0.7676 - val_loss: 1.0420 - val_accuracy: 0.7160\n",
      "Epoch 368/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9491 - accuracy: 0.7690 - val_loss: 1.0394 - val_accuracy: 0.7180\n",
      "Epoch 369/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9474 - accuracy: 0.7690 - val_loss: 1.0360 - val_accuracy: 0.7250\n",
      "Epoch 370/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9480 - accuracy: 0.7689 - val_loss: 1.0405 - val_accuracy: 0.7230\n",
      "Epoch 371/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9467 - accuracy: 0.7696 - val_loss: 1.0444 - val_accuracy: 0.7120\n",
      "Epoch 372/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9461 - accuracy: 0.7704 - val_loss: 1.0443 - val_accuracy: 0.7140\n",
      "Epoch 373/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9466 - accuracy: 0.7684 - val_loss: 1.0336 - val_accuracy: 0.7270\n",
      "Epoch 374/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9455 - accuracy: 0.7699 - val_loss: 1.0420 - val_accuracy: 0.7190\n",
      "Epoch 375/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9452 - accuracy: 0.7684 - val_loss: 1.0402 - val_accuracy: 0.7180\n",
      "Epoch 376/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9452 - accuracy: 0.7676 - val_loss: 1.0340 - val_accuracy: 0.7170\n",
      "Epoch 377/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9440 - accuracy: 0.7714 - val_loss: 1.0371 - val_accuracy: 0.7130\n",
      "Epoch 378/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9439 - accuracy: 0.7720 - val_loss: 1.0358 - val_accuracy: 0.7150\n",
      "Epoch 379/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9424 - accuracy: 0.7687 - val_loss: 1.0450 - val_accuracy: 0.7220\n",
      "Epoch 380/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9424 - accuracy: 0.7707 - val_loss: 1.0497 - val_accuracy: 0.7170\n",
      "Epoch 381/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9430 - accuracy: 0.7693 - val_loss: 1.0345 - val_accuracy: 0.7250\n",
      "Epoch 382/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9413 - accuracy: 0.7694 - val_loss: 1.0400 - val_accuracy: 0.7230\n",
      "Epoch 383/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9412 - accuracy: 0.7683 - val_loss: 1.0300 - val_accuracy: 0.7230\n",
      "Epoch 384/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9405 - accuracy: 0.7693 - val_loss: 1.0345 - val_accuracy: 0.7320\n",
      "Epoch 385/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9416 - accuracy: 0.7709 - val_loss: 1.0344 - val_accuracy: 0.7210\n",
      "Epoch 386/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9400 - accuracy: 0.7710 - val_loss: 1.0331 - val_accuracy: 0.7220\n",
      "Epoch 387/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9392 - accuracy: 0.7717 - val_loss: 1.0310 - val_accuracy: 0.7240\n",
      "Epoch 388/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9389 - accuracy: 0.7717 - val_loss: 1.0481 - val_accuracy: 0.7150\n",
      "Epoch 389/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9392 - accuracy: 0.7693 - val_loss: 1.0360 - val_accuracy: 0.7180\n",
      "Epoch 390/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9380 - accuracy: 0.7711 - val_loss: 1.0287 - val_accuracy: 0.7270\n",
      "Epoch 391/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9367 - accuracy: 0.7707 - val_loss: 1.0303 - val_accuracy: 0.7190\n",
      "Epoch 392/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9367 - accuracy: 0.7719 - val_loss: 1.0299 - val_accuracy: 0.7210\n",
      "Epoch 393/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9364 - accuracy: 0.7721 - val_loss: 1.0292 - val_accuracy: 0.7240\n",
      "Epoch 394/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9367 - accuracy: 0.7694 - val_loss: 1.0344 - val_accuracy: 0.7130\n",
      "Epoch 395/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9363 - accuracy: 0.7710 - val_loss: 1.0331 - val_accuracy: 0.7160\n",
      "Epoch 396/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9348 - accuracy: 0.7739 - val_loss: 1.0271 - val_accuracy: 0.7240\n",
      "Epoch 397/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9344 - accuracy: 0.7719 - val_loss: 1.0321 - val_accuracy: 0.7210\n",
      "Epoch 398/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9336 - accuracy: 0.7730 - val_loss: 1.0271 - val_accuracy: 0.7210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9336 - accuracy: 0.7733 - val_loss: 1.0261 - val_accuracy: 0.7240\n",
      "Epoch 400/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9336 - accuracy: 0.7719 - val_loss: 1.0276 - val_accuracy: 0.7180\n",
      "Epoch 401/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9323 - accuracy: 0.7709 - val_loss: 1.0270 - val_accuracy: 0.7280\n",
      "Epoch 402/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9322 - accuracy: 0.7697 - val_loss: 1.0259 - val_accuracy: 0.7260\n",
      "Epoch 403/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9310 - accuracy: 0.7734 - val_loss: 1.0317 - val_accuracy: 0.7210\n",
      "Epoch 404/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9318 - accuracy: 0.7703 - val_loss: 1.0262 - val_accuracy: 0.7240\n",
      "Epoch 405/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9309 - accuracy: 0.7710 - val_loss: 1.0274 - val_accuracy: 0.7260\n",
      "Epoch 406/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9319 - accuracy: 0.7724 - val_loss: 1.0263 - val_accuracy: 0.7200\n",
      "Epoch 407/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9305 - accuracy: 0.7747 - val_loss: 1.0282 - val_accuracy: 0.7270\n",
      "Epoch 408/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9301 - accuracy: 0.7710 - val_loss: 1.0263 - val_accuracy: 0.7160\n",
      "Epoch 409/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9292 - accuracy: 0.7733 - val_loss: 1.0355 - val_accuracy: 0.7140\n",
      "Epoch 410/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9286 - accuracy: 0.7730 - val_loss: 1.0278 - val_accuracy: 0.7190\n",
      "Epoch 411/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9283 - accuracy: 0.7713 - val_loss: 1.0240 - val_accuracy: 0.7200\n",
      "Epoch 412/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9273 - accuracy: 0.7739 - val_loss: 1.0563 - val_accuracy: 0.7030\n",
      "Epoch 413/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9277 - accuracy: 0.7726 - val_loss: 1.0265 - val_accuracy: 0.7180\n",
      "Epoch 414/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9274 - accuracy: 0.7724 - val_loss: 1.0277 - val_accuracy: 0.7180\n",
      "Epoch 415/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9267 - accuracy: 0.7736 - val_loss: 1.0217 - val_accuracy: 0.7180\n",
      "Epoch 416/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9257 - accuracy: 0.7699 - val_loss: 1.0216 - val_accuracy: 0.7240\n",
      "Epoch 417/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9255 - accuracy: 0.7737 - val_loss: 1.0213 - val_accuracy: 0.7280\n",
      "Epoch 418/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9246 - accuracy: 0.7724 - val_loss: 1.0190 - val_accuracy: 0.7220\n",
      "Epoch 419/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9247 - accuracy: 0.7721 - val_loss: 1.0356 - val_accuracy: 0.7180\n",
      "Epoch 420/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9259 - accuracy: 0.7740 - val_loss: 1.0448 - val_accuracy: 0.7100\n",
      "Epoch 421/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9240 - accuracy: 0.7734 - val_loss: 1.0256 - val_accuracy: 0.7200\n",
      "Epoch 422/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9229 - accuracy: 0.7736 - val_loss: 1.0356 - val_accuracy: 0.7140\n",
      "Epoch 423/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9227 - accuracy: 0.7723 - val_loss: 1.0233 - val_accuracy: 0.7240\n",
      "Epoch 424/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9225 - accuracy: 0.7736 - val_loss: 1.0236 - val_accuracy: 0.7210\n",
      "Epoch 425/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9217 - accuracy: 0.7743 - val_loss: 1.0273 - val_accuracy: 0.7140\n",
      "Epoch 426/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9213 - accuracy: 0.7724 - val_loss: 1.0199 - val_accuracy: 0.7280\n",
      "Epoch 427/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9210 - accuracy: 0.7743 - val_loss: 1.0202 - val_accuracy: 0.7160\n",
      "Epoch 428/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9205 - accuracy: 0.7743 - val_loss: 1.0168 - val_accuracy: 0.7280\n",
      "Epoch 429/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9198 - accuracy: 0.7747 - val_loss: 1.0326 - val_accuracy: 0.7180\n",
      "Epoch 430/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9208 - accuracy: 0.7746 - val_loss: 1.0215 - val_accuracy: 0.7150\n",
      "Epoch 431/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9189 - accuracy: 0.7741 - val_loss: 1.0214 - val_accuracy: 0.7220\n",
      "Epoch 432/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9188 - accuracy: 0.7769 - val_loss: 1.0213 - val_accuracy: 0.7150\n",
      "Epoch 433/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9182 - accuracy: 0.7739 - val_loss: 1.0443 - val_accuracy: 0.7060\n",
      "Epoch 434/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9189 - accuracy: 0.7723 - val_loss: 1.0195 - val_accuracy: 0.7300\n",
      "Epoch 435/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9182 - accuracy: 0.7749 - val_loss: 1.0235 - val_accuracy: 0.7200\n",
      "Epoch 436/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9188 - accuracy: 0.7763 - val_loss: 1.0147 - val_accuracy: 0.7220\n",
      "Epoch 437/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9171 - accuracy: 0.7747 - val_loss: 1.0160 - val_accuracy: 0.7290\n",
      "Epoch 438/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9168 - accuracy: 0.7741 - val_loss: 1.0162 - val_accuracy: 0.7220\n",
      "Epoch 439/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9164 - accuracy: 0.7750 - val_loss: 1.0291 - val_accuracy: 0.7180\n",
      "Epoch 440/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9159 - accuracy: 0.7756 - val_loss: 1.0171 - val_accuracy: 0.7210\n",
      "Epoch 441/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9158 - accuracy: 0.7769 - val_loss: 1.0166 - val_accuracy: 0.7240\n",
      "Epoch 442/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9164 - accuracy: 0.7736 - val_loss: 1.0169 - val_accuracy: 0.7200\n",
      "Epoch 443/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9140 - accuracy: 0.7759 - val_loss: 1.0303 - val_accuracy: 0.7190\n",
      "Epoch 444/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9158 - accuracy: 0.7741 - val_loss: 1.0225 - val_accuracy: 0.7200\n",
      "Epoch 445/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9144 - accuracy: 0.7721 - val_loss: 1.0233 - val_accuracy: 0.7210\n",
      "Epoch 446/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9155 - accuracy: 0.7741 - val_loss: 1.0193 - val_accuracy: 0.7200\n",
      "Epoch 447/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9135 - accuracy: 0.7756 - val_loss: 1.0191 - val_accuracy: 0.7160\n",
      "Epoch 448/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9132 - accuracy: 0.7749 - val_loss: 1.0283 - val_accuracy: 0.7150\n",
      "Epoch 449/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9128 - accuracy: 0.7753 - val_loss: 1.0164 - val_accuracy: 0.7210\n",
      "Epoch 450/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9114 - accuracy: 0.7764 - val_loss: 1.0191 - val_accuracy: 0.7180\n",
      "Epoch 451/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9116 - accuracy: 0.7740 - val_loss: 1.0306 - val_accuracy: 0.7140\n",
      "Epoch 452/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9115 - accuracy: 0.7763 - val_loss: 1.0195 - val_accuracy: 0.7190\n",
      "Epoch 453/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9114 - accuracy: 0.7774 - val_loss: 1.0250 - val_accuracy: 0.7190\n",
      "Epoch 454/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9103 - accuracy: 0.7779 - val_loss: 1.0121 - val_accuracy: 0.7190\n",
      "Epoch 455/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9112 - accuracy: 0.7757 - val_loss: 1.0212 - val_accuracy: 0.7190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9099 - accuracy: 0.7770 - val_loss: 1.0140 - val_accuracy: 0.7190\n",
      "Epoch 457/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9113 - accuracy: 0.7769 - val_loss: 1.0183 - val_accuracy: 0.7210\n",
      "Epoch 458/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9097 - accuracy: 0.7761 - val_loss: 1.0129 - val_accuracy: 0.7210\n",
      "Epoch 459/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9096 - accuracy: 0.7764 - val_loss: 1.0142 - val_accuracy: 0.7250\n",
      "Epoch 460/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9086 - accuracy: 0.7769 - val_loss: 1.0125 - val_accuracy: 0.7190\n",
      "Epoch 461/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9082 - accuracy: 0.7780 - val_loss: 1.0107 - val_accuracy: 0.7200\n",
      "Epoch 462/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9082 - accuracy: 0.7759 - val_loss: 1.0168 - val_accuracy: 0.7170\n",
      "Epoch 463/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9074 - accuracy: 0.7790 - val_loss: 1.0178 - val_accuracy: 0.7180\n",
      "Epoch 464/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9078 - accuracy: 0.7744 - val_loss: 1.0134 - val_accuracy: 0.7210\n",
      "Epoch 465/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9075 - accuracy: 0.7759 - val_loss: 1.0116 - val_accuracy: 0.7170\n",
      "Epoch 466/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9074 - accuracy: 0.7786 - val_loss: 1.0165 - val_accuracy: 0.7170\n",
      "Epoch 467/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9082 - accuracy: 0.7754 - val_loss: 1.0084 - val_accuracy: 0.7270\n",
      "Epoch 468/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9059 - accuracy: 0.7790 - val_loss: 1.0131 - val_accuracy: 0.7180\n",
      "Epoch 469/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9049 - accuracy: 0.7777 - val_loss: 1.0080 - val_accuracy: 0.7240\n",
      "Epoch 470/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9052 - accuracy: 0.7761 - val_loss: 1.0155 - val_accuracy: 0.7230\n",
      "Epoch 471/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9046 - accuracy: 0.7744 - val_loss: 1.0167 - val_accuracy: 0.7180\n",
      "Epoch 472/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9044 - accuracy: 0.7773 - val_loss: 1.0068 - val_accuracy: 0.7310\n",
      "Epoch 473/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9042 - accuracy: 0.7781 - val_loss: 1.0085 - val_accuracy: 0.7230\n",
      "Epoch 474/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9029 - accuracy: 0.7794 - val_loss: 1.0123 - val_accuracy: 0.7210\n",
      "Epoch 475/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9035 - accuracy: 0.7769 - val_loss: 1.0163 - val_accuracy: 0.7190\n",
      "Epoch 476/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9027 - accuracy: 0.7747 - val_loss: 1.0092 - val_accuracy: 0.7190\n",
      "Epoch 477/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9035 - accuracy: 0.7769 - val_loss: 1.0253 - val_accuracy: 0.7210\n",
      "Epoch 478/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9018 - accuracy: 0.7787 - val_loss: 1.0077 - val_accuracy: 0.7250\n",
      "Epoch 479/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9035 - accuracy: 0.7784 - val_loss: 1.0123 - val_accuracy: 0.7250\n",
      "Epoch 480/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9014 - accuracy: 0.7786 - val_loss: 1.0091 - val_accuracy: 0.7250\n",
      "Epoch 481/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9028 - accuracy: 0.7773 - val_loss: 1.0112 - val_accuracy: 0.7200\n",
      "Epoch 482/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.9010 - accuracy: 0.7777 - val_loss: 1.0151 - val_accuracy: 0.7280\n",
      "Epoch 483/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9007 - accuracy: 0.7761 - val_loss: 1.0270 - val_accuracy: 0.7130\n",
      "Epoch 484/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.9010 - accuracy: 0.7770 - val_loss: 1.0047 - val_accuracy: 0.7250\n",
      "Epoch 485/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8998 - accuracy: 0.7776 - val_loss: 1.0076 - val_accuracy: 0.7210\n",
      "Epoch 486/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8991 - accuracy: 0.7780 - val_loss: 1.0105 - val_accuracy: 0.7180\n",
      "Epoch 487/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8995 - accuracy: 0.7789 - val_loss: 1.0093 - val_accuracy: 0.7250\n",
      "Epoch 488/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8990 - accuracy: 0.7781 - val_loss: 1.0143 - val_accuracy: 0.7180\n",
      "Epoch 489/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8991 - accuracy: 0.7793 - val_loss: 1.0106 - val_accuracy: 0.7230\n",
      "Epoch 490/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8978 - accuracy: 0.7781 - val_loss: 1.0039 - val_accuracy: 0.7250\n",
      "Epoch 491/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8981 - accuracy: 0.7763 - val_loss: 1.0075 - val_accuracy: 0.7220\n",
      "Epoch 492/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8973 - accuracy: 0.7781 - val_loss: 1.0087 - val_accuracy: 0.7210\n",
      "Epoch 493/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8970 - accuracy: 0.7779 - val_loss: 1.0036 - val_accuracy: 0.7190\n",
      "Epoch 494/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8977 - accuracy: 0.7790 - val_loss: 1.0169 - val_accuracy: 0.7220\n",
      "Epoch 495/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8971 - accuracy: 0.7794 - val_loss: 1.0040 - val_accuracy: 0.7200\n",
      "Epoch 496/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8974 - accuracy: 0.7790 - val_loss: 1.0174 - val_accuracy: 0.7230\n",
      "Epoch 497/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8959 - accuracy: 0.7780 - val_loss: 1.0040 - val_accuracy: 0.7210\n",
      "Epoch 498/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8967 - accuracy: 0.7781 - val_loss: 1.0078 - val_accuracy: 0.7220\n",
      "Epoch 499/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8955 - accuracy: 0.7793 - val_loss: 1.0040 - val_accuracy: 0.7230\n",
      "Epoch 500/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8956 - accuracy: 0.7789 - val_loss: 1.0145 - val_accuracy: 0.7230\n",
      "Epoch 501/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8961 - accuracy: 0.7779 - val_loss: 1.0080 - val_accuracy: 0.7240\n",
      "Epoch 502/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8948 - accuracy: 0.7797 - val_loss: 1.0026 - val_accuracy: 0.7220\n",
      "Epoch 503/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8958 - accuracy: 0.7797 - val_loss: 1.0052 - val_accuracy: 0.7230\n",
      "Epoch 504/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8953 - accuracy: 0.7771 - val_loss: 1.0026 - val_accuracy: 0.7230\n",
      "Epoch 505/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8944 - accuracy: 0.7794 - val_loss: 1.0015 - val_accuracy: 0.7210\n",
      "Epoch 506/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8937 - accuracy: 0.7821 - val_loss: 1.0261 - val_accuracy: 0.7180\n",
      "Epoch 507/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8934 - accuracy: 0.7806 - val_loss: 1.0082 - val_accuracy: 0.7200\n",
      "Epoch 508/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8948 - accuracy: 0.7763 - val_loss: 1.0097 - val_accuracy: 0.7260\n",
      "Epoch 509/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8928 - accuracy: 0.7800 - val_loss: 1.0057 - val_accuracy: 0.7260\n",
      "Epoch 510/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8922 - accuracy: 0.7809 - val_loss: 0.9996 - val_accuracy: 0.7260\n",
      "Epoch 511/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8932 - accuracy: 0.7796 - val_loss: 1.0020 - val_accuracy: 0.7220\n",
      "Epoch 512/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8918 - accuracy: 0.7793 - val_loss: 0.9983 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8919 - accuracy: 0.7800 - val_loss: 1.0064 - val_accuracy: 0.7210\n",
      "Epoch 514/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8912 - accuracy: 0.7799 - val_loss: 1.0150 - val_accuracy: 0.7210\n",
      "Epoch 515/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8910 - accuracy: 0.7793 - val_loss: 1.0048 - val_accuracy: 0.7250\n",
      "Epoch 516/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8901 - accuracy: 0.7799 - val_loss: 1.0053 - val_accuracy: 0.7260\n",
      "Epoch 517/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8901 - accuracy: 0.7831 - val_loss: 1.0101 - val_accuracy: 0.7200\n",
      "Epoch 518/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8917 - accuracy: 0.7794 - val_loss: 1.0112 - val_accuracy: 0.7190\n",
      "Epoch 519/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8903 - accuracy: 0.7807 - val_loss: 1.0090 - val_accuracy: 0.7180\n",
      "Epoch 520/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8896 - accuracy: 0.7821 - val_loss: 1.0000 - val_accuracy: 0.7280\n",
      "Epoch 521/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8911 - accuracy: 0.7797 - val_loss: 1.0293 - val_accuracy: 0.7140\n",
      "Epoch 522/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8900 - accuracy: 0.7796 - val_loss: 1.0022 - val_accuracy: 0.7280\n",
      "Epoch 523/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8900 - accuracy: 0.7807 - val_loss: 1.0020 - val_accuracy: 0.7240\n",
      "Epoch 524/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8880 - accuracy: 0.7817 - val_loss: 0.9992 - val_accuracy: 0.7240\n",
      "Epoch 525/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8879 - accuracy: 0.7800 - val_loss: 1.0067 - val_accuracy: 0.7200\n",
      "Epoch 526/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8880 - accuracy: 0.7810 - val_loss: 1.0024 - val_accuracy: 0.7230\n",
      "Epoch 527/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8881 - accuracy: 0.7816 - val_loss: 1.0131 - val_accuracy: 0.7240\n",
      "Epoch 528/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8887 - accuracy: 0.7809 - val_loss: 1.0063 - val_accuracy: 0.7200\n",
      "Epoch 529/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8888 - accuracy: 0.7790 - val_loss: 0.9985 - val_accuracy: 0.7190\n",
      "Epoch 530/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8875 - accuracy: 0.7819 - val_loss: 0.9985 - val_accuracy: 0.7190\n",
      "Epoch 531/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8872 - accuracy: 0.7811 - val_loss: 1.0009 - val_accuracy: 0.7190\n",
      "Epoch 532/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8863 - accuracy: 0.7820 - val_loss: 1.0044 - val_accuracy: 0.7250\n",
      "Epoch 533/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8858 - accuracy: 0.7806 - val_loss: 1.0077 - val_accuracy: 0.7190\n",
      "Epoch 534/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8864 - accuracy: 0.7811 - val_loss: 1.0031 - val_accuracy: 0.7180\n",
      "Epoch 535/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8860 - accuracy: 0.7803 - val_loss: 0.9985 - val_accuracy: 0.7240\n",
      "Epoch 536/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8858 - accuracy: 0.7823 - val_loss: 1.0139 - val_accuracy: 0.7230\n",
      "Epoch 537/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.7810 - val_loss: 0.9979 - val_accuracy: 0.7200\n",
      "Epoch 538/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8857 - accuracy: 0.7796 - val_loss: 0.9974 - val_accuracy: 0.7290\n",
      "Epoch 539/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.7829 - val_loss: 1.0236 - val_accuracy: 0.7200\n",
      "Epoch 540/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8848 - accuracy: 0.7824 - val_loss: 1.0016 - val_accuracy: 0.7140\n",
      "Epoch 541/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8838 - accuracy: 0.7804 - val_loss: 1.0020 - val_accuracy: 0.7220\n",
      "Epoch 542/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8867 - accuracy: 0.7807 - val_loss: 0.9970 - val_accuracy: 0.7240\n",
      "Epoch 543/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.7823 - val_loss: 0.9999 - val_accuracy: 0.7190\n",
      "Epoch 544/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8848 - accuracy: 0.7809 - val_loss: 0.9978 - val_accuracy: 0.7300\n",
      "Epoch 545/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8837 - accuracy: 0.7811 - val_loss: 0.9987 - val_accuracy: 0.7260\n",
      "Epoch 546/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8840 - accuracy: 0.7811 - val_loss: 1.0270 - val_accuracy: 0.7160\n",
      "Epoch 547/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8835 - accuracy: 0.7809 - val_loss: 1.0017 - val_accuracy: 0.7260\n",
      "Epoch 548/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8821 - accuracy: 0.7813 - val_loss: 0.9991 - val_accuracy: 0.7210\n",
      "Epoch 549/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8825 - accuracy: 0.7823 - val_loss: 1.0112 - val_accuracy: 0.7150\n",
      "Epoch 550/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8832 - accuracy: 0.7824 - val_loss: 1.0043 - val_accuracy: 0.7200\n",
      "Epoch 551/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8814 - accuracy: 0.7819 - val_loss: 0.9999 - val_accuracy: 0.7250\n",
      "Epoch 552/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8820 - accuracy: 0.7816 - val_loss: 1.0027 - val_accuracy: 0.7230\n",
      "Epoch 553/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8812 - accuracy: 0.7807 - val_loss: 1.0094 - val_accuracy: 0.7160\n",
      "Epoch 554/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8820 - accuracy: 0.7809 - val_loss: 1.0034 - val_accuracy: 0.7200\n",
      "Epoch 555/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8815 - accuracy: 0.7821 - val_loss: 1.0069 - val_accuracy: 0.7230\n",
      "Epoch 556/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8814 - accuracy: 0.7841 - val_loss: 0.9940 - val_accuracy: 0.7190\n",
      "Epoch 557/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8797 - accuracy: 0.7826 - val_loss: 1.0056 - val_accuracy: 0.7180\n",
      "Epoch 558/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8810 - accuracy: 0.7834 - val_loss: 1.0071 - val_accuracy: 0.7290\n",
      "Epoch 559/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8805 - accuracy: 0.7824 - val_loss: 0.9991 - val_accuracy: 0.7250\n",
      "Epoch 560/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8799 - accuracy: 0.7816 - val_loss: 0.9989 - val_accuracy: 0.7210\n",
      "Epoch 561/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8797 - accuracy: 0.7813 - val_loss: 0.9950 - val_accuracy: 0.7320\n",
      "Epoch 562/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8793 - accuracy: 0.7811 - val_loss: 0.9990 - val_accuracy: 0.7320\n",
      "Epoch 563/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8798 - accuracy: 0.7807 - val_loss: 1.0064 - val_accuracy: 0.7210\n",
      "Epoch 564/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8790 - accuracy: 0.7829 - val_loss: 1.0013 - val_accuracy: 0.7290\n",
      "Epoch 565/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8779 - accuracy: 0.7816 - val_loss: 0.9943 - val_accuracy: 0.7200\n",
      "Epoch 566/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8785 - accuracy: 0.7821 - val_loss: 0.9994 - val_accuracy: 0.7320\n",
      "Epoch 567/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8779 - accuracy: 0.7837 - val_loss: 0.9917 - val_accuracy: 0.7250\n",
      "Epoch 568/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8781 - accuracy: 0.7819 - val_loss: 1.0155 - val_accuracy: 0.7210\n",
      "Epoch 569/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8786 - accuracy: 0.7833 - val_loss: 1.0164 - val_accuracy: 0.7180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8796 - accuracy: 0.7833 - val_loss: 0.9959 - val_accuracy: 0.7140\n",
      "Epoch 571/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8776 - accuracy: 0.7809 - val_loss: 1.0133 - val_accuracy: 0.7240\n",
      "Epoch 572/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8764 - accuracy: 0.7847 - val_loss: 0.9894 - val_accuracy: 0.7240\n",
      "Epoch 573/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8762 - accuracy: 0.7840 - val_loss: 1.0011 - val_accuracy: 0.7180\n",
      "Epoch 574/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8760 - accuracy: 0.7840 - val_loss: 0.9960 - val_accuracy: 0.7240\n",
      "Epoch 575/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8773 - accuracy: 0.7851 - val_loss: 0.9914 - val_accuracy: 0.7220\n",
      "Epoch 576/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8751 - accuracy: 0.7837 - val_loss: 0.9946 - val_accuracy: 0.7270\n",
      "Epoch 577/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8763 - accuracy: 0.7846 - val_loss: 0.9921 - val_accuracy: 0.7360\n",
      "Epoch 578/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8758 - accuracy: 0.7844 - val_loss: 0.9950 - val_accuracy: 0.7210\n",
      "Epoch 579/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8746 - accuracy: 0.7849 - val_loss: 0.9937 - val_accuracy: 0.7190\n",
      "Epoch 580/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8746 - accuracy: 0.7823 - val_loss: 1.0066 - val_accuracy: 0.7190\n",
      "Epoch 581/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8751 - accuracy: 0.7849 - val_loss: 0.9985 - val_accuracy: 0.7330\n",
      "Epoch 582/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8758 - accuracy: 0.7849 - val_loss: 0.9925 - val_accuracy: 0.7270\n",
      "Epoch 583/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8756 - accuracy: 0.7840 - val_loss: 1.0118 - val_accuracy: 0.7210\n",
      "Epoch 584/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8739 - accuracy: 0.7824 - val_loss: 0.9970 - val_accuracy: 0.7230\n",
      "Epoch 585/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8733 - accuracy: 0.7836 - val_loss: 0.9926 - val_accuracy: 0.7290\n",
      "Epoch 586/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8739 - accuracy: 0.7841 - val_loss: 0.9993 - val_accuracy: 0.7180\n",
      "Epoch 587/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8738 - accuracy: 0.7847 - val_loss: 0.9937 - val_accuracy: 0.7240\n",
      "Epoch 588/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8730 - accuracy: 0.7841 - val_loss: 0.9930 - val_accuracy: 0.7260\n",
      "Epoch 589/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8722 - accuracy: 0.7844 - val_loss: 0.9966 - val_accuracy: 0.7250\n",
      "Epoch 590/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8721 - accuracy: 0.7841 - val_loss: 0.9983 - val_accuracy: 0.7280\n",
      "Epoch 591/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8724 - accuracy: 0.7859 - val_loss: 0.9877 - val_accuracy: 0.7270\n",
      "Epoch 592/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8722 - accuracy: 0.7853 - val_loss: 1.0117 - val_accuracy: 0.7200\n",
      "Epoch 593/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8729 - accuracy: 0.7827 - val_loss: 1.0022 - val_accuracy: 0.7250\n",
      "Epoch 594/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8725 - accuracy: 0.7863 - val_loss: 0.9928 - val_accuracy: 0.7240\n",
      "Epoch 595/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8717 - accuracy: 0.7834 - val_loss: 1.0067 - val_accuracy: 0.7170\n",
      "Epoch 596/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8733 - accuracy: 0.7839 - val_loss: 0.9996 - val_accuracy: 0.7350\n",
      "Epoch 597/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8717 - accuracy: 0.7873 - val_loss: 0.9959 - val_accuracy: 0.7190\n",
      "Epoch 598/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8712 - accuracy: 0.7841 - val_loss: 1.0118 - val_accuracy: 0.7180\n",
      "Epoch 599/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8716 - accuracy: 0.7833 - val_loss: 0.9907 - val_accuracy: 0.7210\n",
      "Epoch 600/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8705 - accuracy: 0.7863 - val_loss: 1.0013 - val_accuracy: 0.7170\n",
      "Epoch 601/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8711 - accuracy: 0.7846 - val_loss: 0.9894 - val_accuracy: 0.7240\n",
      "Epoch 602/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8699 - accuracy: 0.7859 - val_loss: 0.9882 - val_accuracy: 0.7340\n",
      "Epoch 603/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8699 - accuracy: 0.7836 - val_loss: 0.9944 - val_accuracy: 0.7250\n",
      "Epoch 604/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8707 - accuracy: 0.7853 - val_loss: 0.9964 - val_accuracy: 0.7300\n",
      "Epoch 605/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8707 - accuracy: 0.7857 - val_loss: 1.0001 - val_accuracy: 0.7210\n",
      "Epoch 606/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8710 - accuracy: 0.7837 - val_loss: 0.9959 - val_accuracy: 0.7290\n",
      "Epoch 607/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8677 - accuracy: 0.7884 - val_loss: 1.0160 - val_accuracy: 0.7120\n",
      "Epoch 608/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8704 - accuracy: 0.7861 - val_loss: 0.9943 - val_accuracy: 0.7230\n",
      "Epoch 609/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7869 - val_loss: 0.9963 - val_accuracy: 0.7320\n",
      "Epoch 610/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8693 - accuracy: 0.7864 - val_loss: 1.0101 - val_accuracy: 0.7170\n",
      "Epoch 611/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8688 - accuracy: 0.7866 - val_loss: 0.9916 - val_accuracy: 0.7260\n",
      "Epoch 612/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8679 - accuracy: 0.7860 - val_loss: 1.0069 - val_accuracy: 0.7160\n",
      "Epoch 613/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8699 - accuracy: 0.7859 - val_loss: 0.9863 - val_accuracy: 0.7240\n",
      "Epoch 614/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8674 - accuracy: 0.7866 - val_loss: 0.9912 - val_accuracy: 0.7250\n",
      "Epoch 615/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8679 - accuracy: 0.7864 - val_loss: 0.9951 - val_accuracy: 0.7340\n",
      "Epoch 616/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8675 - accuracy: 0.7863 - val_loss: 0.9896 - val_accuracy: 0.7340\n",
      "Epoch 617/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8676 - accuracy: 0.7887 - val_loss: 0.9882 - val_accuracy: 0.7290\n",
      "Epoch 618/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8683 - accuracy: 0.7866 - val_loss: 0.9945 - val_accuracy: 0.7300\n",
      "Epoch 619/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8686 - accuracy: 0.7870 - val_loss: 0.9901 - val_accuracy: 0.7210\n",
      "Epoch 620/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8664 - accuracy: 0.7879 - val_loss: 0.9872 - val_accuracy: 0.7230\n",
      "Epoch 621/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8657 - accuracy: 0.7846 - val_loss: 1.0096 - val_accuracy: 0.7320\n",
      "Epoch 622/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8699 - accuracy: 0.7859 - val_loss: 0.9873 - val_accuracy: 0.7280\n",
      "Epoch 623/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8658 - accuracy: 0.7861 - val_loss: 0.9891 - val_accuracy: 0.7280\n",
      "Epoch 624/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8641 - accuracy: 0.7887 - val_loss: 0.9914 - val_accuracy: 0.7240\n",
      "Epoch 625/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8667 - accuracy: 0.7864 - val_loss: 1.0237 - val_accuracy: 0.7180\n",
      "Epoch 626/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8670 - accuracy: 0.7877 - val_loss: 0.9891 - val_accuracy: 0.7230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 627/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8644 - accuracy: 0.7874 - val_loss: 0.9883 - val_accuracy: 0.7220\n",
      "Epoch 628/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8652 - accuracy: 0.7867 - val_loss: 0.9936 - val_accuracy: 0.7280\n",
      "Epoch 629/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8643 - accuracy: 0.7864 - val_loss: 0.9958 - val_accuracy: 0.7220\n",
      "Epoch 630/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8646 - accuracy: 0.7896 - val_loss: 0.9869 - val_accuracy: 0.7210\n",
      "Epoch 631/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8644 - accuracy: 0.7867 - val_loss: 1.0000 - val_accuracy: 0.7300\n",
      "Epoch 632/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8656 - accuracy: 0.7854 - val_loss: 0.9897 - val_accuracy: 0.7200\n",
      "Epoch 633/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8641 - accuracy: 0.7851 - val_loss: 0.9937 - val_accuracy: 0.7270\n",
      "Epoch 634/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8637 - accuracy: 0.7873 - val_loss: 0.9884 - val_accuracy: 0.7300\n",
      "Epoch 635/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8641 - accuracy: 0.7870 - val_loss: 0.9981 - val_accuracy: 0.7190\n",
      "Epoch 636/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8642 - accuracy: 0.7874 - val_loss: 0.9925 - val_accuracy: 0.7260\n",
      "Epoch 637/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8643 - accuracy: 0.7879 - val_loss: 0.9901 - val_accuracy: 0.7240\n",
      "Epoch 638/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8628 - accuracy: 0.7867 - val_loss: 0.9911 - val_accuracy: 0.7210\n",
      "Epoch 639/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8630 - accuracy: 0.7873 - val_loss: 0.9877 - val_accuracy: 0.7240\n",
      "Epoch 640/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8641 - accuracy: 0.7881 - val_loss: 0.9870 - val_accuracy: 0.7230\n",
      "Epoch 641/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8615 - accuracy: 0.7884 - val_loss: 0.9864 - val_accuracy: 0.7320\n",
      "Epoch 642/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8608 - accuracy: 0.7871 - val_loss: 0.9906 - val_accuracy: 0.7250\n",
      "Epoch 643/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8626 - accuracy: 0.7879 - val_loss: 0.9842 - val_accuracy: 0.7290\n",
      "Epoch 644/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8632 - accuracy: 0.7881 - val_loss: 0.9901 - val_accuracy: 0.7230\n",
      "Epoch 645/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8631 - accuracy: 0.7896 - val_loss: 0.9848 - val_accuracy: 0.7240\n",
      "Epoch 646/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8619 - accuracy: 0.7917 - val_loss: 1.0041 - val_accuracy: 0.7170\n",
      "Epoch 647/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8607 - accuracy: 0.7894 - val_loss: 1.0177 - val_accuracy: 0.7170\n",
      "Epoch 648/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8631 - accuracy: 0.7860 - val_loss: 1.0112 - val_accuracy: 0.7240\n",
      "Epoch 649/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8629 - accuracy: 0.7901 - val_loss: 0.9822 - val_accuracy: 0.7240\n",
      "Epoch 650/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8597 - accuracy: 0.7906 - val_loss: 0.9850 - val_accuracy: 0.7250\n",
      "Epoch 651/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8615 - accuracy: 0.7886 - val_loss: 0.9997 - val_accuracy: 0.7260\n",
      "Epoch 652/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8607 - accuracy: 0.7866 - val_loss: 0.9893 - val_accuracy: 0.7220\n",
      "Epoch 653/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8609 - accuracy: 0.7886 - val_loss: 0.9848 - val_accuracy: 0.7270\n",
      "Epoch 654/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8610 - accuracy: 0.7879 - val_loss: 0.9994 - val_accuracy: 0.7210\n",
      "Epoch 655/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8600 - accuracy: 0.7889 - val_loss: 0.9887 - val_accuracy: 0.7230\n",
      "Epoch 656/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8597 - accuracy: 0.7900 - val_loss: 0.9987 - val_accuracy: 0.7170\n",
      "Epoch 657/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8590 - accuracy: 0.7886 - val_loss: 1.0034 - val_accuracy: 0.7280\n",
      "Epoch 658/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8600 - accuracy: 0.7901 - val_loss: 0.9929 - val_accuracy: 0.7310\n",
      "Epoch 659/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8588 - accuracy: 0.7907 - val_loss: 0.9871 - val_accuracy: 0.7210\n",
      "Epoch 660/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8586 - accuracy: 0.7880 - val_loss: 0.9940 - val_accuracy: 0.7290\n",
      "Epoch 661/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8598 - accuracy: 0.7891 - val_loss: 0.9890 - val_accuracy: 0.7250\n",
      "Epoch 662/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8583 - accuracy: 0.7891 - val_loss: 0.9838 - val_accuracy: 0.7240\n",
      "Epoch 663/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8584 - accuracy: 0.7887 - val_loss: 1.0059 - val_accuracy: 0.7200\n",
      "Epoch 664/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8593 - accuracy: 0.7869 - val_loss: 0.9854 - val_accuracy: 0.7260\n",
      "Epoch 665/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8586 - accuracy: 0.7910 - val_loss: 1.0151 - val_accuracy: 0.7190\n",
      "Epoch 666/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8612 - accuracy: 0.7871 - val_loss: 0.9861 - val_accuracy: 0.7310\n",
      "Epoch 667/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8571 - accuracy: 0.7900 - val_loss: 0.9910 - val_accuracy: 0.7200\n",
      "Epoch 668/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8581 - accuracy: 0.7887 - val_loss: 1.0126 - val_accuracy: 0.7180\n",
      "Epoch 669/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8592 - accuracy: 0.7887 - val_loss: 1.0263 - val_accuracy: 0.7130\n",
      "Epoch 670/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8609 - accuracy: 0.7864 - val_loss: 0.9925 - val_accuracy: 0.7260\n",
      "Epoch 671/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8572 - accuracy: 0.7896 - val_loss: 0.9884 - val_accuracy: 0.7240\n",
      "Epoch 672/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8571 - accuracy: 0.7881 - val_loss: 0.9841 - val_accuracy: 0.7270\n",
      "Epoch 673/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8573 - accuracy: 0.7896 - val_loss: 0.9849 - val_accuracy: 0.7260\n",
      "Epoch 674/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8593 - accuracy: 0.7874 - val_loss: 0.9884 - val_accuracy: 0.7290\n",
      "Epoch 675/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8574 - accuracy: 0.7897 - val_loss: 0.9895 - val_accuracy: 0.7270\n",
      "Epoch 676/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8582 - accuracy: 0.7896 - val_loss: 1.0166 - val_accuracy: 0.7150\n",
      "Epoch 677/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8589 - accuracy: 0.7880 - val_loss: 1.0019 - val_accuracy: 0.7280\n",
      "Epoch 678/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8566 - accuracy: 0.7900 - val_loss: 0.9991 - val_accuracy: 0.7310\n",
      "Epoch 679/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8568 - accuracy: 0.7896 - val_loss: 0.9913 - val_accuracy: 0.7230\n",
      "Epoch 680/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8566 - accuracy: 0.7900 - val_loss: 1.0072 - val_accuracy: 0.7320\n",
      "Epoch 681/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8567 - accuracy: 0.7887 - val_loss: 0.9854 - val_accuracy: 0.7370\n",
      "Epoch 682/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8554 - accuracy: 0.7916 - val_loss: 0.9960 - val_accuracy: 0.7220\n",
      "Epoch 683/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8532 - accuracy: 0.7904 - val_loss: 0.9837 - val_accuracy: 0.7270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 684/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8551 - accuracy: 0.7890 - val_loss: 0.9945 - val_accuracy: 0.7330\n",
      "Epoch 685/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8561 - accuracy: 0.7894 - val_loss: 0.9923 - val_accuracy: 0.7180\n",
      "Epoch 686/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8554 - accuracy: 0.7924 - val_loss: 0.9959 - val_accuracy: 0.7260\n",
      "Epoch 687/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8544 - accuracy: 0.7903 - val_loss: 0.9894 - val_accuracy: 0.7230\n",
      "Epoch 688/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8543 - accuracy: 0.7876 - val_loss: 0.9845 - val_accuracy: 0.7240\n",
      "Epoch 689/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8566 - accuracy: 0.7910 - val_loss: 0.9933 - val_accuracy: 0.7230\n",
      "Epoch 690/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8542 - accuracy: 0.7900 - val_loss: 0.9940 - val_accuracy: 0.7260\n",
      "Epoch 691/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8548 - accuracy: 0.7917 - val_loss: 0.9935 - val_accuracy: 0.7330\n",
      "Epoch 692/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8533 - accuracy: 0.7921 - val_loss: 0.9936 - val_accuracy: 0.7280\n",
      "Epoch 693/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8529 - accuracy: 0.7910 - val_loss: 0.9879 - val_accuracy: 0.7280\n",
      "Epoch 694/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8541 - accuracy: 0.7930 - val_loss: 1.0098 - val_accuracy: 0.7240\n",
      "Epoch 695/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8553 - accuracy: 0.7884 - val_loss: 1.0077 - val_accuracy: 0.7280\n",
      "Epoch 696/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8538 - accuracy: 0.7923 - val_loss: 0.9837 - val_accuracy: 0.7280\n",
      "Epoch 697/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8546 - accuracy: 0.7901 - val_loss: 0.9892 - val_accuracy: 0.7370\n",
      "Epoch 698/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8545 - accuracy: 0.7906 - val_loss: 0.9935 - val_accuracy: 0.7280\n",
      "Epoch 699/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8535 - accuracy: 0.7926 - val_loss: 0.9892 - val_accuracy: 0.7310\n",
      "Epoch 700/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8549 - accuracy: 0.7926 - val_loss: 0.9851 - val_accuracy: 0.7340\n",
      "Epoch 701/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8522 - accuracy: 0.7920 - val_loss: 0.9813 - val_accuracy: 0.7290\n",
      "Epoch 702/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8521 - accuracy: 0.7909 - val_loss: 0.9815 - val_accuracy: 0.7240\n",
      "Epoch 703/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8521 - accuracy: 0.7927 - val_loss: 1.0000 - val_accuracy: 0.7300\n",
      "Epoch 704/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8552 - accuracy: 0.7904 - val_loss: 1.0062 - val_accuracy: 0.7340\n",
      "Epoch 705/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8524 - accuracy: 0.7903 - val_loss: 1.0035 - val_accuracy: 0.7330\n",
      "Epoch 706/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8545 - accuracy: 0.7916 - val_loss: 0.9916 - val_accuracy: 0.7350\n",
      "Epoch 707/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8526 - accuracy: 0.7947 - val_loss: 1.0052 - val_accuracy: 0.7270\n",
      "Epoch 708/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8505 - accuracy: 0.7921 - val_loss: 0.9842 - val_accuracy: 0.7330\n",
      "Epoch 709/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8495 - accuracy: 0.7923 - val_loss: 0.9843 - val_accuracy: 0.7240\n",
      "Epoch 710/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8511 - accuracy: 0.7936 - val_loss: 0.9844 - val_accuracy: 0.7300\n",
      "Epoch 711/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8514 - accuracy: 0.7916 - val_loss: 0.9990 - val_accuracy: 0.7310\n",
      "Epoch 712/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8543 - accuracy: 0.7934 - val_loss: 0.9859 - val_accuracy: 0.7240\n",
      "Epoch 713/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8495 - accuracy: 0.7941 - val_loss: 0.9856 - val_accuracy: 0.7340\n",
      "Epoch 714/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8503 - accuracy: 0.7909 - val_loss: 0.9848 - val_accuracy: 0.7230\n",
      "Epoch 715/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8519 - accuracy: 0.7916 - val_loss: 0.9964 - val_accuracy: 0.7330\n",
      "Epoch 716/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8536 - accuracy: 0.7884 - val_loss: 0.9909 - val_accuracy: 0.7240\n",
      "Epoch 717/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8489 - accuracy: 0.7927 - val_loss: 0.9938 - val_accuracy: 0.7340\n",
      "Epoch 718/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8491 - accuracy: 0.7951 - val_loss: 0.9995 - val_accuracy: 0.7290\n",
      "Epoch 719/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8492 - accuracy: 0.7934 - val_loss: 0.9948 - val_accuracy: 0.7290\n",
      "Epoch 720/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8494 - accuracy: 0.7921 - val_loss: 0.9856 - val_accuracy: 0.7260\n",
      "Epoch 721/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8488 - accuracy: 0.7923 - val_loss: 0.9895 - val_accuracy: 0.7310\n",
      "Epoch 722/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8468 - accuracy: 0.7957 - val_loss: 0.9827 - val_accuracy: 0.7360\n",
      "Epoch 723/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8508 - accuracy: 0.7914 - val_loss: 0.9916 - val_accuracy: 0.7300\n",
      "Epoch 724/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8491 - accuracy: 0.7927 - val_loss: 1.0187 - val_accuracy: 0.7170\n",
      "Epoch 725/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8515 - accuracy: 0.7934 - val_loss: 0.9833 - val_accuracy: 0.7300\n",
      "Epoch 726/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8492 - accuracy: 0.7939 - val_loss: 1.0057 - val_accuracy: 0.7280\n",
      "Epoch 727/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8482 - accuracy: 0.7953 - val_loss: 0.9814 - val_accuracy: 0.7280\n",
      "Epoch 728/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8491 - accuracy: 0.7940 - val_loss: 1.0252 - val_accuracy: 0.7080\n",
      "Epoch 729/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8498 - accuracy: 0.7936 - val_loss: 1.0178 - val_accuracy: 0.7150\n",
      "Epoch 730/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8482 - accuracy: 0.7947 - val_loss: 0.9869 - val_accuracy: 0.7280\n",
      "Epoch 731/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8502 - accuracy: 0.7953 - val_loss: 0.9845 - val_accuracy: 0.7280\n",
      "Epoch 732/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8472 - accuracy: 0.7951 - val_loss: 0.9823 - val_accuracy: 0.7320\n",
      "Epoch 733/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8465 - accuracy: 0.7966 - val_loss: 0.9813 - val_accuracy: 0.7240\n",
      "Epoch 734/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8476 - accuracy: 0.7946 - val_loss: 0.9797 - val_accuracy: 0.7260\n",
      "Epoch 735/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8477 - accuracy: 0.7929 - val_loss: 0.9779 - val_accuracy: 0.7360\n",
      "Epoch 736/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8468 - accuracy: 0.7936 - val_loss: 0.9874 - val_accuracy: 0.7290\n",
      "Epoch 737/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8466 - accuracy: 0.7936 - val_loss: 0.9792 - val_accuracy: 0.7320\n",
      "Epoch 738/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8490 - accuracy: 0.7959 - val_loss: 0.9980 - val_accuracy: 0.7220\n",
      "Epoch 739/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8492 - accuracy: 0.7963 - val_loss: 0.9878 - val_accuracy: 0.7310\n",
      "Epoch 740/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8467 - accuracy: 0.7944 - val_loss: 0.9846 - val_accuracy: 0.7370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8474 - accuracy: 0.7956 - val_loss: 0.9912 - val_accuracy: 0.7370\n",
      "Epoch 742/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8458 - accuracy: 0.79 - 0s 4ms/step - loss: 0.8462 - accuracy: 0.7959 - val_loss: 0.9841 - val_accuracy: 0.7300\n",
      "Epoch 743/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8479 - accuracy: 0.7937 - val_loss: 1.0120 - val_accuracy: 0.7270\n",
      "Epoch 744/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8453 - accuracy: 0.7960 - val_loss: 1.0102 - val_accuracy: 0.7220\n",
      "Epoch 745/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8471 - accuracy: 0.7941 - val_loss: 0.9815 - val_accuracy: 0.7310\n",
      "Epoch 746/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8485 - accuracy: 0.7966 - val_loss: 0.9971 - val_accuracy: 0.7300\n",
      "Epoch 747/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8456 - accuracy: 0.7949 - val_loss: 0.9886 - val_accuracy: 0.7310\n",
      "Epoch 748/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8453 - accuracy: 0.7980 - val_loss: 1.0057 - val_accuracy: 0.7060\n",
      "Epoch 749/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8471 - accuracy: 0.7949 - val_loss: 0.9827 - val_accuracy: 0.7370\n",
      "Epoch 750/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8460 - accuracy: 0.7956 - val_loss: 0.9833 - val_accuracy: 0.7340\n",
      "Epoch 751/1000\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8455 - accuracy: 0.7954 - val_loss: 0.9799 - val_accuracy: 0.7280\n",
      "Epoch 752/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8443 - accuracy: 0.7946 - val_loss: 0.9945 - val_accuracy: 0.7390\n",
      "Epoch 753/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8489 - accuracy: 0.7969 - val_loss: 0.9943 - val_accuracy: 0.7360\n",
      "Epoch 754/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8454 - accuracy: 0.7943 - val_loss: 0.9942 - val_accuracy: 0.7340\n",
      "Epoch 755/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8459 - accuracy: 0.7947 - val_loss: 0.9822 - val_accuracy: 0.7420\n",
      "Epoch 756/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8445 - accuracy: 0.7960 - val_loss: 1.0318 - val_accuracy: 0.7180\n",
      "Epoch 757/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8458 - accuracy: 0.7964 - val_loss: 0.9872 - val_accuracy: 0.7380\n",
      "Epoch 758/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8449 - accuracy: 0.7964 - val_loss: 0.9821 - val_accuracy: 0.7270\n",
      "Epoch 759/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8433 - accuracy: 0.7960 - val_loss: 0.9801 - val_accuracy: 0.7350\n",
      "Epoch 760/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8432 - accuracy: 0.7974 - val_loss: 0.9829 - val_accuracy: 0.7290\n",
      "Epoch 761/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8427 - accuracy: 0.7953 - val_loss: 0.9987 - val_accuracy: 0.7430\n",
      "Epoch 762/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8456 - accuracy: 0.7963 - val_loss: 0.9902 - val_accuracy: 0.7370\n",
      "Epoch 763/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8448 - accuracy: 0.7939 - val_loss: 1.0395 - val_accuracy: 0.7120\n",
      "Epoch 764/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8472 - accuracy: 0.7953 - val_loss: 0.9932 - val_accuracy: 0.7360\n",
      "Epoch 765/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8428 - accuracy: 0.7971 - val_loss: 0.9987 - val_accuracy: 0.7260\n",
      "Epoch 766/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8467 - accuracy: 0.7967 - val_loss: 1.0017 - val_accuracy: 0.7170\n",
      "Epoch 767/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8447 - accuracy: 0.7944 - val_loss: 0.9882 - val_accuracy: 0.7270\n",
      "Epoch 768/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8422 - accuracy: 0.7989 - val_loss: 0.9969 - val_accuracy: 0.7320\n",
      "Epoch 769/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8474 - accuracy: 0.7954 - val_loss: 0.9949 - val_accuracy: 0.7330\n",
      "Epoch 770/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8440 - accuracy: 0.7959 - val_loss: 0.9857 - val_accuracy: 0.7310\n",
      "Epoch 771/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8425 - accuracy: 0.7969 - val_loss: 0.9883 - val_accuracy: 0.7250\n",
      "Epoch 772/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8431 - accuracy: 0.7980 - val_loss: 0.9986 - val_accuracy: 0.7220\n",
      "Epoch 773/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8423 - accuracy: 0.7951 - val_loss: 0.9874 - val_accuracy: 0.7280\n",
      "Epoch 774/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8436 - accuracy: 0.7949 - val_loss: 1.0069 - val_accuracy: 0.7280\n",
      "Epoch 775/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8460 - accuracy: 0.7953 - val_loss: 0.9923 - val_accuracy: 0.7320\n",
      "Epoch 776/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8422 - accuracy: 0.7956 - val_loss: 1.0183 - val_accuracy: 0.7190\n",
      "Epoch 777/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8447 - accuracy: 0.7967 - val_loss: 0.9838 - val_accuracy: 0.7300\n",
      "Epoch 778/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8411 - accuracy: 0.7993 - val_loss: 0.9912 - val_accuracy: 0.7310\n",
      "Epoch 779/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8408 - accuracy: 0.8020 - val_loss: 0.9870 - val_accuracy: 0.7300\n",
      "Epoch 780/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8399 - accuracy: 0.7971 - val_loss: 1.0181 - val_accuracy: 0.7100\n",
      "Epoch 781/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8419 - accuracy: 0.7981 - val_loss: 0.9837 - val_accuracy: 0.7290\n",
      "Epoch 782/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8411 - accuracy: 0.7973 - val_loss: 0.9961 - val_accuracy: 0.7420\n",
      "Epoch 783/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8413 - accuracy: 0.7990 - val_loss: 1.0102 - val_accuracy: 0.7210\n",
      "Epoch 784/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8432 - accuracy: 0.7959 - val_loss: 0.9927 - val_accuracy: 0.7300\n",
      "Epoch 785/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8405 - accuracy: 0.7986 - val_loss: 0.9948 - val_accuracy: 0.7330\n",
      "Epoch 786/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8400 - accuracy: 0.7971 - val_loss: 0.9857 - val_accuracy: 0.7410\n",
      "Epoch 787/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8403 - accuracy: 0.7979 - val_loss: 0.9972 - val_accuracy: 0.7370\n",
      "Epoch 788/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8418 - accuracy: 0.7970 - val_loss: 0.9885 - val_accuracy: 0.7250\n",
      "Epoch 789/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8391 - accuracy: 0.7960 - val_loss: 1.0079 - val_accuracy: 0.7350\n",
      "Epoch 790/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8399 - accuracy: 0.8001 - val_loss: 0.9843 - val_accuracy: 0.7300\n",
      "Epoch 791/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8386 - accuracy: 0.7990 - val_loss: 1.0059 - val_accuracy: 0.7330\n",
      "Epoch 792/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8410 - accuracy: 0.7980 - val_loss: 0.9879 - val_accuracy: 0.7290\n",
      "Epoch 793/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8393 - accuracy: 0.7974 - val_loss: 0.9841 - val_accuracy: 0.7290\n",
      "Epoch 794/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8394 - accuracy: 0.7996 - val_loss: 0.9859 - val_accuracy: 0.7330\n",
      "Epoch 795/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8378 - accuracy: 0.8007 - val_loss: 1.0116 - val_accuracy: 0.7320\n",
      "Epoch 796/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8405 - accuracy: 0.7943 - val_loss: 0.9873 - val_accuracy: 0.7310\n",
      "Epoch 797/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8370 - accuracy: 0.7989 - val_loss: 1.0444 - val_accuracy: 0.7080\n",
      "Epoch 798/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8403 - accuracy: 0.7974 - val_loss: 0.9832 - val_accuracy: 0.7370\n",
      "Epoch 799/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8364 - accuracy: 0.8003 - val_loss: 0.9910 - val_accuracy: 0.7420\n",
      "Epoch 800/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8381 - accuracy: 0.7999 - val_loss: 0.9844 - val_accuracy: 0.7330\n",
      "Epoch 801/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8394 - accuracy: 0.7981 - val_loss: 0.9892 - val_accuracy: 0.7340\n",
      "Epoch 802/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8418 - accuracy: 0.8006 - val_loss: 1.0448 - val_accuracy: 0.7100\n",
      "Epoch 803/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8403 - accuracy: 0.7980 - val_loss: 0.9896 - val_accuracy: 0.7240\n",
      "Epoch 804/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8370 - accuracy: 0.7996 - val_loss: 1.0014 - val_accuracy: 0.7370\n",
      "Epoch 805/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8381 - accuracy: 0.7991 - val_loss: 1.0226 - val_accuracy: 0.7130\n",
      "Epoch 806/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8383 - accuracy: 0.8006 - val_loss: 0.9820 - val_accuracy: 0.7330\n",
      "Epoch 807/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8362 - accuracy: 0.8034 - val_loss: 0.9916 - val_accuracy: 0.7260\n",
      "Epoch 808/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8397 - accuracy: 0.7970 - val_loss: 0.9892 - val_accuracy: 0.7330\n",
      "Epoch 809/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8356 - accuracy: 0.7991 - val_loss: 1.0043 - val_accuracy: 0.7300\n",
      "Epoch 810/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8383 - accuracy: 0.7999 - val_loss: 0.9915 - val_accuracy: 0.7330\n",
      "Epoch 811/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8375 - accuracy: 0.7977 - val_loss: 0.9894 - val_accuracy: 0.7350\n",
      "Epoch 812/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8401 - accuracy: 0.7969 - val_loss: 0.9798 - val_accuracy: 0.7340\n",
      "Epoch 813/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8380 - accuracy: 0.7996 - val_loss: 0.9915 - val_accuracy: 0.7300\n",
      "Epoch 814/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8361 - accuracy: 0.7993 - val_loss: 0.9838 - val_accuracy: 0.7340\n",
      "Epoch 815/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8382 - accuracy: 0.8017 - val_loss: 0.9770 - val_accuracy: 0.7270\n",
      "Epoch 816/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8336 - accuracy: 0.8017 - val_loss: 0.9886 - val_accuracy: 0.7310\n",
      "Epoch 817/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8350 - accuracy: 0.8010 - val_loss: 1.0150 - val_accuracy: 0.7190\n",
      "Epoch 818/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8401 - accuracy: 0.8001 - val_loss: 0.9819 - val_accuracy: 0.7350\n",
      "Epoch 819/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8346 - accuracy: 0.8029 - val_loss: 0.9915 - val_accuracy: 0.7320\n",
      "Epoch 820/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8416 - accuracy: 0.7960 - val_loss: 0.9962 - val_accuracy: 0.7380\n",
      "Epoch 821/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8351 - accuracy: 0.8009 - val_loss: 0.9865 - val_accuracy: 0.7290\n",
      "Epoch 822/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8330 - accuracy: 0.8037 - val_loss: 1.0189 - val_accuracy: 0.7190\n",
      "Epoch 823/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8369 - accuracy: 0.8023 - val_loss: 0.9876 - val_accuracy: 0.7310\n",
      "Epoch 824/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8345 - accuracy: 0.8013 - val_loss: 0.9924 - val_accuracy: 0.7340\n",
      "Epoch 825/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8361 - accuracy: 0.8016 - val_loss: 0.9902 - val_accuracy: 0.7340\n",
      "Epoch 826/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8334 - accuracy: 0.8004 - val_loss: 1.0070 - val_accuracy: 0.7320\n",
      "Epoch 827/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8357 - accuracy: 0.7987 - val_loss: 1.0203 - val_accuracy: 0.7200\n",
      "Epoch 828/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8345 - accuracy: 0.8010 - val_loss: 1.0141 - val_accuracy: 0.7200\n",
      "Epoch 829/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8353 - accuracy: 0.8027 - val_loss: 0.9835 - val_accuracy: 0.7350\n",
      "Epoch 830/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8364 - accuracy: 0.8007 - val_loss: 0.9936 - val_accuracy: 0.7370\n",
      "Epoch 831/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8331 - accuracy: 0.8027 - val_loss: 0.9836 - val_accuracy: 0.7310\n",
      "Epoch 832/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8342 - accuracy: 0.8014 - val_loss: 0.9806 - val_accuracy: 0.7410\n",
      "Epoch 833/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8337 - accuracy: 0.7997 - val_loss: 0.9782 - val_accuracy: 0.7330\n",
      "Epoch 834/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8341 - accuracy: 0.7980 - val_loss: 0.9818 - val_accuracy: 0.7360\n",
      "Epoch 835/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8337 - accuracy: 0.7996 - val_loss: 1.0071 - val_accuracy: 0.7360\n",
      "Epoch 836/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8351 - accuracy: 0.8009 - val_loss: 0.9967 - val_accuracy: 0.7440\n",
      "Epoch 837/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8330 - accuracy: 0.8020 - val_loss: 0.9801 - val_accuracy: 0.7400\n",
      "Epoch 838/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8350 - accuracy: 0.8021 - val_loss: 0.9890 - val_accuracy: 0.7350\n",
      "Epoch 839/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8310 - accuracy: 0.8036 - val_loss: 0.9804 - val_accuracy: 0.7330\n",
      "Epoch 840/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8317 - accuracy: 0.8033 - val_loss: 0.9877 - val_accuracy: 0.7380\n",
      "Epoch 841/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8312 - accuracy: 0.8029 - val_loss: 0.9779 - val_accuracy: 0.7300\n",
      "Epoch 842/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8326 - accuracy: 0.8027 - val_loss: 1.0240 - val_accuracy: 0.7240\n",
      "Epoch 843/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8362 - accuracy: 0.7990 - val_loss: 0.9793 - val_accuracy: 0.7330\n",
      "Epoch 844/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8315 - accuracy: 0.8020 - val_loss: 0.9897 - val_accuracy: 0.7280\n",
      "Epoch 845/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8329 - accuracy: 0.8043 - val_loss: 0.9994 - val_accuracy: 0.7320\n",
      "Epoch 846/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8390 - accuracy: 0.7999 - val_loss: 1.0134 - val_accuracy: 0.7350\n",
      "Epoch 847/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8350 - accuracy: 0.8011 - val_loss: 0.9898 - val_accuracy: 0.7320\n",
      "Epoch 848/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8355 - accuracy: 0.8010 - val_loss: 0.9931 - val_accuracy: 0.7340\n",
      "Epoch 849/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8308 - accuracy: 0.8026 - val_loss: 0.9833 - val_accuracy: 0.7370\n",
      "Epoch 850/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8292 - accuracy: 0.8049 - val_loss: 0.9822 - val_accuracy: 0.7360\n",
      "Epoch 851/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8343 - accuracy: 0.8029 - val_loss: 0.9839 - val_accuracy: 0.7430\n",
      "Epoch 852/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8309 - accuracy: 0.8044 - val_loss: 0.9832 - val_accuracy: 0.7320\n",
      "Epoch 853/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8348 - accuracy: 0.7994 - val_loss: 0.9808 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 854/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8305 - accuracy: 0.8029 - val_loss: 0.9947 - val_accuracy: 0.7280\n",
      "Epoch 855/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8297 - accuracy: 0.8057 - val_loss: 0.9846 - val_accuracy: 0.7330\n",
      "Epoch 856/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8327 - accuracy: 0.8037 - val_loss: 0.9855 - val_accuracy: 0.7360\n",
      "Epoch 857/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8309 - accuracy: 0.8039 - val_loss: 0.9997 - val_accuracy: 0.7270\n",
      "Epoch 858/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8329 - accuracy: 0.8051 - val_loss: 1.0100 - val_accuracy: 0.7250\n",
      "Epoch 859/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8354 - accuracy: 0.7993 - val_loss: 0.9799 - val_accuracy: 0.7410\n",
      "Epoch 860/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8296 - accuracy: 0.8051 - val_loss: 0.9811 - val_accuracy: 0.7330\n",
      "Epoch 861/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8297 - accuracy: 0.8034 - val_loss: 0.9795 - val_accuracy: 0.7420\n",
      "Epoch 862/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8308 - accuracy: 0.8040 - val_loss: 0.9899 - val_accuracy: 0.7300\n",
      "Epoch 863/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8292 - accuracy: 0.8001 - val_loss: 1.0042 - val_accuracy: 0.7340\n",
      "Epoch 864/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8341 - accuracy: 0.8024 - val_loss: 0.9959 - val_accuracy: 0.7350\n",
      "Epoch 865/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8291 - accuracy: 0.8019 - val_loss: 0.9816 - val_accuracy: 0.7340\n",
      "Epoch 866/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8296 - accuracy: 0.8040 - val_loss: 1.0013 - val_accuracy: 0.7230\n",
      "Epoch 867/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8297 - accuracy: 0.8017 - val_loss: 1.0183 - val_accuracy: 0.7230\n",
      "Epoch 868/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8342 - accuracy: 0.8026 - val_loss: 1.0074 - val_accuracy: 0.7260\n",
      "Epoch 869/1000\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.8265 - accuracy: 0.8053 - val_loss: 0.9921 - val_accuracy: 0.7350\n",
      "Epoch 870/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8285 - accuracy: 0.8073 - val_loss: 0.9798 - val_accuracy: 0.7350\n",
      "Epoch 871/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8286 - accuracy: 0.8034 - val_loss: 1.0015 - val_accuracy: 0.7320\n",
      "Epoch 872/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8318 - accuracy: 0.8069 - val_loss: 1.0010 - val_accuracy: 0.7340\n",
      "Epoch 873/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8288 - accuracy: 0.8024 - val_loss: 1.0004 - val_accuracy: 0.7340\n",
      "Epoch 874/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8363 - accuracy: 0.7990 - val_loss: 0.9892 - val_accuracy: 0.7390\n",
      "Epoch 875/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8269 - accuracy: 0.8056 - val_loss: 1.0072 - val_accuracy: 0.7310\n",
      "Epoch 876/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8308 - accuracy: 0.8056 - val_loss: 0.9977 - val_accuracy: 0.7340\n",
      "Epoch 877/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8303 - accuracy: 0.8050 - val_loss: 0.9893 - val_accuracy: 0.7330\n",
      "Epoch 878/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8286 - accuracy: 0.8067 - val_loss: 0.9921 - val_accuracy: 0.7370\n",
      "Epoch 879/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8278 - accuracy: 0.8043 - val_loss: 0.9955 - val_accuracy: 0.7320\n",
      "Epoch 880/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8262 - accuracy: 0.8071 - val_loss: 0.9981 - val_accuracy: 0.7350\n",
      "Epoch 881/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8285 - accuracy: 0.8046 - val_loss: 1.0833 - val_accuracy: 0.7000\n",
      "Epoch 882/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8307 - accuracy: 0.8033 - val_loss: 1.0036 - val_accuracy: 0.7370\n",
      "Epoch 883/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8309 - accuracy: 0.8036 - val_loss: 0.9861 - val_accuracy: 0.7380\n",
      "Epoch 884/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8320 - accuracy: 0.8040 - val_loss: 0.9942 - val_accuracy: 0.7340\n",
      "Epoch 885/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8254 - accuracy: 0.8050 - val_loss: 0.9987 - val_accuracy: 0.7300\n",
      "Epoch 886/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8298 - accuracy: 0.8057 - val_loss: 1.0205 - val_accuracy: 0.7270\n",
      "Epoch 887/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8258 - accuracy: 0.8076 - val_loss: 0.9880 - val_accuracy: 0.7380\n",
      "Epoch 888/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8291 - accuracy: 0.8029 - val_loss: 0.9853 - val_accuracy: 0.7400\n",
      "Epoch 889/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8269 - accuracy: 0.8087 - val_loss: 0.9893 - val_accuracy: 0.7380\n",
      "Epoch 890/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8257 - accuracy: 0.8056 - val_loss: 0.9941 - val_accuracy: 0.7340\n",
      "Epoch 891/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8262 - accuracy: 0.8077 - val_loss: 0.9806 - val_accuracy: 0.7370\n",
      "Epoch 892/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8256 - accuracy: 0.8090 - val_loss: 1.0194 - val_accuracy: 0.7300\n",
      "Epoch 893/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8257 - accuracy: 0.8070 - val_loss: 0.9990 - val_accuracy: 0.7340\n",
      "Epoch 894/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8293 - accuracy: 0.8057 - val_loss: 0.9996 - val_accuracy: 0.7330\n",
      "Epoch 895/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8276 - accuracy: 0.8044 - val_loss: 1.0011 - val_accuracy: 0.7270\n",
      "Epoch 896/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8285 - accuracy: 0.8083 - val_loss: 1.1819 - val_accuracy: 0.6730\n",
      "Epoch 897/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8428 - accuracy: 0.7980 - val_loss: 1.0034 - val_accuracy: 0.7330\n",
      "Epoch 898/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8261 - accuracy: 0.8076 - val_loss: 0.9833 - val_accuracy: 0.7380\n",
      "Epoch 899/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8223 - accuracy: 0.8101 - val_loss: 0.9865 - val_accuracy: 0.7380\n",
      "Epoch 900/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8302 - accuracy: 0.8030 - val_loss: 0.9947 - val_accuracy: 0.7260\n",
      "Epoch 901/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8232 - accuracy: 0.8066 - val_loss: 0.9799 - val_accuracy: 0.7450\n",
      "Epoch 902/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8299 - accuracy: 0.7999 - val_loss: 0.9945 - val_accuracy: 0.7320\n",
      "Epoch 903/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8271 - accuracy: 0.8060 - val_loss: 0.9870 - val_accuracy: 0.7250\n",
      "Epoch 904/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8247 - accuracy: 0.8060 - val_loss: 1.0453 - val_accuracy: 0.7150\n",
      "Epoch 905/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8301 - accuracy: 0.8050 - val_loss: 0.9827 - val_accuracy: 0.7370\n",
      "Epoch 906/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8239 - accuracy: 0.8060 - val_loss: 0.9837 - val_accuracy: 0.7370\n",
      "Epoch 907/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8233 - accuracy: 0.8114 - val_loss: 1.0157 - val_accuracy: 0.7350\n",
      "Epoch 908/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8294 - accuracy: 0.8053 - val_loss: 0.9784 - val_accuracy: 0.7410\n",
      "Epoch 909/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8229 - accuracy: 0.8093 - val_loss: 0.9836 - val_accuracy: 0.7360\n",
      "Epoch 910/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8258 - accuracy: 0.8061 - val_loss: 0.9876 - val_accuracy: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 911/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8249 - accuracy: 0.8087 - val_loss: 1.0313 - val_accuracy: 0.7230\n",
      "Epoch 912/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8299 - accuracy: 0.8051 - val_loss: 0.9979 - val_accuracy: 0.7310\n",
      "Epoch 913/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8271 - accuracy: 0.8043 - val_loss: 0.9840 - val_accuracy: 0.7360\n",
      "Epoch 914/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8244 - accuracy: 0.8067 - val_loss: 1.0056 - val_accuracy: 0.7300\n",
      "Epoch 915/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8361 - accuracy: 0.8037 - val_loss: 1.0212 - val_accuracy: 0.7290\n",
      "Epoch 916/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8254 - accuracy: 0.8111 - val_loss: 0.9926 - val_accuracy: 0.7340\n",
      "Epoch 917/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8222 - accuracy: 0.8086 - val_loss: 0.9909 - val_accuracy: 0.7330\n",
      "Epoch 918/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8207 - accuracy: 0.8123 - val_loss: 1.0124 - val_accuracy: 0.7270\n",
      "Epoch 919/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8283 - accuracy: 0.8061 - val_loss: 0.9899 - val_accuracy: 0.7400\n",
      "Epoch 920/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8202 - accuracy: 0.8111 - val_loss: 1.0097 - val_accuracy: 0.7260\n",
      "Epoch 921/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8210 - accuracy: 0.8111 - val_loss: 1.0298 - val_accuracy: 0.7270\n",
      "Epoch 922/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8252 - accuracy: 0.8069 - val_loss: 0.9992 - val_accuracy: 0.7370\n",
      "Epoch 923/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8225 - accuracy: 0.8117 - val_loss: 0.9978 - val_accuracy: 0.7300\n",
      "Epoch 924/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8226 - accuracy: 0.8057 - val_loss: 1.0062 - val_accuracy: 0.7270\n",
      "Epoch 925/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8225 - accuracy: 0.8069 - val_loss: 0.9885 - val_accuracy: 0.7310\n",
      "Epoch 926/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8230 - accuracy: 0.8093 - val_loss: 0.9952 - val_accuracy: 0.7370\n",
      "Epoch 927/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8242 - accuracy: 0.8099 - val_loss: 0.9863 - val_accuracy: 0.7400\n",
      "Epoch 928/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8215 - accuracy: 0.8073 - val_loss: 1.0046 - val_accuracy: 0.7250\n",
      "Epoch 929/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8237 - accuracy: 0.8121 - val_loss: 0.9777 - val_accuracy: 0.7390\n",
      "Epoch 930/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8264 - accuracy: 0.8066 - val_loss: 0.9782 - val_accuracy: 0.7380\n",
      "Epoch 931/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8218 - accuracy: 0.8087 - val_loss: 0.9835 - val_accuracy: 0.7400\n",
      "Epoch 932/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8190 - accuracy: 0.8110 - val_loss: 0.9841 - val_accuracy: 0.7370\n",
      "Epoch 933/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8216 - accuracy: 0.8101 - val_loss: 0.9885 - val_accuracy: 0.7380\n",
      "Epoch 934/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8255 - accuracy: 0.8050 - val_loss: 0.9898 - val_accuracy: 0.7440\n",
      "Epoch 935/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8195 - accuracy: 0.8101 - val_loss: 0.9870 - val_accuracy: 0.7360\n",
      "Epoch 936/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8212 - accuracy: 0.8119 - val_loss: 0.9986 - val_accuracy: 0.7410\n",
      "Epoch 937/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8195 - accuracy: 0.8100 - val_loss: 1.0743 - val_accuracy: 0.7000\n",
      "Epoch 938/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8187 - accuracy: 0.8116 - val_loss: 1.0123 - val_accuracy: 0.7330\n",
      "Epoch 939/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8235 - accuracy: 0.8090 - val_loss: 0.9798 - val_accuracy: 0.7380\n",
      "Epoch 940/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8196 - accuracy: 0.8116 - val_loss: 0.9819 - val_accuracy: 0.7420\n",
      "Epoch 941/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8282 - accuracy: 0.8057 - val_loss: 1.0407 - val_accuracy: 0.7220\n",
      "Epoch 942/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8187 - accuracy: 0.8076 - val_loss: 1.0085 - val_accuracy: 0.7310\n",
      "Epoch 943/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8216 - accuracy: 0.8096 - val_loss: 0.9858 - val_accuracy: 0.7350\n",
      "Epoch 944/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8180 - accuracy: 0.8129 - val_loss: 1.0202 - val_accuracy: 0.7260\n",
      "Epoch 945/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8194 - accuracy: 0.8077 - val_loss: 1.0339 - val_accuracy: 0.7260\n",
      "Epoch 946/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8191 - accuracy: 0.8101 - val_loss: 0.9854 - val_accuracy: 0.7370\n",
      "Epoch 947/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8230 - accuracy: 0.8107 - val_loss: 0.9825 - val_accuracy: 0.7420\n",
      "Epoch 948/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8189 - accuracy: 0.8087 - val_loss: 1.0039 - val_accuracy: 0.7350\n",
      "Epoch 949/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8243 - accuracy: 0.8091 - val_loss: 1.0594 - val_accuracy: 0.7050\n",
      "Epoch 950/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8313 - accuracy: 0.8083 - val_loss: 1.0337 - val_accuracy: 0.7230\n",
      "Epoch 951/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.8099 - val_loss: 0.9824 - val_accuracy: 0.7370\n",
      "Epoch 952/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8227 - accuracy: 0.8091 - val_loss: 0.9948 - val_accuracy: 0.7410\n",
      "Epoch 953/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8164 - accuracy: 0.8127 - val_loss: 1.0061 - val_accuracy: 0.7310\n",
      "Epoch 954/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8257 - accuracy: 0.8111 - val_loss: 1.0000 - val_accuracy: 0.7340\n",
      "Epoch 955/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8191 - accuracy: 0.8123 - val_loss: 1.0136 - val_accuracy: 0.7280\n",
      "Epoch 956/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8184 - accuracy: 0.8084 - val_loss: 0.9890 - val_accuracy: 0.7340\n",
      "Epoch 957/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8226 - accuracy: 0.8070 - val_loss: 0.9798 - val_accuracy: 0.7410\n",
      "Epoch 958/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8164 - accuracy: 0.8109 - val_loss: 1.0119 - val_accuracy: 0.7330\n",
      "Epoch 959/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8175 - accuracy: 0.8121 - val_loss: 0.9843 - val_accuracy: 0.7430\n",
      "Epoch 960/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8220 - accuracy: 0.8069 - val_loss: 1.0121 - val_accuracy: 0.7350\n",
      "Epoch 961/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8162 - accuracy: 0.8107 - val_loss: 1.0717 - val_accuracy: 0.7230\n",
      "Epoch 962/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8230 - accuracy: 0.8071 - val_loss: 0.9867 - val_accuracy: 0.7360\n",
      "Epoch 963/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8160 - accuracy: 0.8111 - val_loss: 1.0076 - val_accuracy: 0.7410\n",
      "Epoch 964/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8184 - accuracy: 0.8136 - val_loss: 0.9987 - val_accuracy: 0.7360\n",
      "Epoch 965/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8172 - accuracy: 0.8117 - val_loss: 1.0202 - val_accuracy: 0.7370\n",
      "Epoch 966/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8183 - accuracy: 0.8117 - val_loss: 0.9889 - val_accuracy: 0.7380\n",
      "Epoch 967/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8209 - accuracy: 0.8111 - val_loss: 1.0405 - val_accuracy: 0.7200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 968/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8192 - accuracy: 0.8086 - val_loss: 0.9925 - val_accuracy: 0.7370\n",
      "Epoch 969/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8163 - accuracy: 0.8119 - val_loss: 1.0006 - val_accuracy: 0.7380\n",
      "Epoch 970/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8122 - accuracy: 0.8164 - val_loss: 0.9813 - val_accuracy: 0.7400\n",
      "Epoch 971/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8154 - accuracy: 0.8124 - val_loss: 0.9863 - val_accuracy: 0.7400\n",
      "Epoch 972/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8202 - accuracy: 0.8117 - val_loss: 1.0045 - val_accuracy: 0.7410\n",
      "Epoch 973/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8185 - accuracy: 0.8109 - val_loss: 0.9902 - val_accuracy: 0.7420\n",
      "Epoch 974/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.8081 - val_loss: 1.0512 - val_accuracy: 0.7210\n",
      "Epoch 975/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8175 - accuracy: 0.8149 - val_loss: 0.9956 - val_accuracy: 0.7350\n",
      "Epoch 976/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.8120 - val_loss: 0.9858 - val_accuracy: 0.7420\n",
      "Epoch 977/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8144 - accuracy: 0.8121 - val_loss: 1.0149 - val_accuracy: 0.7370\n",
      "Epoch 978/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8189 - accuracy: 0.8113 - val_loss: 1.0127 - val_accuracy: 0.7300\n",
      "Epoch 979/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8175 - accuracy: 0.8113 - val_loss: 1.0964 - val_accuracy: 0.7030\n",
      "Epoch 980/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8237 - accuracy: 0.8041 - val_loss: 0.9883 - val_accuracy: 0.7390\n",
      "Epoch 981/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8204 - accuracy: 0.8090 - val_loss: 1.0031 - val_accuracy: 0.7320\n",
      "Epoch 982/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8169 - accuracy: 0.8134 - val_loss: 0.9910 - val_accuracy: 0.7410\n",
      "Epoch 983/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8154 - accuracy: 0.8127 - val_loss: 1.0218 - val_accuracy: 0.7400\n",
      "Epoch 984/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8170 - accuracy: 0.8139 - val_loss: 0.9945 - val_accuracy: 0.7400\n",
      "Epoch 985/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8168 - accuracy: 0.8111 - val_loss: 0.9876 - val_accuracy: 0.7430\n",
      "Epoch 986/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.8125 - accuracy: 0.8139 - val_loss: 0.9993 - val_accuracy: 0.7400\n",
      "Epoch 987/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8137 - accuracy: 0.8099 - val_loss: 1.0380 - val_accuracy: 0.7330\n",
      "Epoch 988/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8175 - accuracy: 0.8159 - val_loss: 0.9839 - val_accuracy: 0.7400\n",
      "Epoch 989/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8129 - accuracy: 0.8136 - val_loss: 0.9939 - val_accuracy: 0.7390\n",
      "Epoch 990/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8173 - accuracy: 0.8119 - val_loss: 0.9806 - val_accuracy: 0.7450\n",
      "Epoch 991/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8150 - accuracy: 0.8134 - val_loss: 1.0532 - val_accuracy: 0.7110\n",
      "Epoch 992/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8205 - accuracy: 0.8094 - val_loss: 1.0377 - val_accuracy: 0.7240\n",
      "Epoch 993/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8169 - accuracy: 0.8097 - val_loss: 1.0128 - val_accuracy: 0.7360\n",
      "Epoch 994/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8133 - accuracy: 0.8133 - val_loss: 0.9987 - val_accuracy: 0.7390\n",
      "Epoch 995/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8165 - accuracy: 0.8109 - val_loss: 1.0108 - val_accuracy: 0.7310\n",
      "Epoch 996/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8130 - accuracy: 0.8143 - val_loss: 1.0152 - val_accuracy: 0.7360\n",
      "Epoch 997/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8111 - accuracy: 0.8151 - val_loss: 1.0051 - val_accuracy: 0.7410\n",
      "Epoch 998/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8156 - accuracy: 0.8123 - val_loss: 1.0023 - val_accuracy: 0.7310\n",
      "Epoch 999/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8178 - accuracy: 0.8137 - val_loss: 1.0316 - val_accuracy: 0.7330\n",
      "Epoch 1000/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8237 - accuracy: 0.8131 - val_loss: 0.9896 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=1000,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8030 - accuracy: 0.8169\n",
      "Training Loss: 0.803 Training Accuracy: 0.817\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9029 - accuracy: 0.7730\n",
      "Testing Loss: 0.903 Testing Accuracy: 0.773\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about the best result you've achieved so far, but you were training for quite a while! Next, experiment with dropout regularization to see if it offers any advantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.9826 - accuracy: 0.1331 - val_loss: 1.9468 - val_accuracy: 0.1470\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.9626 - accuracy: 0.1389 - val_loss: 1.9398 - val_accuracy: 0.1640\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.9496 - accuracy: 0.1484 - val_loss: 1.9348 - val_accuracy: 0.1860\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.9464 - accuracy: 0.1589 - val_loss: 1.9304 - val_accuracy: 0.1960\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.9381 - accuracy: 0.1637 - val_loss: 1.9267 - val_accuracy: 0.2110\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.9342 - accuracy: 0.1730 - val_loss: 1.9230 - val_accuracy: 0.2130\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.9300 - accuracy: 0.1846 - val_loss: 1.9192 - val_accuracy: 0.2210\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.9268 - accuracy: 0.1816 - val_loss: 1.9149 - val_accuracy: 0.2310\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.9210 - accuracy: 0.1917 - val_loss: 1.9104 - val_accuracy: 0.2420\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.9176 - accuracy: 0.1919 - val_loss: 1.9051 - val_accuracy: 0.2350\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.9116 - accuracy: 0.2017 - val_loss: 1.8994 - val_accuracy: 0.2410\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.9047 - accuracy: 0.2084 - val_loss: 1.8919 - val_accuracy: 0.2470\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.9045 - accuracy: 0.2066 - val_loss: 1.8845 - val_accuracy: 0.2500\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.8964 - accuracy: 0.2119 - val_loss: 1.8762 - val_accuracy: 0.2570\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.8877 - accuracy: 0.2237 - val_loss: 1.8668 - val_accuracy: 0.2730\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.8798 - accuracy: 0.2271 - val_loss: 1.8561 - val_accuracy: 0.2800\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.8728 - accuracy: 0.2291 - val_loss: 1.8437 - val_accuracy: 0.2920\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.8651 - accuracy: 0.2300 - val_loss: 1.8318 - val_accuracy: 0.3020\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.8603 - accuracy: 0.2407 - val_loss: 1.8195 - val_accuracy: 0.3130\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.8491 - accuracy: 0.2500 - val_loss: 1.8060 - val_accuracy: 0.3220\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.8372 - accuracy: 0.2504 - val_loss: 1.7917 - val_accuracy: 0.3280\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.8243 - accuracy: 0.2639 - val_loss: 1.7747 - val_accuracy: 0.3420\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.8189 - accuracy: 0.2749 - val_loss: 1.7594 - val_accuracy: 0.3480\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.8097 - accuracy: 0.2650 - val_loss: 1.7433 - val_accuracy: 0.3610\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.7932 - accuracy: 0.2731 - val_loss: 1.7254 - val_accuracy: 0.3730\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.7754 - accuracy: 0.2869 - val_loss: 1.7069 - val_accuracy: 0.3830\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.7715 - accuracy: 0.2811 - val_loss: 1.6895 - val_accuracy: 0.3910\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.7545 - accuracy: 0.2986 - val_loss: 1.6713 - val_accuracy: 0.3980\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.7469 - accuracy: 0.3010 - val_loss: 1.6543 - val_accuracy: 0.4070\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.7249 - accuracy: 0.3027 - val_loss: 1.6355 - val_accuracy: 0.4110\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.7152 - accuracy: 0.3083 - val_loss: 1.6188 - val_accuracy: 0.4140\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.7048 - accuracy: 0.3156 - val_loss: 1.5994 - val_accuracy: 0.4260\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.6961 - accuracy: 0.3210 - val_loss: 1.5805 - val_accuracy: 0.4340\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.6767 - accuracy: 0.3280 - val_loss: 1.5631 - val_accuracy: 0.4350\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.6661 - accuracy: 0.3293 - val_loss: 1.5468 - val_accuracy: 0.4410\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.6465 - accuracy: 0.3391 - val_loss: 1.5244 - val_accuracy: 0.4390\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.6308 - accuracy: 0.3479 - val_loss: 1.5046 - val_accuracy: 0.4510\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.6273 - accuracy: 0.3446 - val_loss: 1.4893 - val_accuracy: 0.4630\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.6157 - accuracy: 0.3521 - val_loss: 1.4740 - val_accuracy: 0.4770\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.6055 - accuracy: 0.3534 - val_loss: 1.4578 - val_accuracy: 0.4900\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.5889 - accuracy: 0.3670 - val_loss: 1.4416 - val_accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.5760 - accuracy: 0.3756 - val_loss: 1.4271 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.5680 - accuracy: 0.3759 - val_loss: 1.4075 - val_accuracy: 0.5200\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.5597 - accuracy: 0.3780 - val_loss: 1.3931 - val_accuracy: 0.5380\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.5507 - accuracy: 0.3869 - val_loss: 1.3804 - val_accuracy: 0.5500\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.5269 - accuracy: 0.3949 - val_loss: 1.3637 - val_accuracy: 0.5530\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.5154 - accuracy: 0.4021 - val_loss: 1.3531 - val_accuracy: 0.5580\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.5071 - accuracy: 0.3979 - val_loss: 1.3380 - val_accuracy: 0.5700\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.4922 - accuracy: 0.4076 - val_loss: 1.3243 - val_accuracy: 0.5730\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.4913 - accuracy: 0.4091 - val_loss: 1.3085 - val_accuracy: 0.5860\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.4756 - accuracy: 0.4166 - val_loss: 1.2924 - val_accuracy: 0.5840\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.4678 - accuracy: 0.4206 - val_loss: 1.2820 - val_accuracy: 0.5930\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.4544 - accuracy: 0.4266 - val_loss: 1.2694 - val_accuracy: 0.5950\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.4418 - accuracy: 0.4321 - val_loss: 1.2585 - val_accuracy: 0.5990\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.4322 - accuracy: 0.4381 - val_loss: 1.2457 - val_accuracy: 0.6050\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.4227 - accuracy: 0.4400 - val_loss: 1.2317 - val_accuracy: 0.6080\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.4236 - accuracy: 0.4409 - val_loss: 1.2231 - val_accuracy: 0.6150\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.4070 - accuracy: 0.4441 - val_loss: 1.2121 - val_accuracy: 0.6220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.4036 - accuracy: 0.4383 - val_loss: 1.2028 - val_accuracy: 0.6230\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.3848 - accuracy: 0.4584 - val_loss: 1.1891 - val_accuracy: 0.6310\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.3853 - accuracy: 0.4569 - val_loss: 1.1810 - val_accuracy: 0.6390\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.3700 - accuracy: 0.4649 - val_loss: 1.1692 - val_accuracy: 0.6380\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.3537 - accuracy: 0.4669 - val_loss: 1.1596 - val_accuracy: 0.6420\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.3442 - accuracy: 0.4770 - val_loss: 1.1475 - val_accuracy: 0.6440\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.3423 - accuracy: 0.4783 - val_loss: 1.1374 - val_accuracy: 0.6470\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.3327 - accuracy: 0.4824 - val_loss: 1.1296 - val_accuracy: 0.6470\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.3237 - accuracy: 0.4867 - val_loss: 1.1205 - val_accuracy: 0.6560\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.3150 - accuracy: 0.4877 - val_loss: 1.1112 - val_accuracy: 0.6520\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.3112 - accuracy: 0.4870 - val_loss: 1.1021 - val_accuracy: 0.6570\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.2986 - accuracy: 0.4920 - val_loss: 1.0956 - val_accuracy: 0.6550\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.2975 - accuracy: 0.4891 - val_loss: 1.0850 - val_accuracy: 0.6650\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.2786 - accuracy: 0.4993 - val_loss: 1.0769 - val_accuracy: 0.6630\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.2816 - accuracy: 0.4943 - val_loss: 1.0681 - val_accuracy: 0.6690\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.2695 - accuracy: 0.5093 - val_loss: 1.0592 - val_accuracy: 0.6680\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.2584 - accuracy: 0.5177 - val_loss: 1.0522 - val_accuracy: 0.6710\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.2535 - accuracy: 0.5159 - val_loss: 1.0465 - val_accuracy: 0.6690\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.2489 - accuracy: 0.5151 - val_loss: 1.0381 - val_accuracy: 0.6760\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.2362 - accuracy: 0.5123 - val_loss: 1.0309 - val_accuracy: 0.6730\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.2400 - accuracy: 0.5136 - val_loss: 1.0259 - val_accuracy: 0.6760\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.2346 - accuracy: 0.5183 - val_loss: 1.0153 - val_accuracy: 0.6760\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.2240 - accuracy: 0.5133 - val_loss: 1.0087 - val_accuracy: 0.6800\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.2319 - accuracy: 0.5230 - val_loss: 1.0053 - val_accuracy: 0.6860\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.2168 - accuracy: 0.5269 - val_loss: 0.9993 - val_accuracy: 0.6810\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.2176 - accuracy: 0.5310 - val_loss: 0.9948 - val_accuracy: 0.6830\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.2088 - accuracy: 0.5366 - val_loss: 0.9859 - val_accuracy: 0.6860\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.2038 - accuracy: 0.5387 - val_loss: 0.9837 - val_accuracy: 0.6870\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.1912 - accuracy: 0.5334 - val_loss: 0.9794 - val_accuracy: 0.6880\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.1875 - accuracy: 0.5376 - val_loss: 0.9708 - val_accuracy: 0.6910\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1793 - accuracy: 0.5417 - val_loss: 0.9617 - val_accuracy: 0.6910\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1772 - accuracy: 0.5551 - val_loss: 0.9579 - val_accuracy: 0.6880\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1821 - accuracy: 0.5490 - val_loss: 0.9553 - val_accuracy: 0.6910\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1641 - accuracy: 0.5591 - val_loss: 0.9480 - val_accuracy: 0.6900\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1557 - accuracy: 0.5563 - val_loss: 0.9409 - val_accuracy: 0.6920\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.1391 - accuracy: 0.5634 - val_loss: 0.9353 - val_accuracy: 0.6930\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1468 - accuracy: 0.5597 - val_loss: 0.9291 - val_accuracy: 0.6960\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1471 - accuracy: 0.5530 - val_loss: 0.9265 - val_accuracy: 0.6930\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.1401 - accuracy: 0.5580 - val_loss: 0.9205 - val_accuracy: 0.6960\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1464 - accuracy: 0.5597 - val_loss: 0.9151 - val_accuracy: 0.7000\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1360 - accuracy: 0.5680 - val_loss: 0.9110 - val_accuracy: 0.7000\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1295 - accuracy: 0.5710 - val_loss: 0.9070 - val_accuracy: 0.7020\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.1151 - accuracy: 0.5647 - val_loss: 0.9017 - val_accuracy: 0.7010\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.1117 - accuracy: 0.5757 - val_loss: 0.8985 - val_accuracy: 0.7030\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.1128 - accuracy: 0.5780 - val_loss: 0.8939 - val_accuracy: 0.7030\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.0990 - accuracy: 0.5824 - val_loss: 0.8905 - val_accuracy: 0.7030\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.1037 - accuracy: 0.5834 - val_loss: 0.8861 - val_accuracy: 0.7060\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.1131 - accuracy: 0.5797 - val_loss: 0.8832 - val_accuracy: 0.7020\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0998 - accuracy: 0.5797 - val_loss: 0.8779 - val_accuracy: 0.7070\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0854 - accuracy: 0.5951 - val_loss: 0.8751 - val_accuracy: 0.7050\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0765 - accuracy: 0.5953 - val_loss: 0.8691 - val_accuracy: 0.7070\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0709 - accuracy: 0.5933 - val_loss: 0.8630 - val_accuracy: 0.7080\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0687 - accuracy: 0.5987 - val_loss: 0.8586 - val_accuracy: 0.7120\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0734 - accuracy: 0.5944 - val_loss: 0.8542 - val_accuracy: 0.7070\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0754 - accuracy: 0.5840 - val_loss: 0.8545 - val_accuracy: 0.7080\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0649 - accuracy: 0.5950 - val_loss: 0.8496 - val_accuracy: 0.7110\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0655 - accuracy: 0.5993 - val_loss: 0.8497 - val_accuracy: 0.7090\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0490 - accuracy: 0.5997 - val_loss: 0.8433 - val_accuracy: 0.7120\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0560 - accuracy: 0.6069 - val_loss: 0.8411 - val_accuracy: 0.7130\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0328 - accuracy: 0.6114 - val_loss: 0.8356 - val_accuracy: 0.7130\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0410 - accuracy: 0.6123 - val_loss: 0.8339 - val_accuracy: 0.7090\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0271 - accuracy: 0.6126 - val_loss: 0.8278 - val_accuracy: 0.7110\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0427 - accuracy: 0.6019 - val_loss: 0.8268 - val_accuracy: 0.7130\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0480 - accuracy: 0.6056 - val_loss: 0.8264 - val_accuracy: 0.7170\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0215 - accuracy: 0.6160 - val_loss: 0.8215 - val_accuracy: 0.7150\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0285 - accuracy: 0.6136 - val_loss: 0.8174 - val_accuracy: 0.7180\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0193 - accuracy: 0.6106 - val_loss: 0.8154 - val_accuracy: 0.7130\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0364 - accuracy: 0.6161 - val_loss: 0.8128 - val_accuracy: 0.7150\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0172 - accuracy: 0.6160 - val_loss: 0.8099 - val_accuracy: 0.7120\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0095 - accuracy: 0.6306 - val_loss: 0.8067 - val_accuracy: 0.7150\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0000 - accuracy: 0.6251 - val_loss: 0.8037 - val_accuracy: 0.7150\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0073 - accuracy: 0.6223 - val_loss: 0.8011 - val_accuracy: 0.7130\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0031 - accuracy: 0.6264 - val_loss: 0.7964 - val_accuracy: 0.7130\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9833 - accuracy: 0.6329 - val_loss: 0.7931 - val_accuracy: 0.7200\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.6209 - val_loss: 0.7919 - val_accuracy: 0.7150\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9972 - accuracy: 0.6231 - val_loss: 0.7889 - val_accuracy: 0.7180\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9783 - accuracy: 0.6343 - val_loss: 0.7862 - val_accuracy: 0.7220\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9818 - accuracy: 0.6386 - val_loss: 0.7849 - val_accuracy: 0.7170\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9770 - accuracy: 0.6376 - val_loss: 0.7816 - val_accuracy: 0.7160\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9903 - accuracy: 0.6334 - val_loss: 0.7805 - val_accuracy: 0.7150\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9690 - accuracy: 0.6357 - val_loss: 0.7771 - val_accuracy: 0.7170\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9736 - accuracy: 0.6404 - val_loss: 0.7735 - val_accuracy: 0.7170\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9562 - accuracy: 0.6453 - val_loss: 0.7688 - val_accuracy: 0.7160\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9674 - accuracy: 0.6361 - val_loss: 0.7679 - val_accuracy: 0.7150\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9606 - accuracy: 0.6440 - val_loss: 0.7643 - val_accuracy: 0.7190\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9535 - accuracy: 0.6401 - val_loss: 0.7622 - val_accuracy: 0.7210\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9520 - accuracy: 0.6491 - val_loss: 0.7606 - val_accuracy: 0.7140\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9478 - accuracy: 0.6387 - val_loss: 0.7582 - val_accuracy: 0.7180\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9517 - accuracy: 0.6444 - val_loss: 0.7554 - val_accuracy: 0.7170\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9441 - accuracy: 0.6591 - val_loss: 0.7528 - val_accuracy: 0.7180\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.9517 - accuracy: 0.6519 - val_loss: 0.7503 - val_accuracy: 0.7230\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9269 - accuracy: 0.6549 - val_loss: 0.7496 - val_accuracy: 0.7200\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9190 - accuracy: 0.6590 - val_loss: 0.7478 - val_accuracy: 0.7160\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9297 - accuracy: 0.6571 - val_loss: 0.7435 - val_accuracy: 0.7200\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9278 - accuracy: 0.6504 - val_loss: 0.7437 - val_accuracy: 0.7190\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.9218 - accuracy: 0.6511 - val_loss: 0.7415 - val_accuracy: 0.7200\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.9315 - accuracy: 0.6540 - val_loss: 0.7398 - val_accuracy: 0.7190\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.9163 - accuracy: 0.6677 - val_loss: 0.7365 - val_accuracy: 0.7230\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.9226 - accuracy: 0.6636 - val_loss: 0.7368 - val_accuracy: 0.7190\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.9118 - accuracy: 0.6623 - val_loss: 0.7348 - val_accuracy: 0.7200\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.9226 - accuracy: 0.6579 - val_loss: 0.7349 - val_accuracy: 0.7190\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.6627 - val_loss: 0.7288 - val_accuracy: 0.7220\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.9086 - accuracy: 0.6630 - val_loss: 0.7292 - val_accuracy: 0.7210\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.8885 - accuracy: 0.6731 - val_loss: 0.7248 - val_accuracy: 0.7260\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.9174 - accuracy: 0.6569 - val_loss: 0.7250 - val_accuracy: 0.7220\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8975 - accuracy: 0.6690 - val_loss: 0.7216 - val_accuracy: 0.7230\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.9038 - accuracy: 0.6609 - val_loss: 0.7199 - val_accuracy: 0.7240\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8836 - accuracy: 0.6714 - val_loss: 0.7176 - val_accuracy: 0.7230\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8857 - accuracy: 0.6653 - val_loss: 0.7169 - val_accuracy: 0.7280\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.8879 - accuracy: 0.6754 - val_loss: 0.7159 - val_accuracy: 0.7240\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.8812 - accuracy: 0.6729 - val_loss: 0.7131 - val_accuracy: 0.7260\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8854 - accuracy: 0.6686 - val_loss: 0.7121 - val_accuracy: 0.7260\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8974 - accuracy: 0.6659 - val_loss: 0.7119 - val_accuracy: 0.7280\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8880 - accuracy: 0.6739 - val_loss: 0.7100 - val_accuracy: 0.7300\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8827 - accuracy: 0.6766 - val_loss: 0.7081 - val_accuracy: 0.7290\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8914 - accuracy: 0.6666 - val_loss: 0.7065 - val_accuracy: 0.7290\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8612 - accuracy: 0.6834 - val_loss: 0.7064 - val_accuracy: 0.7260\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8809 - accuracy: 0.6754 - val_loss: 0.7039 - val_accuracy: 0.7270\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8698 - accuracy: 0.6743 - val_loss: 0.7025 - val_accuracy: 0.7310\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8740 - accuracy: 0.6751 - val_loss: 0.7012 - val_accuracy: 0.7270\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8605 - accuracy: 0.6830 - val_loss: 0.6998 - val_accuracy: 0.7260\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8566 - accuracy: 0.6827 - val_loss: 0.6983 - val_accuracy: 0.7250\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8762 - accuracy: 0.6729 - val_loss: 0.6980 - val_accuracy: 0.7250\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8509 - accuracy: 0.6844 - val_loss: 0.6958 - val_accuracy: 0.7280\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8448 - accuracy: 0.6866 - val_loss: 0.6939 - val_accuracy: 0.7260\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8573 - accuracy: 0.6820 - val_loss: 0.6952 - val_accuracy: 0.7230\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.8531 - accuracy: 0.6860 - val_loss: 0.6935 - val_accuracy: 0.7270\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8464 - accuracy: 0.6853 - val_loss: 0.6936 - val_accuracy: 0.7260\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8662 - accuracy: 0.6744 - val_loss: 0.6928 - val_accuracy: 0.7290\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.8579 - accuracy: 0.6881 - val_loss: 0.6910 - val_accuracy: 0.7280\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.8606 - accuracy: 0.6844 - val_loss: 0.6913 - val_accuracy: 0.7290\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8443 - accuracy: 0.6876 - val_loss: 0.6892 - val_accuracy: 0.7300\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8506 - accuracy: 0.6857 - val_loss: 0.6892 - val_accuracy: 0.7290\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8517 - accuracy: 0.6823 - val_loss: 0.6883 - val_accuracy: 0.7300\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8301 - accuracy: 0.6899 - val_loss: 0.6862 - val_accuracy: 0.7290\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.8286 - accuracy: 0.6933 - val_loss: 0.6837 - val_accuracy: 0.7310\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8230 - accuracy: 0.6953 - val_loss: 0.6828 - val_accuracy: 0.7330\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8299 - accuracy: 0.6944 - val_loss: 0.6821 - val_accuracy: 0.7340\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8269 - accuracy: 0.6967 - val_loss: 0.6808 - val_accuracy: 0.7360\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8243 - accuracy: 0.6997 - val_loss: 0.6812 - val_accuracy: 0.7350\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8364 - accuracy: 0.6941 - val_loss: 0.6798 - val_accuracy: 0.7380\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.8287 - accuracy: 0.6990 - val_loss: 0.6788 - val_accuracy: 0.7360\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "model.add(layers.Dense(50, activation='relu')) #2 hidden layers\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "dropout_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=200,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 904us/step - loss: 0.5311 - accuracy: 0.8159\n",
      "Training Loss: 0.531 Training Accuracy: 0.816\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.7640\n",
      "Testing Loss: 0.631 Testing Accuracy: 0.764\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again! The variance did become higher again compared to L1-regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, one of the solutions to high variance was just getting more data. You actually *have* more data, but took a subset of 10,000 units before. Let's now quadruple your data set, and see what happens. Note that you are really just lucky here, and getting more data isn't always possible, but this is a useful exercise in order to understand the power of big data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "df = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df[\"Consumer complaint narrative\"]\n",
    "y = df[\"Product\"]\n",
    "\n",
    "# train test split\n",
    "X_train_lrg, X_test_lrg, y_train_lrg, y_test_lrg = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#Validation set\n",
    "X_train_final_lrg, X_val_lrg, y_train_final_lrg, y_val_lrg = train_test_split(X_train_lrg, y_train_lrg, random_state=123)\n",
    "\n",
    "\n",
    "#one-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_lrg)\n",
    "\n",
    "X_train_tok_lrg = tokenizer.texts_to_matrix(X_train_final_lrg, mode='binary')\n",
    "X_val_lrg = tokenizer.texts_to_matrix(X_val_lrg, mode='binary')\n",
    "X_test_lrg = tokenizer.texts_to_matrix(X_test_lrg, mode='binary')\n",
    "\n",
    "#one-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_lrg)\n",
    "\n",
    "y_train_lb_lrg = to_categorical(lb.transform(y_train_final_lrg))[:, :, 1]\n",
    "y_val_lrg = to_categorical(lb.transform(y_val_lrg))[:, :, 1]\n",
    "y_test_lrg = to_categorical(lb.transform(y_test_lrg))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.9272 - accuracy: 0.1868 - val_loss: 1.9028 - val_accuracy: 0.2399\n",
      "Epoch 2/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.8742 - accuracy: 0.2719 - val_loss: 1.8415 - val_accuracy: 0.3109\n",
      "Epoch 3/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.7938 - accuracy: 0.3574 - val_loss: 1.7411 - val_accuracy: 0.3995\n",
      "Epoch 4/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.6731 - accuracy: 0.4470 - val_loss: 1.6021 - val_accuracy: 0.4807\n",
      "Epoch 5/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.5243 - accuracy: 0.5248 - val_loss: 1.4473 - val_accuracy: 0.5464\n",
      "Epoch 6/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.3721 - accuracy: 0.5832 - val_loss: 1.3005 - val_accuracy: 0.6040\n",
      "Epoch 7/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.2337 - accuracy: 0.6277 - val_loss: 1.1722 - val_accuracy: 0.6412\n",
      "Epoch 8/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.1148 - accuracy: 0.6610 - val_loss: 1.0650 - val_accuracy: 0.6704\n",
      "Epoch 9/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.0158 - accuracy: 0.6874 - val_loss: 0.9770 - val_accuracy: 0.6901\n",
      "Epoch 10/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.9354 - accuracy: 0.7052 - val_loss: 0.9081 - val_accuracy: 0.7019\n",
      "Epoch 11/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.8710 - accuracy: 0.7212 - val_loss: 0.8537 - val_accuracy: 0.7149\n",
      "Epoch 12/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.8196 - accuracy: 0.7313 - val_loss: 0.8113 - val_accuracy: 0.7227\n",
      "Epoch 13/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7780 - accuracy: 0.7405 - val_loss: 0.7766 - val_accuracy: 0.7300\n",
      "Epoch 14/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7443 - accuracy: 0.7476 - val_loss: 0.7495 - val_accuracy: 0.7381\n",
      "Epoch 15/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7160 - accuracy: 0.7561 - val_loss: 0.7273 - val_accuracy: 0.7421\n",
      "Epoch 16/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.7613 - val_loss: 0.7086 - val_accuracy: 0.7475\n",
      "Epoch 17/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.7684 - val_loss: 0.6941 - val_accuracy: 0.7473\n",
      "Epoch 18/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.7714 - val_loss: 0.6800 - val_accuracy: 0.7533\n",
      "Epoch 19/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.7774 - val_loss: 0.6690 - val_accuracy: 0.7573\n",
      "Epoch 20/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.7824 - val_loss: 0.6598 - val_accuracy: 0.7593\n",
      "Epoch 21/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.7854 - val_loss: 0.6503 - val_accuracy: 0.7649\n",
      "Epoch 22/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6013 - accuracy: 0.7901 - val_loss: 0.6444 - val_accuracy: 0.7620\n",
      "Epoch 23/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7921 - val_loss: 0.6365 - val_accuracy: 0.7665\n",
      "Epoch 24/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.7960 - val_loss: 0.6313 - val_accuracy: 0.7669\n",
      "Epoch 25/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7979 - val_loss: 0.6259 - val_accuracy: 0.7715\n",
      "Epoch 26/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.8006 - val_loss: 0.6198 - val_accuracy: 0.7735\n",
      "Epoch 27/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.8044 - val_loss: 0.6155 - val_accuracy: 0.7743\n",
      "Epoch 28/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.8075 - val_loss: 0.6118 - val_accuracy: 0.7748\n",
      "Epoch 29/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.8090 - val_loss: 0.6083 - val_accuracy: 0.7783\n",
      "Epoch 30/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.8119 - val_loss: 0.6048 - val_accuracy: 0.7776\n",
      "Epoch 31/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.8142 - val_loss: 0.6025 - val_accuracy: 0.7796\n",
      "Epoch 32/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.8152 - val_loss: 0.5987 - val_accuracy: 0.7803\n",
      "Epoch 33/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.8185 - val_loss: 0.5978 - val_accuracy: 0.7819\n",
      "Epoch 34/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.8200 - val_loss: 0.5940 - val_accuracy: 0.7823\n",
      "Epoch 35/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.8217 - val_loss: 0.5924 - val_accuracy: 0.7832\n",
      "Epoch 36/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.5012 - accuracy: 0.8234 - val_loss: 0.5895 - val_accuracy: 0.7863\n",
      "Epoch 37/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.8261 - val_loss: 0.5894 - val_accuracy: 0.7860\n",
      "Epoch 38/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.8266 - val_loss: 0.5877 - val_accuracy: 0.7871\n",
      "Epoch 39/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.8294 - val_loss: 0.5849 - val_accuracy: 0.7883\n",
      "Epoch 40/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.8301 - val_loss: 0.5844 - val_accuracy: 0.7868\n",
      "Epoch 41/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.8320 - val_loss: 0.5816 - val_accuracy: 0.7900\n",
      "Epoch 42/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.8336 - val_loss: 0.5813 - val_accuracy: 0.7893\n",
      "Epoch 43/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.8355 - val_loss: 0.5809 - val_accuracy: 0.7891\n",
      "Epoch 44/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.8363 - val_loss: 0.5800 - val_accuracy: 0.7871\n",
      "Epoch 45/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8386 - val_loss: 0.5784 - val_accuracy: 0.7915\n",
      "Epoch 46/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.8394 - val_loss: 0.5760 - val_accuracy: 0.7929\n",
      "Epoch 47/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.8417 - val_loss: 0.5773 - val_accuracy: 0.7911\n",
      "Epoch 48/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8428 - val_loss: 0.5756 - val_accuracy: 0.7927\n",
      "Epoch 49/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.8428 - val_loss: 0.5759 - val_accuracy: 0.7908\n",
      "Epoch 50/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8454 - val_loss: 0.5738 - val_accuracy: 0.7935\n",
      "Epoch 51/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8467 - val_loss: 0.5734 - val_accuracy: 0.7939\n",
      "Epoch 52/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8470 - val_loss: 0.5731 - val_accuracy: 0.7925\n",
      "Epoch 53/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8488 - val_loss: 0.5736 - val_accuracy: 0.7905\n",
      "Epoch 54/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8506 - val_loss: 0.5719 - val_accuracy: 0.7960\n",
      "Epoch 55/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8507 - val_loss: 0.5713 - val_accuracy: 0.7948\n",
      "Epoch 56/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8530 - val_loss: 0.5739 - val_accuracy: 0.7921\n",
      "Epoch 57/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8537 - val_loss: 0.5729 - val_accuracy: 0.7937\n",
      "Epoch 58/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8559 - val_loss: 0.5723 - val_accuracy: 0.7939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8560 - val_loss: 0.5721 - val_accuracy: 0.7947\n",
      "Epoch 60/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8571 - val_loss: 0.5726 - val_accuracy: 0.7928\n",
      "Epoch 61/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8567 - val_loss: 0.5715 - val_accuracy: 0.7940\n",
      "Epoch 62/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8609 - val_loss: 0.5706 - val_accuracy: 0.7955\n",
      "Epoch 63/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8601 - val_loss: 0.5719 - val_accuracy: 0.7956\n",
      "Epoch 64/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8616 - val_loss: 0.5717 - val_accuracy: 0.7936\n",
      "Epoch 65/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8630 - val_loss: 0.5717 - val_accuracy: 0.7957\n",
      "Epoch 66/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8631 - val_loss: 0.5728 - val_accuracy: 0.7957\n",
      "Epoch 67/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8652 - val_loss: 0.5719 - val_accuracy: 0.7964\n",
      "Epoch 68/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8661 - val_loss: 0.5725 - val_accuracy: 0.7949\n",
      "Epoch 69/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8664 - val_loss: 0.5719 - val_accuracy: 0.7960\n",
      "Epoch 70/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8679 - val_loss: 0.5741 - val_accuracy: 0.7948\n",
      "Epoch 71/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8694 - val_loss: 0.5724 - val_accuracy: 0.7961\n",
      "Epoch 72/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.8701 - val_loss: 0.5748 - val_accuracy: 0.7944\n",
      "Epoch 73/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8695 - val_loss: 0.5753 - val_accuracy: 0.7948\n",
      "Epoch 74/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8702 - val_loss: 0.5751 - val_accuracy: 0.7951\n",
      "Epoch 75/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8716 - val_loss: 0.5747 - val_accuracy: 0.7953\n",
      "Epoch 76/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8727 - val_loss: 0.5754 - val_accuracy: 0.7976\n",
      "Epoch 77/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8747 - val_loss: 0.5767 - val_accuracy: 0.7977\n",
      "Epoch 78/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8748 - val_loss: 0.5768 - val_accuracy: 0.7975\n",
      "Epoch 79/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8749 - val_loss: 0.5773 - val_accuracy: 0.7955\n",
      "Epoch 80/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8764 - val_loss: 0.5779 - val_accuracy: 0.7953\n",
      "Epoch 81/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8772 - val_loss: 0.5778 - val_accuracy: 0.7960\n",
      "Epoch 82/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8773 - val_loss: 0.5788 - val_accuracy: 0.7973\n",
      "Epoch 83/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3553 - accuracy: 0.8798 - val_loss: 0.5797 - val_accuracy: 0.7948\n",
      "Epoch 84/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.8800 - val_loss: 0.5820 - val_accuracy: 0.7953\n",
      "Epoch 85/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8794 - val_loss: 0.5835 - val_accuracy: 0.7949\n",
      "Epoch 86/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8807 - val_loss: 0.5811 - val_accuracy: 0.7967\n",
      "Epoch 87/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8824 - val_loss: 0.5816 - val_accuracy: 0.7983\n",
      "Epoch 88/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8830 - val_loss: 0.5827 - val_accuracy: 0.7960\n",
      "Epoch 89/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8837 - val_loss: 0.5831 - val_accuracy: 0.7984\n",
      "Epoch 90/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8848 - val_loss: 0.5853 - val_accuracy: 0.7976\n",
      "Epoch 91/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3391 - accuracy: 0.8856 - val_loss: 0.5857 - val_accuracy: 0.7972\n",
      "Epoch 92/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8856 - val_loss: 0.5863 - val_accuracy: 0.7975\n",
      "Epoch 93/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8874 - val_loss: 0.5864 - val_accuracy: 0.7972\n",
      "Epoch 94/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8871 - val_loss: 0.5884 - val_accuracy: 0.7964\n",
      "Epoch 95/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8884 - val_loss: 0.5915 - val_accuracy: 0.7964\n",
      "Epoch 96/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.8892 - val_loss: 0.5878 - val_accuracy: 0.7984\n",
      "Epoch 97/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8896 - val_loss: 0.5902 - val_accuracy: 0.7973\n",
      "Epoch 98/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8906 - val_loss: 0.5905 - val_accuracy: 0.7964\n",
      "Epoch 99/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3248 - accuracy: 0.8903 - val_loss: 0.5906 - val_accuracy: 0.7963\n",
      "Epoch 100/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3232 - accuracy: 0.8915 - val_loss: 0.5944 - val_accuracy: 0.7976\n",
      "Epoch 101/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3215 - accuracy: 0.8921 - val_loss: 0.5944 - val_accuracy: 0.7968\n",
      "Epoch 102/120\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 0.3201 - accuracy: 0.8928 - val_loss: 0.5935 - val_accuracy: 0.7975\n",
      "Epoch 103/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3179 - accuracy: 0.8936 - val_loss: 0.5992 - val_accuracy: 0.7969\n",
      "Epoch 104/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.8930 - val_loss: 0.5988 - val_accuracy: 0.7960\n",
      "Epoch 105/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.8948 - val_loss: 0.6009 - val_accuracy: 0.7968\n",
      "Epoch 106/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3133 - accuracy: 0.8948 - val_loss: 0.5984 - val_accuracy: 0.7981\n",
      "Epoch 107/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8961 - val_loss: 0.5984 - val_accuracy: 0.7972\n",
      "Epoch 108/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8968 - val_loss: 0.6006 - val_accuracy: 0.7964\n",
      "Epoch 109/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.3083 - accuracy: 0.8973 - val_loss: 0.6016 - val_accuracy: 0.7969\n",
      "Epoch 110/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8977 - val_loss: 0.6055 - val_accuracy: 0.7959\n",
      "Epoch 111/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8978 - val_loss: 0.6075 - val_accuracy: 0.7949\n",
      "Epoch 112/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3037 - accuracy: 0.8994 - val_loss: 0.6043 - val_accuracy: 0.7965\n",
      "Epoch 113/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8990 - val_loss: 0.6080 - val_accuracy: 0.7972\n",
      "Epoch 114/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.3005 - accuracy: 0.9000 - val_loss: 0.6098 - val_accuracy: 0.7967\n",
      "Epoch 115/120\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.9006 - val_loss: 0.6066 - val_accuracy: 0.7961\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.9012 - val_loss: 0.6095 - val_accuracy: 0.7968\n",
      "Epoch 117/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.9004 - val_loss: 0.6116 - val_accuracy: 0.7948\n",
      "Epoch 118/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.9022 - val_loss: 0.6141 - val_accuracy: 0.7955\n",
      "Epoch 119/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.9018 - val_loss: 0.6117 - val_accuracy: 0.7949\n",
      "Epoch 120/120\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.9024 - val_loss: 0.6137 - val_accuracy: 0.7951\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "moredata_model = model.fit(X_train_tok_lrg,\n",
    "                    y_train_lb_lrg,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_lrg, y_val_lrg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 1s 967us/step - loss: 0.2869 - accuracy: 0.9055\n",
      "Training Loss: 0.287 Training Accuracy: 0.905\n",
      "313/313 [==============================] - 0s 976us/step - loss: 0.6074 - accuracy: 0.7914\n",
      "Testing Loss: 0.607 Testing Accuracy: 0.791\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok_lrg, y_train_lb_lrg)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_lrg, y_test_lrg)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs, you were able to get a fairly similar validation accuracy of 89.67 (compared to 88.45 in obtained in the first model in this lab). Your test set accuracy went up from 75.8 to 79.2% though, without any other regularization technique. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  \n",
    "\n",
    "In this lesson, you not only built an initial deep-learning model, you then used a validation set to tune your model using various types of regularization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
